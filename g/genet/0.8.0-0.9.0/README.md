# Comparing `tmp/genet-0.8.0-py3-none-any.whl.zip` & `tmp/genet-0.9.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,33 +1,33 @@
-Zip file size: 58184 bytes, number of entries: 31
+Zip file size: 58829 bytes, number of entries: 31
 -rw-rw-rw-  2.0 fat      109 b- defN 22-Oct-28 02:23 genet/__init__.py
 -rw-rw-rw-  2.0 fat      113 b- defN 22-Dec-29 12:57 genet/main.py
 -rw-rw-rw-  2.0 fat      102 b- defN 22-Dec-21 12:42 genet/analysis/__init__.py
 -rw-rw-rw-  2.0 fat    10745 b- defN 22-Dec-24 07:17 genet/analysis/functional.py
 -rw-rw-rw-  2.0 fat      229 b- defN 22-Nov-23 01:16 genet/database/__init__.py
 -rw-rw-rw-  2.0 fat     8457 b- defN 23-Feb-01 08:54 genet/database/functional.py
 -rw-rw-rw-  2.0 fat     3275 b- defN 23-May-23 03:59 genet/design/DesignUtils.py
 -rw-rw-rw-  2.0 fat      101 b- defN 23-May-23 04:02 genet/design/__init__.py
 -rw-rw-rw-  2.0 fat    42517 b- defN 23-Jun-14 10:39 genet/design/functional.py
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Oct-28 02:23 genet/design/ref_transcripts.py
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Oct-28 02:23 genet/design/modules/__init__.py
 -rw-rw-rw-  2.0 fat       77 b- defN 23-Jul-27 14:04 genet/models/__init__.py
--rw-rw-rw-  2.0 fat    12566 b- defN 23-Aug-09 06:13 genet/models/constants.py
--rw-rw-rw-  2.0 fat     4989 b- defN 23-Aug-09 05:22 genet/models/functional.py
--rw-rw-rw-  2.0 fat    31496 b- defN 23-Aug-09 05:52 genet/predict/DeepPrime.py
--rw-rw-rw-  2.0 fat    15012 b- defN 23-Aug-09 06:37 genet/predict/DeepSmallCas9.py
--rw-rw-rw-  2.0 fat     7169 b- defN 23-Aug-09 10:04 genet/predict/DeepSpCas9.py
--rw-rw-rw-  2.0 fat     4601 b- defN 23-Aug-09 05:11 genet/predict/DeepSpCas9Variants.py
--rw-rw-rw-  2.0 fat      846 b- defN 23-Aug-07 00:01 genet/predict/PredUtils.py
--rw-rw-rw-  2.0 fat      383 b- defN 23-Aug-09 10:03 genet/predict/__init__.py
--rw-rw-rw-  2.0 fat    46548 b- defN 23-Aug-09 10:02 genet/predict/functional.py
--rw-rw-rw-  2.0 fat     1097 b- defN 23-Aug-07 09:55 genet/predict_dev/PredUtils.py
--rw-rw-rw-  2.0 fat      180 b- defN 23-Aug-07 10:00 genet/predict_dev/__init__.py
--rw-rw-rw-  2.0 fat    15390 b- defN 23-Aug-07 00:01 genet/predict_dev/functional_dev.py
--rw-rw-rw-  2.0 fat      180 b- defN 23-Aug-09 10:05 genet/utils/__init__.py
+-rw-rw-rw-  2.0 fat    14132 b- defN 23-Aug-10 02:43 genet/models/constants.py
+-rw-rw-rw-  2.0 fat     4957 b- defN 23-Aug-10 02:43 genet/models/functional.py
+-rw-rw-rw-  2.0 fat     7216 b- defN 23-Aug-10 02:43 genet/predict/DeepCas9Variants.py
+-rw-rw-rw-  2.0 fat    36137 b- defN 23-Aug-12 09:31 genet/predict/DeepPrime.py
+-rw-rw-rw-  2.0 fat    15012 b- defN 23-Aug-09 10:35 genet/predict/DeepSmallCas9.py
+-rw-rw-rw-  2.0 fat     8988 b- defN 23-Aug-12 09:34 genet/predict/DeepSpCas9.py
+-rw-rw-rw-  2.0 fat     1251 b- defN 23-Aug-10 00:21 genet/predict/PredUtils.py
+-rw-rw-rw-  2.0 fat      420 b- defN 23-Aug-12 09:35 genet/predict/__init__.py
+-rw-rw-rw-  2.0 fat    32537 b- defN 23-Aug-12 09:33 genet/predict/functional.py
+-rw-rw-rw-  2.0 fat     1097 b- defN 23-Aug-09 10:35 genet/predict_dev/PredUtils.py
+-rw-rw-rw-  2.0 fat      180 b- defN 23-Aug-09 10:35 genet/predict_dev/__init__.py
+-rw-rw-rw-  2.0 fat    15390 b- defN 23-Aug-09 10:35 genet/predict_dev/functional_dev.py
+-rw-rw-rw-  2.0 fat      180 b- defN 23-Aug-12 09:34 genet/utils/__init__.py
 -rw-rw-rw-  2.0 fat     2150 b- defN 23-Jul-27 14:00 genet/utils/functional.py
 -rw-rw-rw-  2.0 fat       43 b- defN 22-Oct-28 02:23 tests/__init__.py
--rw-rw-rw-  2.0 fat    15764 b- defN 23-Aug-09 10:08 genet-0.8.0.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 23-Aug-09 10:08 genet-0.8.0.dist-info/WHEEL
--rw-rw-rw-  2.0 fat       12 b- defN 23-Aug-09 10:08 genet-0.8.0.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat     2526 b- defN 23-Aug-09 10:08 genet-0.8.0.dist-info/RECORD
-31 files, 226769 bytes uncompressed, 54150 bytes compressed:  76.1%
+-rw-rw-rw-  2.0 fat    25527 b- defN 23-Aug-12 09:36 genet-0.9.0.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 23-Aug-12 09:36 genet-0.9.0.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat       12 b- defN 23-Aug-12 09:36 genet-0.9.0.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat     2525 b- defN 23-Aug-12 09:36 genet-0.9.0.dist-info/RECORD
+31 files, 233571 bytes uncompressed, 54799 bytes compressed:  76.5%
```

## zipnote {}

```diff
@@ -36,26 +36,26 @@
 
 Filename: genet/models/constants.py
 Comment: 
 
 Filename: genet/models/functional.py
 Comment: 
 
+Filename: genet/predict/DeepCas9Variants.py
+Comment: 
+
 Filename: genet/predict/DeepPrime.py
 Comment: 
 
 Filename: genet/predict/DeepSmallCas9.py
 Comment: 
 
 Filename: genet/predict/DeepSpCas9.py
 Comment: 
 
-Filename: genet/predict/DeepSpCas9Variants.py
-Comment: 
-
 Filename: genet/predict/PredUtils.py
 Comment: 
 
 Filename: genet/predict/__init__.py
 Comment: 
 
 Filename: genet/predict/functional.py
@@ -75,20 +75,20 @@
 
 Filename: genet/utils/functional.py
 Comment: 
 
 Filename: tests/__init__.py
 Comment: 
 
-Filename: genet-0.8.0.dist-info/METADATA
+Filename: genet-0.9.0.dist-info/METADATA
 Comment: 
 
-Filename: genet-0.8.0.dist-info/WHEEL
+Filename: genet-0.9.0.dist-info/WHEEL
 Comment: 
 
-Filename: genet-0.8.0.dist-info/top_level.txt
+Filename: genet-0.9.0.dist-info/top_level.txt
 Comment: 
 
-Filename: genet-0.8.0.dist-info/RECORD
+Filename: genet-0.9.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## genet/models/constants.py

```diff
@@ -1,67 +1,95 @@
 '''Model path and list of files
 All models from GitHub repository: genet-models
 '''
 
-
-
 dict_model_info = {
     
     # DeepSpCas9 model
     'SpCas9': {
+        # PAM pattern: NGG + NGA + NAG
         'type': 'DeepSpCas9',
         'repo': 'Goosang-Yu/genet-models/main/genet_models',
-        'path': 'DeepSpCas9'
+        'path': 'DeepSpCas9',
+        'regex': {'+': '[ATGC]{25}G[AG][ATGC]{3}|[ATGC]{25}AG[ATGC]{3}',
+                  '-': '[ATGC]{3}[CT]C[ATGC]{25}|[ATGC]{3}CT[ATGC]{25}',},
     },
 
-    # DeepSpCas9variants
+    # DeepCas9variants
     'SpCas9-NG': {
-        'type': 'DeepSpCas9variants',
+        # PAM pattern: NG + NA
+        'type': 'DeepCas9variants',
         'repo': 'Goosang-Yu/genet-models/main/genet_models',
-        'path': 'DeepSpCas9variants/PAM_variant_NG'
+        'path': 'DeepCas9variants/PAM_variant_NG',
+        'regex': {'+': '[ATGC]{25}[AG][ATGC]{4}',
+                  '-': '[ATGC]{4}[TC][ATGC]{25}',},
     },
     'SpCas9-NRCH': {
-        'type': 'DeepSpCas9variants',
+        # PAM pattern: NG + NA + NNG
+        'type': 'DeepCas9variants',
         'repo': 'Goosang-Yu/genet-models/main/genet_models',
-        'path': 'DeepSpCas9variants/PAM_variant_NRCH'
+        'path': 'DeepCas9variants/PAM_variant_NRCH',
+        'regex': {'+': '[ATGC]{25}[AG][ATGC]{4}|[ATGC]{26}G[ATGC]{3}',
+                  '-': '[ATGC]{4}[TC][ATGC]{25}|[ATGC]{3}C[ATGC]{26}',},
     },
     'SpCas9-NRRH': {
-        'type': 'DeepSpCas9variants',
+        # PAM pattern: NG + NA
+        'type': 'DeepCas9variants',
         'repo': 'Goosang-Yu/genet-models/main/genet_models',
-        'path': 'DeepSpCas9variants/PAM_variant_NRRH'
+        'path': 'DeepCas9variants/PAM_variant_NRRH',
+        'regex': {'+': '[ATGC]{25}[AG][ATGC]{4}',
+                  '-': '[ATGC]{4}[TC][ATGC]{25}',},
     },
     'SpCas9-NRTH': {
-        'type': 'DeepSpCas9variants',
+        # PAM pattern: NG + NA
+        'type': 'DeepCas9variants',
         'repo': 'Goosang-Yu/genet-models/main/genet_models',
-        'path': 'DeepSpCas9variants/PAM_variant_NRTH'
+        'path': 'DeepCas9variants/PAM_variant_NRTH',
+        'regex': {'+': '[ATGC]{25}[AG][ATGC]{4}',
+                  '-': '[ATGC]{4}[TC][ATGC]{25}',},
     },
     'SpCas9-Sc++': {
-        'type': 'DeepSpCas9variants',
+        # PAM pattern: NNG[CGT]
+        'type': 'DeepCas9variants',
         'repo': 'Goosang-Yu/genet-models/main/genet_models',
-        'path': 'DeepSpCas9variants/PAM_variant_Sc++'
+        'path': 'DeepCas9variants/PAM_variant_Sc++',
+        'regex': {'+': '[ATGC]{26}G[TGC][ATGC]{2}',
+                  '-': '[ATGC]{2}[AGC]C[ATGC]{26}',},
     },
     'SpCas9-SpCas9': {
-        'type': 'DeepSpCas9variants',
+        # PAM pattern: NGG + NGA + NAG
+        'type': 'DeepCas9variants',
         'repo': 'Goosang-Yu/genet-models/main/genet_models',
-        'path': 'DeepSpCas9variants/PAM_variant_SpCas9'
+        'path': 'DeepCas9variants/PAM_variant_SpCas9',
+        'regex': {'+': '[ATGC]{25}G[AG][ATGC]{3}|[ATGC]{25}AG[ATGC]{3}',
+                  '-': '[ATGC]{3}[CT]C[ATGC]{25}|[ATGC]{3}CT[ATGC]{25}',},
     },
     'SpCas9-SpG': {
-        'type': 'DeepSpCas9variants',
+        # PAM pattern: NG + NA
+        'type': 'DeepCas9variants',
         'repo': 'Goosang-Yu/genet-models/main/genet_models',
-        'path': 'DeepSpCas9variants/PAM_variant_SpG'
+        'path': 'DeepCas9variants/PAM_variant_SpG',
+        'regex': {'+': '[ATGC]{25}[AG][ATGC]{4}',
+                  '-': '[ATGC]{4}[TC][ATGC]{25}',},
     },
     'SpCas9-SpRY': {
-        'type': 'DeepSpCas9variants',
+        # PAM pattern: NNNG
+        'type': 'DeepCas9variants',
         'repo': 'Goosang-Yu/genet-models/main/genet_models',
-        'path': 'DeepSpCas9variants/PAM_variant_SpRY'
+        'path': 'DeepCas9variants/PAM_variant_SpRY',
+        'regex': {'+': '[ATGC]{25}[AG][ATGC]{4}|[ATGC]{27}G[ATGC]{2}',
+                  '-': '[ATGC]{4}[CT][ATGC]{25}|[ATGC]{2}C[ATGC]{27}',},
     },
     'SpCas9-VRQR': {
-        'type': 'DeepSpCas9variants',
+        # PAM pattern: NG + NNAG
+        'type': 'DeepCas9variants',
         'repo': 'Goosang-Yu/genet-models/main/genet_models',
-        'path': 'DeepSpCas9variants/PAM_variant_VRQR'
+        'path': 'DeepCas9variants/PAM_variant_VRQR',
+        'regex': {'+': '[ATGC]{25}G[ATGC]{4}|[ATGC]{26}AG[ATGC]{2}',
+                  '-': '[ATGC]{4}C[ATGC]{25}|[ATGC]{2}CT[ATGC]{26}',},
     },
 
 
     # DeepSmallCas9
     'CjCas9': {
         'type': 'DeepSmallCas9',
         'repo': 'Goosang-Yu/genet-models/main/genet_models',
@@ -314,15 +342,15 @@
     'DeepSpCas9': [
         '__init__.py',
         'PreTrain-Final-3-5-7-100-70-40-0.001-550-80-60.data-00000-of-00001', 
         'PreTrain-Final-3-5-7-100-70-40-0.001-550-80-60.index',
         'PreTrain-Final-3-5-7-100-70-40-0.001-550-80-60.meta',
     ],
     
-    'DeepSpCas9variants': [
+    'DeepCas9variants': [
         '__init__.py',
         'DeepCas9variants_model_WeightQuantization.tflite',
     ],
 
     'DeepPrime_base': [
         '__init__.py',
         'dp_mean.csv',
```

## genet/models/functional.py

```diff
@@ -12,43 +12,43 @@
     def __init__(self, model:str, effector:str, cell_type=None):
         '''
         self.model_dir: 모델 check point file들이 저장되어있는 위치
         '''
 
         if model == 'DeepSpCas9':
             model_type = effector
-        elif model == 'DeepSpCas9variants':
+        elif model == 'DeepCas9variants':
             model_type = effector
         elif model == 'DeepSmallCas9':
             model_type = effector
         elif model == 'DeepPrime':
             model_type = effector + '-' + cell_type
         else: 
             model_type = effector + '-' + cell_type
         
         # 이 모델이 genet에서 지원하는 것인지 확인하기
         try: 
-            self.model_info = models.constants.dict_model_info[model_type]
+            self.info = models.constants.dict_model_info[model_type]
         except:
             print('[Warning] Not available model in GenET!')
             sys.exit()
         
         # model_dir: 
-        self.model_dir  = inspect.getfile(models).replace('__init__.py', '') + self.model_info['path']
+        self.model_dir  = inspect.getfile(models).replace('__init__.py', '') + self.info['path']
 
         # 만약 모델이 아직 다운로드 되지 않았다면, 다운로드 하기.
         if not os.path.exists(self.model_dir):
             os.makedirs(self.model_dir)
 
             dict_files = models.constants.dict_model_requests
 
             self.download_from_github(
-                repo      = self.model_info['repo'],
-                path      = self.model_info['path'],
-                files     = dict_files[self.model_info['type']],
+                repo      = self.info['repo'],
+                path      = self.info['path'],
+                files     = dict_files[self.info['type']],
                 save_dir  = self.model_dir,
                 )
 
     def download_from_github(self, repo, path, files, save_dir):
         
         print('The model %s is not installed. Download checkpoint files.\n' % path)
```

## genet/predict/DeepPrime.py

```diff
@@ -1,26 +1,26 @@
-# from genet.utils import *
 import genet
 import genet.utils
+from genet.predict.PredUtils import *
+from genet.predict.DeepSpCas9 import SpCas9
+from genet.models import LoadModel
 
 import torch
 import torch.nn.functional as F
 import torch.nn as nn
 
 import os, sys, regex, logging
 import numpy as np
 import pandas as pd
-
-import tensorflow as tf
-# tf.disable_v2_behavior()
-
 from glob import glob
+
 from Bio.SeqUtils import MeltingTemp as mt
 from Bio.SeqUtils import gc_fraction as gc
 from Bio.Seq import Seq
+
 from RNA import fold_compound
 
 np.set_printoptions(threshold=sys.maxsize)
 os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
 
 
 class DeepPrime:
@@ -60,39 +60,103 @@
         
         # initializing
         self.set_logging()
         self.check_input()
 
         ## FeatureExtraction Class
         cFeat = FeatureExtraction()
+        self.logger.info('Make features of pegRNAs')
 
         cFeat.input_id = sID
         cFeat.get_input(Ref_seq, ED_seq, edit_type, edit_len)
-
         cFeat.get_sAltNotation(self.nAltIndex)
         cFeat.get_all_RT_PBS(self.nAltIndex, nMinPBS= self.pbs_min-1, nMaxPBS=self.pbs_max, nMaxRT=rtt_max, pam=self.pam)
         cFeat.make_rt_pbs_combinations()
         cFeat.determine_seqs()
         cFeat.determine_secondary_structure()
 
         self.features = cFeat.make_output_df()
         
         del cFeat
 
+        if len(self.features) > 0:
+            self.list_Guide30 = [WT74[:30] for WT74 in self.features['WT74_On']]
+            self.features['DeepSpCas9_score'] = SpCas9().predict(self.list_Guide30)['SpCas9']
+        
+        else:
+            print('\nsID:', sID)
+            print('DeepPrime only support RTT length upto 40nt')
+            print('There are no available pegRNAs, please check your input sequences\n')
+
         self.logger.info('Created an instance of DeepPrime')
 
     # def __init__: END
 
 
-    def submit(self, pe_system:str, cell_type:str = 'HEK293T'):
-        print('start pe_scre', self.Ref_seq, self.ED_seq, )
+    def predict(self, pe_system:str, cell_type:str = 'HEK293T', show_features:bool = False, report=False):
 
-        return None
+        df_all = self.features.copy()
+
+        os.environ['CUDA_VISIBLE_DEVICES']='0'
+        device = 'cuda' if torch.cuda.is_available() else 'cpu'
+        
+        model_info = LoadModel('DeepPrime', pe_system, cell_type)
+        model_dir  = model_info.model_dir
+
+        mean = pd.read_csv(f'{model_dir}/mean.csv', header=None, index_col=0).squeeze()
+        std  = pd.read_csv(f'{model_dir}/std.csv',  header=None, index_col=0).squeeze()
+
+        test_features = select_cols(df_all)
+
+        g_test = seq_concat(df_all)
+        x_test = (test_features - mean) / std
+
+        g_test = torch.tensor(g_test, dtype=torch.float32, device=device)
+        x_test = torch.tensor(x_test.to_numpy(), dtype=torch.float32, device=device)
+
+        models = [m_files for m_files in glob(f'{model_dir}/*.pt')]
+        preds  = []
 
-    # def submit: END
+        for m in models:
+            model = GeneInteractionModel(hidden_size=128, num_layers=1).to(device)
+            model.load_state_dict(torch.load(m, map_location=device))
+            model.eval()
+            with torch.no_grad():
+                g, x = g_test, x_test
+                g = g.permute((0, 3, 1, 2))
+                pred = model(g, x).detach().cpu().numpy()
+            preds.append(pred)
+        
+        # AVERAGE PREDICTIONS
+        preds = np.squeeze(np.array(preds))
+        preds = np.mean(preds, axis=0)
+        preds = np.exp(preds) - 1
+
+        df_all[f'{pe_system}_score'] = preds
+
+        if show_features == False:
+
+            def get_extension(masked_seq:str):
+                ext_seq = masked_seq.replace('x', '')
+                ext_seq = reverse_complement(ext_seq)
+                return ext_seq
+            
+            df = pd.DataFrame()
+            df['Target'] = df_all['WT74_On']
+            df['Spacer'] = self.list_Guide30
+            df['RT-PBS'] = df_all['Edited74_On'].apply(get_extension)
+            df = pd.concat([df,df_all.iloc[:, 3:9]],axis=1)
+            df[f'{pe_system}_score'] = df_all[f'{pe_system}_score']
+
+            return df
+
+        elif show_features == True:
+            return df_all
+
+    # def predict: END
 
 
     def set_logging(self):
 
         self.logger = logging.getLogger(self.OUT_PATH)
         self.logger.setLevel(logging.DEBUG)
 
@@ -131,53 +195,109 @@
         return None
 
     # def set_logging: END
 
 
     def check_input(self):
         
+        if len(self.Ref_seq) != 121:
+            self.error(f'sID:{self.sID}\nThe length of Ref_seq should be 121nt')
+            raise ValueError('Please check your input: Ref_seq')
+        
+        if len(self.ED_seq) != 121:
+            self.error(f'sID:{self.sID}\nThe length of ED_seq should be 121nt')
+            raise ValueError('Please check your input: ED_seq')
+
         if self.pbs_min < 1:
-            self.error('sID:%s\nPlease set PBS max length at least 1nt' % self.sID)
+            self.error(f'sID:{self.sID}\nPlease set PBS max length at least 1nt')
             raise ValueError('Please check your input: pbs_min')
         
         if self.pbs_max > 17:
-            self.error('sID:%s\nPlease set PBS max length upto 17nt' % self.sID)
+            self.error(f'sID:{self.sID}\nPlease set PBS max length upto 17nt')
             raise ValueError('Please check your input: pbs_max')
         
         if self.rtt_max > 40:
-            self.error('sID:%s\nPlease set RTT max length upto 40nt' % self.sID)
+            self.error(f'sID:{self.sID}\nPlease set RTT max length upto 40nt')
             raise ValueError('Please check your input: rtt_max')
 
         if self.edit_type not in ['sub', 'ins', 'del']:
-            self.error('sID:%s\n\t Please select proper edit type.\n\t Available edit tyle: sub, ins, del' % self.sID)
+            self.error(f'sID:{self.sID}\n\t Please select proper edit type.\n\t Available edit style: sub, ins, del')
+            raise ValueError('Please check your input: edit_type')
+        
+        if self.pam not in ['NGG', 'NRCH']:
+            self.error(f'sID:{self.sID}\n\t Please select proper PAM type.\n\t Available PAM: NGG, NRCH')
             raise ValueError('Please check your input: edit_type')
 
         if self.edit_len > 3:
-            self.error('sID:%s\n\t Please set edit length upto 3nt. Available edit length range: 1~3nt' % self.sID)
+            self.error(f'sID:{self.sID}\n\t Please set edit length upto 3nt. Available edit length range: 1~3nt')
             raise ValueError('Please check your input: edit_len')
         
         if self.edit_len < 1:
-            self.error('sID:%s\n\t Please set edit length at least 1nt. Available edit length range: 1~3nt' % self.sID)
+            self.error(f'sID:{self.sID}\n\t Please set edit length at least 1nt. Available edit length range: 1~3nt')
             raise ValueError('Please check your input: edit_len')
 
-        self.info('Input information\n\t ID: %s\n\t Refseq: %s\n\t EDseq :%s' % (self.sID, self.Ref_seq, self.ED_seq))
+        self.info(f'Input information\n\t ID: {self.sID}\n\t Refseq: {self.Ref_seq}\n\t EDseq :{self.ED_seq}')
 
         return None
     
     # def check_input: END
 
 
-    def do_something(self):
-        self.logger.info('Something happened.')
 
-        return None
+def set_alt_position_window(sStrand, sAltKey, nAltIndex, nIndexStart, nIndexEnd, nAltLen):
+    if sStrand == '+':
 
-    # def do_something: END
-    
+        if sAltKey.startswith('sub'):
+            return (nAltIndex + 1) - (nIndexStart - 3)
+        else:
+            return (nAltIndex + 1) - (nIndexStart - 3)
+
+    else:
+        if sAltKey.startswith('sub'):
+            return nIndexEnd - nAltIndex + 3 - (nAltLen - 1)
+
+        elif sAltKey.startswith('del'):
+            return nIndexEnd - nAltIndex + 3 - nAltLen
+
+        else:
+            return nIndexEnd - nAltIndex + 3 + nAltLen
+        # if END:
+    # if END:
 
+# def END: set_alt_position_window
+
+
+def set_PAM_nicking_pos(sStrand, sAltType, nAltLen, nAltIndex, nIndexStart, nIndexEnd):
+    if sStrand == '-':
+        nPAM_Nick = nIndexEnd + 3
+    else:
+        nPAM_Nick = nIndexStart - 3
+
+    return nPAM_Nick
+
+# def END: set_PAM_Nicking_Pos
+
+
+def check_PAM_window(dict_sWinSize, sStrand, nIndexStart, nIndexEnd, sAltType, nAltLen, nAltIndex):
+    nUp, nDown = dict_sWinSize[sAltType][nAltLen]
+
+    if sStrand == '+':
+        nPAMCheck_min = nAltIndex - nUp + 1
+        nPAMCheck_max = nAltIndex + nDown + 1
+    else:
+        nPAMCheck_min = nAltIndex - nDown + 1
+        nPAMCheck_max = nAltIndex + nUp + 1
+    # if END:
+
+    if nIndexStart < nPAMCheck_min or nIndexEnd > nPAMCheck_max:
+        return 0
+    else:
+        return 1
+
+# def END: check_PAM_window
 
 class FeatureExtraction:
     def __init__(self):
         self.sGuideKey = ''
         self.sChrID = ''
         self.sStrand = ''
         self.nGenomicPos = 0
@@ -244,15 +364,15 @@
     def get_all_RT_PBS(self, 
                     nAltIndex,
                     nMinPBS = 0,
                     nMaxPBS = 17,
                     nMaxRT = 40,
                     nSetPBSLen = 0,
                     nSetRTLen = 0,
-                    pe_system = 'PE2'
+                    pam = 'NGG'
                     ):
         """
         nMinPBS: If you set specific number, lower than MinPBS will be not generated. Default=0
         nMaxPBS: If you set specific number, higher than MinPBS will be not generated. Default=17
         nMaxRT = : If you set specific number, higher than MinPBS will be not generated. Default=40
         nSetPBSLen = 0  # Fix PBS Len: Set if >0
         nSetRTLen = 0  # Fix RT  Len: Set if >0
@@ -262,18 +382,18 @@
         nMaxEditPosWin = nMaxRT + 3  # Distance between PAM and mutation
 
         dict_sWinSize = {'sub': {1: [nMaxRT - 1 - 3, 6], 2: [nMaxRT - 2 - 3, 6], 3: [nMaxRT - 3 - 3, 6]},
                         'ins': {1: [nMaxRT - 2 - 3, 6], 2: [nMaxRT - 3 - 3, 6], 3: [nMaxRT - 4 - 3, 6]},
                         'del': {1: [nMaxRT - 1 - 3, 6], 2: [nMaxRT - 1 - 3, 6], 3: [nMaxRT - 1 - 3, 6]}}
 
         
-        if 'NRCH' in pe_system: # for NRCH-PE PAM
+        if pam == 'NRCH': # for NRCH-PE PAM
             dict_sRE = {'+': '[ACGT][ACGT]G[ACGT]|[ACGT][CG]A[ACGT]|[ACGT][AG]CC|[ATCG]ATG', 
                         '-': '[ACGT]C[ACGT][ACGT]|[ACGT]T[CG][ACGT]|G[GT]T[ACGT]|ATT[ACGT]|CAT[ACGT]|GGC[ACGT]|GTA[ACGT]'} 
-        else:
+        elif pam == 'NGG':
             dict_sRE = {'+': '[ACGT]GG[ACGT]', '-': '[ACGT]CC[ACGT]'} # for Original-PE PAM
 
         for sStrand in ['+', '-']:
 
             sRE = dict_sRE[sStrand]
             for sReIndex in regex.finditer(sRE, self.sWTSeq, overlapped=True):
 
@@ -686,15 +806,14 @@
         # loop END: sPAMKey
 
         return df_out
 
 # def END: make_output
 
 
-
 class GeneInteractionModel(nn.Module):
 
 
     def __init__(self, hidden_size, num_layers, num_features=24, dropout=0.1):
         super(GeneInteractionModel, self).__init__()
         self.hidden_size = hidden_size
         self.num_layers = num_layers
@@ -767,67 +886,67 @@
                             'type_ins', 'type_del', 'Tm1', 'Tm2', 'Tm2new', 'Tm3', 'Tm4', 'TmD',
                             'nGCcnt1', 'nGCcnt2', 'nGCcnt3', 'fGCcont1', 'fGCcont2', 'fGCcont3', 'MFE3', 'MFE4', 'DeepSpCas9_score']]
 
     return features
 
 
 
-def reverse_complement(sSeq):
-    dict_sBases = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A', 'N': 'N', 'U': 'U', 'n': '',
-                   '.': '.', '*': '*', 'a': 't', 'c': 'g', 'g': 'c', 't': 'a'}
-    list_sSeq = list(sSeq)  # Turns the sequence in to a gigantic list
-    list_sSeq = [dict_sBases[sBase] for sBase in list_sSeq]
-    return ''.join(list_sSeq)[::-1]
-
-# def END: reverse_complement
 
-def set_alt_position_window(sStrand, sAltKey, nAltIndex, nIndexStart, nIndexEnd, nAltLen):
-    if sStrand == '+':
 
-        if sAltKey.startswith('sub'):
-            return (nAltIndex + 1) - (nIndexStart - 3)
-        else:
-            return (nAltIndex + 1) - (nIndexStart - 3)
-
-    else:
-        if sAltKey.startswith('sub'):
-            return nIndexEnd - nAltIndex + 3 - (nAltLen - 1)
-
-        elif sAltKey.startswith('del'):
-            return nIndexEnd - nAltIndex + 3 - nAltLen
+def pecv_score(cv_record,
+               sID:str       = 'Sample',
+               pe_system:str = 'PE2max',
+               cell_type:str = 'HEK293T',
+               pbs_min:int   = 7,
+               pbs_max:int   = 15,
+               rtt_max:int   = 40
+               ):
 
-        else:
-            return nIndexEnd - nAltIndex + 3 + nAltLen
-        # if END:
-    # if END:
+    '''
+    Using variants records from GetClinVar in the database module.\n
+    You don't have to bring a sequence input to DeepPrime, but you calculate the score right away.\n
+    If DeepPrime is an unpredictable form of variants, it sends out a message.\n
+    
+    '''
+    
+    # check input parameters
+    if pbs_max > 17: return print('sID:%s\nPlease set PBS max length upto 17nt' % sID)
+    if rtt_max > 40: return print('sID:%s\nPlease set RTT max length upto 40nt' % sID)
+    
+    print('DeepPrime score of ClinVar record')
 
-# def END: set_alt_position_window
+    Ref_seq, ED_seq = cv_record.seq()
 
+    nAltIndex   = 60
+    pbs_range   = [pbs_min, pbs_max]
+    rtt_max     = rtt_max
+    pe_system   = pe_system
 
-def set_PAM_nicking_pos(sStrand, sAltType, nAltLen, nAltIndex, nIndexStart, nIndexEnd):
-    if sStrand == '-':
-        nPAM_Nick = nIndexEnd + 3
-    else:
-        nPAM_Nick = nIndexStart - 3
+    edit_type   = cv_record.alt_type
+    edit_len    = int(cv_record.alt_len)
 
-    return nPAM_Nick
+    ## FeatureExtraction Class
+    cFeat = FeatureExtraction()
 
-# def END: set_PAM_Nicking_Pos
+    cFeat.input_id = sID
+    cFeat.get_input(Ref_seq, ED_seq, edit_type, edit_len)
 
+    cFeat.get_sAltNotation(nAltIndex)
+    cFeat.get_all_RT_PBS(nAltIndex, nMinPBS=pbs_range[0]-1, nMaxPBS=pbs_range[1], nMaxRT=rtt_max, pe_system=pe_system)
+    cFeat.make_rt_pbs_combinations()
+    cFeat.determine_seqs()
+    cFeat.determine_secondary_structure()
 
-def check_PAM_window(dict_sWinSize, sStrand, nIndexStart, nIndexEnd, sAltType, nAltLen, nAltIndex):
-    nUp, nDown = dict_sWinSize[sAltType][nAltLen]
+    df = cFeat.make_output_df()
 
-    if sStrand == '+':
-        nPAMCheck_min = nAltIndex - nUp + 1
-        nPAMCheck_max = nAltIndex + nDown + 1
+    if len(df) > 0:
+        list_Guide30 = [WT74[:30] for WT74 in df['WT74_On']]
+        df['DeepSpCas9_score'] = spcas9_score(list_Guide30)
+        df['%s_score' % pe_system]  = calculate_deepprime_score(df, pe_system, cell_type)
+    
     else:
-        nPAMCheck_min = nAltIndex - nDown + 1
-        nPAMCheck_max = nAltIndex + nUp + 1
-    # if END:
+        print('\nsID:', sID)
+        print('DeepPrime only support RTT length upto 40nt')
+        print('There are no available pegRNAs, please check your input sequences\n')
 
-    if nIndexStart < nPAMCheck_min or nIndexEnd > nPAMCheck_max:
-        return 0
-    else:
-        return 1
+    return df
 
-# def END: check_PAM_window
```

## genet/predict/DeepSpCas9.py

```diff
@@ -1,8 +1,8 @@
-import os, sys
+import os, sys, regex
 import numpy as np
 import pandas as pd
 
 from genet.predict.PredUtils import *
 from genet.models import LoadModel
 
 import tensorflow as tf
@@ -22,27 +22,26 @@
         
         example) 
         >>> list_target30 = [
                             'TCACCTTCGTTTTTTTCCTTCTGCAGGAGG',
                             'CCTTCGTTTTTTTCCTTCTGCAGGAGGACA',
                             'CTTTCAAGAACTCTTCCACCTCCATGGTGT',
                             ]
-
-        >>> list_out = spcas9_score(list_target30)
+        >>> deepspcas9 = genet.predict.SpCas9()
         
-        >>> list_out = [2.80322408676147, 2.25273704528808, 53.4233360290527]
+        >>> spcas_score = deepspcas9(list_target30)
         '''
 
         # TensorFlow config
         self.conf = tf.compat.v1.ConfigProto()
         self.conf.gpu_options.allow_growth = True
         os.environ['CUDA_VISIBLE_DEVICES'] = '%d' % gpu_env
 
-        model_info = LoadModel('DeepSpCas9', 'SpCas9')
-        model_dir  = model_info.model_dir
+        self.model = LoadModel('DeepSpCas9', 'SpCas9')
+        model_dir  = self.model.model_dir
         best_model = 'PreTrain-Final-3-5-7-100-70-40-0.001-550-80-60'
 
         self.model_save = '%s/%s' % (model_dir, best_model)
         
         filter_size = [3, 5, 7]
         filter_num  = [100, 70, 40]
         self.params = [filter_size, filter_num, 0.001, 550]
@@ -55,27 +54,72 @@
         각 sequence 마다의 prediction score를 계산해서 list로 return 하는 함수
         '''
 
         seq_processed = preprocess_seq(list_target30, 30)
 
         with tf.compat.v1.Session(config=self.conf) as sess:
             sess.run(tf.compat.v1.global_variables_initializer())
-            model = DeepCas9(self.params[0], self.params[1], 80, 60, self.params[2])
+            interpreter = DeepCas9(self.params[0], self.params[1], 80, 60, self.params[2])
 
             saver = tf.compat.v1.train.Saver()
             saver.restore(sess, self.model_save)
 
-            list_score = Model_Finaltest(sess, seq_processed, model)
+            list_score = Model_Finaltest(sess, seq_processed, interpreter)
         
         df_out = pd.DataFrame()
-        df_out['Sequence']    = list_target30
+        df_out['Target'] = list_target30
+        df_out['Spacer'] = [seq[4:24] for seq in list_target30]
         df_out['SpCas9'] = list_score
 
         return df_out
     
+    def search(self, seq: str) -> pd.DataFrame:
+        '''주어진 sequence 내에 가능한 모든 target sequence를 찾고, 
+        그 정보와 예측 점수를 계산하는 method
+        '''
+        
+        self.seq = seq.upper()
+        dict_re  = self.model.info['regex']
+        
+        seq_target, seq_guide, seq_strand, pos_start, pos_end = [], [], [], [], []
+        
+        for strand in ['+', '-']:
+            ptn = dict_re[strand]
+
+            for re_idx in regex.finditer(ptn, self.seq, overlapped=True):
+                if strand == '+': match = re_idx.group()
+                else            : match = reverse_complement(re_idx.group())
+        
+                seq_target.append(match)
+                seq_guide.append(match[4:24])
+                seq_strand.append(strand)
+                pos_start.append(re_idx.start())
+                pos_end.append(re_idx.end())
+                
+        
+        seq_processed = preprocess_seq(seq_target, 30)
+
+        with tf.compat.v1.Session(config=self.conf) as sess:
+            sess.run(tf.compat.v1.global_variables_initializer())
+            interpreter = DeepCas9(self.params[0], self.params[1], 80, 60, self.params[2])
+
+            saver = tf.compat.v1.train.Saver()
+            saver.restore(sess, self.model_save)
+
+            list_score = Model_Finaltest(sess, seq_processed, interpreter)
+        
+        df_out = pd.DataFrame({'Target': seq_target,
+                               'Spacer': seq_guide,
+                               'Strand': seq_strand,
+                               'Start' : pos_start,
+                               'End'   : pos_end,
+                               'SpCas9': list_score})
+        
+        return df_out
+    
 
 def Model_Finaltest(sess, TEST_X, model):
     test_batch = 500
     TEST_Z = np.zeros((TEST_X.shape[0], 1), dtype=float)
 
     for i in range(int(np.ceil(float(TEST_X.shape[0]) / float(test_batch)))):
         Dict = {model.inputs: TEST_X[i * test_batch:(i + 1) * test_batch], model.is_training: False}
```

## genet/predict/PredUtils.py

```diff
@@ -18,8 +18,17 @@
             elif data[l][i] in "Tt":  seq_onehot[l, 0, i, 3] = 1
             elif data[l][i] in "Xx":  pass
             elif data[l][i] in "Nn.": pass
             else:
                 print("[Input Error] Non-ATGC character " + data[l])
                 sys.exit()
 
-    return seq_onehot
+    return seq_onehot
+
+def reverse_complement(sSeq):
+    dict_sBases = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A', 'N': 'N', 'U': 'U', 'n': '',
+                   '.': '.', '*': '*', 'a': 't', 'c': 'g', 'g': 'c', 't': 'a'}
+    list_sSeq = list(sSeq)  # Turns the sequence in to a gigantic list
+    list_sSeq = [dict_sBases[sBase] for sBase in list_sSeq]
+    return ''.join(list_sSeq)[::-1]
+
+# def END: reverse_complement
```

## genet/predict/__init__.py

```diff
@@ -1,10 +1,11 @@
 from genet.predict.functional import *
 from genet.predict.DeepSpCas9 import *
-from genet.predict.DeepSpCas9Variants import *
+from genet.predict.DeepCas9Variants import *
+from genet.predict.DeepPrime import *
 
 #### Under development ###
 # from genet.predict.DeepSmallCas9 import *
 # from genet.predict.functional_dev import *
 
 from silence_tensorflow import silence_tensorflow
 import warnings
```

## genet/predict/functional.py

```diff
@@ -1,291 +1,57 @@
-# from genet.utils import *
 import genet
 import genet.utils
+from genet.predict.PredUtils import *
+from genet.predict.DeepSpCas9 import SpCas9
+from genet.models import LoadModel
 
 import torch
 import torch.nn.functional as F
 import torch.nn as nn
 
-import os, sys, regex, logging
+import os, sys, regex
 import numpy as np
 import pandas as pd
-
-import tensorflow as tf
-
 from glob import glob
+
 from Bio.SeqUtils import MeltingTemp as mt
 from Bio.SeqUtils import gc_fraction as gc
 from Bio.Seq import Seq
+
 from RNA import fold_compound
 
 np.set_printoptions(threshold=sys.maxsize)
 os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
 
 
-class Deep_xCas9(object):
-    def __init__(self, filter_size, filter_num, node_1=80, node_2=60, l_rate=0.005):
-        length = 30
-        self.inputs      = tf.compat.v1.placeholder(tf.float32, [None, 1, length, 4])
-        self.targets     = tf.compat.v1.placeholder(tf.float32, [None, 1])
-        self.is_training = tf.compat.v1.placeholder(tf.bool)
-
-        def create_new_conv_layer(input_data, num_input_channels, num_filters, filter_shape, pool_shape, name):
-            # setup the filter input shape for tf.compat.v1.nn.conv_2d
-            conv_filt_shape = [filter_shape[0], filter_shape[1], num_input_channels,
-                               num_filters]
-
-            # initialise weights and bias for the filter
-            w = tf.compat.v1.Variable(tf.compat.v1.truncated_normal(conv_filt_shape, stddev=0.03), name=name + '_W')
-            b = tf.compat.v1.Variable(tf.compat.v1.truncated_normal([num_filters]), name=name + '_b')
-
-            # setup the convolutional layer operation
-            out_layer = tf.nn.conv2d(input_data, w, [1, 1, 1, 1], padding='VALID')
-
-            # add the bias
-            out_layer += b
-
-            # apply a ReLU non-linear activation
-            out_layer = tf.keras.layers.Dropout(rate=0.3)(tf.nn.relu(out_layer))
-
-            # now perform max pooling
-            ksize = [1, pool_shape[0], pool_shape[1], 1]
-            strides = [1, 1, 2, 1]
-            out_layer = tf.nn.avg_pool(out_layer, ksize=ksize, strides=strides, padding='SAME')
-
-            return out_layer
-
-        # def end: create_new_conv_layer
-
-        L_pool_0 = create_new_conv_layer(self.inputs, 4, filter_num[0], [1, filter_size[0]], [1, 2], name='conv1')
-        L_pool_1 = create_new_conv_layer(self.inputs, 4, filter_num[1], [1, filter_size[1]], [1, 2], name='conv2')
-        L_pool_2 = create_new_conv_layer(self.inputs, 4, filter_num[2], [1, filter_size[2]], [1, 2], name='conv3')
-
-        with tf.compat.v1.variable_scope('Fully_Connected_Layer1'):
-            layer_node_0 = int((length - filter_size[0]) / 2) + 1
-            node_num_0   = layer_node_0 * filter_num[0]
-            layer_node_1 = int((length - filter_size[1]) / 2) + 1
-            node_num_1   = layer_node_1 * filter_num[1]
-            layer_node_2 = int((length - filter_size[2]) / 2) + 1
-            node_num_2   = layer_node_2 * filter_num[2]
-
-            L_flatten_0  = tf.reshape(L_pool_0, [-1, node_num_0])
-            L_flatten_1  = tf.reshape(L_pool_1, [-1, node_num_1])
-            L_flatten_2  = tf.reshape(L_pool_2, [-1, node_num_2])
-            L_flatten    = tf.concat([L_flatten_0, L_flatten_1, L_flatten_2], 1, name='concat')
-
-            node_num     = node_num_0 + node_num_1 + node_num_2
-            W_fcl1       = tf.compat.v1.get_variable("W_fcl1", shape=[node_num, node_1])
-            B_fcl1       = tf.compat.v1.get_variable("B_fcl1", shape=[node_1])
-            L_fcl1_pre   = tf.nn.bias_add(tf.matmul(L_flatten, W_fcl1), B_fcl1)
-            L_fcl1       = tf.nn.relu(L_fcl1_pre)
-            L_fcl1_drop  = tf.keras.layers.Dropout(rate=0.3)(L_fcl1)
-
-        with tf.compat.v1.variable_scope('Fully_Connected_Layer2'):
-            W_fcl2       = tf.compat.v1.get_variable("W_fcl2", shape=[node_1, node_2])
-            B_fcl2       = tf.compat.v1.get_variable("B_fcl2", shape=[node_2])
-            L_fcl2_pre   = tf.nn.bias_add(tf.matmul(L_fcl1_drop, W_fcl2), B_fcl2)
-            L_fcl2       = tf.nn.relu(L_fcl2_pre)
-            L_fcl2_drop  = tf.keras.layers.Dropout(rate=0.3)(L_fcl2)
-
-        with tf.compat.v1.variable_scope('Output_Layer'):
-            W_out        = tf.compat.v1.get_variable("W_out", shape=[node_2, 1])
-            B_out        = tf.compat.v1.get_variable("B_out", shape=[1])
-            self.outputs = tf.nn.bias_add(tf.matmul(L_fcl2_drop, W_out), B_out)
-
-        # Define loss function and optimizer
-        self.obj_loss    = tf.reduce_mean(tf.square(self.targets - self.outputs))
-        self.optimizer   = tf.compat.v1.train.AdamOptimizer(l_rate).minimize(self.obj_loss)
-
-    # def end: def __init__
-# class end: Deep_xCas9
-
-
-def Model_Finaltest(sess, TEST_X, model):
-    test_batch = 500
-    TEST_Z = np.zeros((TEST_X.shape[0], 1), dtype=float)
-
-    for i in range(int(np.ceil(float(TEST_X.shape[0]) / float(test_batch)))):
-        Dict = {model.inputs: TEST_X[i * test_batch:(i + 1) * test_batch], model.is_training: False}
-        TEST_Z[i * test_batch:(i + 1) * test_batch] = sess.run([model.outputs], feed_dict=Dict)[0]
-
-    list_score = sum(TEST_Z.tolist(), [])
-
-    return list_score
-
-# def end: Model_Finaltest
-
-
-
-def preprocess_seq(data, seq_length):
-
-    seq_onehot = np.zeros((len(data), 1, seq_length, 4), dtype=float)
-
-    for l in range(len(data)):
-        for i in range(seq_length):
-            try:
-                data[l][i]
-            except Exception:
-                print(data[l], i, seq_length, len(data))
-
-            if   data[l][i] in "Aa":  seq_onehot[l, 0, i, 0] = 1
-            elif data[l][i] in "Cc":  seq_onehot[l, 0, i, 1] = 1
-            elif data[l][i] in "Gg":  seq_onehot[l, 0, i, 2] = 1
-            elif data[l][i] in "Tt":  seq_onehot[l, 0, i, 3] = 1
-            elif data[l][i] in "Xx":  pass
-            elif data[l][i] in "Nn.": pass
-            else:
-                print("[Input Error] Non-ATGC character " + data[l])
-                sys.exit()
-
-    return seq_onehot
-
-def spcas9_score_tf2(list_target30:list, gpu_env=0):
-    '''Tensorflow2 version function
-    The list_target30 should have a 30bp sequence in the form of a list.
-    Also, sequence [24:27] should contain NGG PAM.
-    
-    If you want to use a different GPU (based on nvidia-smi),
-    You can put the GPU number in the gpu_env. \n
-    
-    example) 
-    >>> list_target30 = [
-                        'TCACCTTCGTTTTTTTCCTTCTGCAGGAGG',
-                        'CCTTCGTTTTTTTCCTTCTGCAGGAGGACA',
-                        'CTTTCAAGAACTCTTCCACCTCCATGGTGT',
-                        ]
-
-    >>> list_out = spcas9_score(list_target30)
-    
-    >>> list_out = [2.80322408676147, 2.25273704528808, 53.4233360290527]
-    '''
-    
-    # TensorFlow config
-    conf = tf.ConfigProto()
-    conf.gpu_options.allow_growth = True
-    os.environ['CUDA_VISIBLE_DEVICES'] = '%d' % gpu_env
-
-    x_test = preprocess_seq(list_target30, 30)
 
-    from genet.models import LoadModel
+def spcas9_score(list_target30:list=None, gpu_env=0):
+    '''The function "spcas9_score" is not longer supported from GenET ver 0.9.0 anymore.\n
+    Please use ```genet.predict.SpCas9``` instead.'''
     
-    model_info = LoadModel('SpCas9')
-    model_dir  = model_info.model_dir
-    best_model = 'PreTrain-Final-3-5-7-100-70-40-0.001-550-80-60'
-
-    model_save = '%s/%s' % (model_dir, best_model)
-    final_model =  tf.keras.models.load_model(model_save,compile=False)
-
-    dataset_ = pd.DataFrame()
-    dataset_['target + PAM'] = list_target30
-
-    dataset_seq_masked = preprocess_seq(list_target30, 30)
-    dataset_seq_masked = pd.Series(list(dataset_seq_masked),name='seq')
-
-    dataset_all = pd.concat([dataset_,dataset_seq_masked],axis=1)
+    print('''The function "spcas9_score" is not longer supported from GenET ver 0.9.0 anymore.\n
+          Please use genet.predict.SpCas9 instead.''')
 
-    X_test_seq = np.stack(dataset_all['seq'])
-    hyperparameter_prediction = final_model.predict(X_test_seq, batch_size=128)
-    hyperparameter_prediction = pd.DataFrame(hyperparameter_prediction)
-
-    hyperparameter_prediction=pd.concat([dataset_all['target + PAM'].reset_index(drop=True),dataset_all['feature'].reset_index(drop=True),hyperparameter_prediction.reset_index(drop=True)],axis=1,ignore_index=True)
-
-    
-    return hyperparameter_prediction
-
-def spcas9_score(list_target30:list, gpu_env=0):
-    '''
-    The list_target30 should have a 30bp sequence in the form of a list.
-    Also, sequence [24:27] should contain NGG PAM.
-    
-    If you want to use a different GPU (based on nvidia-smi),
-    You can put the GPU number in the gpu_env. \n
-    
-    example) 
-    >>> list_target30 = [
-                        'TCACCTTCGTTTTTTTCCTTCTGCAGGAGG',
-                        'CCTTCGTTTTTTTCCTTCTGCAGGAGGACA',
-                        'CTTTCAAGAACTCTTCCACCTCCATGGTGT',
-                        ]
-
-    >>> list_out = spcas9_score(list_target30)
-    
-    >>> list_out = [2.80322408676147, 2.25273704528808, 53.4233360290527]
-    '''
-    
-    # TensorFlow config
-    conf = tf.compat.v1.ConfigProto()
-    conf.gpu_options.allow_growth = True
-    os.environ['CUDA_VISIBLE_DEVICES'] = '%d' % gpu_env
-
-    x_test = preprocess_seq(list_target30, 30)
-
-    from genet.models import LoadModel
-    
-    model_info = LoadModel('DeepSpCas9', 'SpCas9')
-    model_dir  = model_info.model_dir
-    best_model = 'PreTrain-Final-3-5-7-100-70-40-0.001-550-80-60'
-
-    model_save = '%s/%s' % (model_dir, best_model)
-    
-    filter_size = [3, 5, 7]
-    filter_num  = [100, 70, 40]
-    args        = [filter_size, filter_num, 0.001, 550]
-
-    tf.compat.v1.reset_default_graph()
-
-    with tf.compat.v1.Session(config=conf) as sess:
-        sess.run(tf.compat.v1.global_variables_initializer())
-        model = Deep_xCas9(filter_size, filter_num, 80, 60, args[2])
-
-        saver = tf.compat.v1.train.Saver()
-        saver.restore(sess, model_save)
-
-        list_score = Model_Finaltest(sess, x_test, model)
-    
-    return list_score
-
-
-def reverse_complement(sSeq):
-    dict_sBases = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A', 'N': 'N', 'U': 'U', 'n': '',
-                   '.': '.', '*': '*', 'a': 't', 'c': 'g', 'g': 'c', 't': 'a'}
-    list_sSeq = list(sSeq)  # Turns the sequence in to a gigantic list
-    list_sSeq = [dict_sBases[sBase] for sBase in list_sSeq]
-    return ''.join(list_sSeq)[::-1]
-
-# def END: reverse_complement
 
 def set_alt_position_window(sStrand, sAltKey, nAltIndex, nIndexStart, nIndexEnd, nAltLen):
     if sStrand == '+':
-
-        if sAltKey.startswith('sub'):
-            return (nAltIndex + 1) - (nIndexStart - 3)
-        else:
-            return (nAltIndex + 1) - (nIndexStart - 3)
+        if sAltKey.startswith('sub'): return (nAltIndex + 1) - (nIndexStart - 3)
+        else                        : return (nAltIndex + 1) - (nIndexStart - 3)
 
     else:
-        if sAltKey.startswith('sub'):
-            return nIndexEnd - nAltIndex + 3 - (nAltLen - 1)
-
-        elif sAltKey.startswith('del'):
-            return nIndexEnd - nAltIndex + 3 - nAltLen
-
-        else:
-            return nIndexEnd - nAltIndex + 3 + nAltLen
-        # if END:
-    # if END:
+        if sAltKey.startswith('sub')  : return nIndexEnd - nAltIndex + 3 - (nAltLen - 1)
+        elif sAltKey.startswith('del'): return nIndexEnd - nAltIndex + 3 - nAltLen
+        else                          : return nIndexEnd - nAltIndex + 3 + nAltLen
 
 # def END: set_alt_position_window
 
 
 def set_PAM_nicking_pos(sStrand, sAltType, nAltLen, nAltIndex, nIndexStart, nIndexEnd):
-    if sStrand == '-':
-        nPAM_Nick = nIndexEnd + 3
-    else:
-        nPAM_Nick = nIndexStart - 3
+    if sStrand == '-': nPAM_Nick = nIndexEnd + 3
+    else             : nPAM_Nick = nIndexStart - 3
 
     return nPAM_Nick
 
 # def END: set_PAM_Nicking_Pos
 
 
 def check_PAM_window(dict_sWinSize, sStrand, nIndexStart, nIndexEnd, sAltType, nAltLen, nAltIndex):
@@ -304,27 +70,23 @@
     else:
         return 1
 
 # def END: check_PAM_window
 
 class FeatureExtraction:
     def __init__(self):
-        self.sGuideKey = ''
-        self.sChrID = ''
         self.sStrand = ''
-        self.nGenomicPos = 0
         self.nEditIndex = 0
         self.nPBSLen = 0
         self.nRTTLen = 0
         self.sPBSSeq = ''
         self.sRTSeq = ''
         self.sPegRNASeq = ''
         self.sWTSeq = ''
         self.sEditedSeq = ''
-        self.list_sSeqs = []
         self.type_sub = 0
         self.type_ins = 0
         self.type_del = 0
         self.fTm1 = 0.0
         self.fTm2 = 0.0
         self.fTm2new = 0.0
         self.fTm3 = 0.0
@@ -574,18 +336,14 @@
     def determine_seqs(self):
         for sPAMKey in self.dict_sSeqs:
 
             sAltKey, sAltNotation, sStrand, nPAM_Nick, nAltPosWin, sPAMSeq, sGuideSeq = sPAMKey.split(',')
             nAltPosWin = int(nAltPosWin)
             nNickIndex = int(nPAM_Nick)
 
-            # if sStrand == '+':
-            #     sWTSeq74 = self.sWTSeq[nNickIndex - 21:nNickIndex + 53]
-            # else:
-            #     sWTSeq74 = reverse_complement(self.sWTSeq[nNickIndex - 53:nNickIndex + 21])
 
             for sSeqKey in self.dict_sCombos[sPAMKey]:
 
                 sRTSeq, sPBSSeq = sSeqKey.split(',')
 
                 ## for Tm1
                 sForTm1 = reverse_complement(sPBSSeq.replace('A', 'U'))
@@ -816,20 +574,16 @@
         
         # loop END: sPAMKey
 
         return df_out
 
 # def END: make_output
 
-
-
-
 class GeneInteractionModel(nn.Module):
 
-
     def __init__(self, hidden_size, num_layers, num_features=24, dropout=0.1):
         super(GeneInteractionModel, self).__init__()
         self.hidden_size = hidden_size
         self.num_layers = num_layers
 
         self.c1 = nn.Sequential(
             nn.Conv2d(in_channels=4, out_channels=128, kernel_size=(2, 3), stride=1, padding=(0, 1)),
@@ -904,15 +658,15 @@
 
 
 def calculate_deepprime_score(df_input, pe_system='PE2max', cell_type='HEK293T'):
 
     os.environ['CUDA_VISIBLE_DEVICES']='0'
     device = 'cuda' if torch.cuda.is_available() else 'cpu'
     
-    from genet.models import LoadModel
+    
 
     model_info = LoadModel('DeepPrime', pe_system, cell_type)
     model_dir  = model_info.model_dir
 
     mean = pd.read_csv('%s/mean.csv' % model_dir, header=None, index_col=0).squeeze()
     std  = pd.read_csv('%s/std.csv' % model_dir, header=None, index_col=0).squeeze()
 
@@ -949,15 +703,17 @@
             ED_seq: str, 
             sAlt: str,
             sID:str       = 'Sample',
             pe_system:str = 'PE2max',
             cell_type:str = 'HEK293T',
             pbs_min:int   = 7,
             pbs_max:int   = 15,
-            rtt_max:int   = 40
+            rtt_max:int   = 40,
+            show_features = False,
+            silence:bool  = False,
             ):
     '''
     Function to score Deep Prime score.\n
     Input  = 121 nt DNA sequence without edit\n
     Output = 121 nt DNA sequence with edit\n
     
     Available Edit types\n
@@ -966,15 +722,19 @@
     Available PE systems\n
     PE2, PE2max, PE4max, NRCH_PE2, NRCH_PE2max, NRCH_PE4max\n
     
     Available Cell types\n
     HEK293T, HCT116, MDA-MB-231, HeLa, DLD1, A549, NIH3T3
     
     '''
-        
+    if silence != True:
+        print('''[Warnning] genet.predict.pe_score will be deprecated in future.\n
+            Please consider genet.predict.DeepPrime instead.\n
+            Run DeepPrime now anyway.\n''')
+            
     nAltIndex   = 60
     pbs_range   = [pbs_min, pbs_max]
     rtt_max     = rtt_max
     pe_system   = pe_system
 
     edit_type   = sAlt[:-1].lower()
     edit_len    = int(sAlt[-1])
@@ -994,27 +754,45 @@
 
     cFeat.get_sAltNotation(nAltIndex)
     cFeat.get_all_RT_PBS(nAltIndex, nMinPBS=pbs_range[0]-1, nMaxPBS=pbs_range[1], nMaxRT=rtt_max, pe_system=pe_system)
     cFeat.make_rt_pbs_combinations()
     cFeat.determine_seqs()
     cFeat.determine_secondary_structure()
 
-    df = cFeat.make_output_df()
+    df_all = cFeat.make_output_df()
 
-    if len(df) > 0:
-        list_Guide30 = [WT74[:30] for WT74 in df['WT74_On']]
-        df['DeepSpCas9_score'] = spcas9_score(list_Guide30)
-        df['%s_score' % pe_system]  = calculate_deepprime_score(df, pe_system, cell_type)
+    if len(df_all) > 0:
+        list_Guide30 = [WT74[:30] for WT74 in df_all['WT74_On']]
+        df_all['DeepSpCas9_score'] = SpCas9().predict(list_Guide30)['SpCas9']
+        df_all['%s_score' % pe_system]  = calculate_deepprime_score(df_all, pe_system, cell_type)
     
     else:
         print('\nsID:', sID)
         print('DeepPrime only support RTT length upto 40nt')
         print('There are no available pegRNAs, please check your input sequences\n')
 
-    return df
+    if show_features == False:
+
+        def get_extension(masked_seq:str):
+            ext_seq = masked_seq.replace('x', '')
+            ext_seq = reverse_complement(ext_seq)
+            return ext_seq
+        
+        df = pd.DataFrame()
+        df['Target'] = df_all['WT74_On']
+        df['Spacer'] = list_Guide30
+        df['RT-PBS'] = df_all['Edited74_On'].apply(get_extension)
+        df = pd.concat([df,df_all.iloc[:, 3:9]],axis=1)
+        df['%s_score' % pe_system] = df_all['%s_score' % pe_system]
+
+        return df
+
+    elif show_features == True:
+        
+        return df_all
 
 def pecv_score(cv_record,
                sID:str       = 'Sample',
                pe_system:str = 'PE2max',
                cell_type:str = 'HEK293T',
                pbs_min:int   = 7,
                pbs_max:int   = 15,
@@ -1066,159 +844,7 @@
     else:
         print('\nsID:', sID)
         print('DeepPrime only support RTT length upto 40nt')
         print('There are no available pegRNAs, please check your input sequences\n')
 
     return df
 
-
-class DeepPrime:
-    '''
-    DeepPrime: pegRNA activity prediction models\n
-    Input  = 121 nt DNA sequence without edit\n
-    Output = 121 nt DNA sequence with edit\n
-    
-    ### Available Edit types\n
-    sub1, sub2, sub3, ins1, ins2, ins3, del1, del2, del3\n
-    
-    ### Available PE systems\n
-    PE2, PE2max, PE4max, NRCH_PE2, NRCH_PE2max, NRCH_PE4max\n
-    
-    ### Available Cell types\n
-    HEK293T, HCT116, MDA-MB-231, HeLa, DLD1, A549, NIH3T3
-    
-    '''
-    def __init__(self, sID:str, Ref_seq: str, ED_seq: str, edit_type: str, edit_len: int,
-                pam:str = 'NGG', pbs_min:int = 7, pbs_max:int = 15,
-                rtt_min:int = 0, rtt_max:int = 40, silence:bool = False,
-                out_dir:str=os.getcwd(),
-                ):
-        
-        # input parameters
-        self.nAltIndex = 60
-        self.sID, self.Ref_seq, self.ED_seq = sID, Ref_seq, ED_seq
-        self.edit_type, self.edit_len, self.pam = edit_type, edit_len, pam
-        self.pbs_min, self.pbs_max = pbs_min, pbs_max
-        self.pbs_range = [pbs_min, pbs_max]
-        self.rtt_min, self.rtt_max   = rtt_min, rtt_max
-        self.silence = silence
-        
-        # output directory
-        self.OUT_PATH = '%s/%s/'  % (out_dir, self.sID)
-        self.TEMP_DIR = '%s/temp' % self.OUT_PATH
-        
-        # initializing
-        self.set_logging()
-        self.check_input()
-
-        ## FeatureExtraction Class
-        cFeat = FeatureExtraction()
-
-        cFeat.input_id = sID
-        cFeat.get_input(Ref_seq, ED_seq, edit_type, edit_len)
-
-        cFeat.get_sAltNotation(self.nAltIndex)
-        cFeat.get_all_RT_PBS(self.nAltIndex, nMinPBS= self.pbs_min-1, nMaxPBS=self.pbs_max, nMaxRT=rtt_max, pam=self.pam)
-        cFeat.make_rt_pbs_combinations()
-        cFeat.determine_seqs()
-        cFeat.determine_secondary_structure()
-
-        self.features = cFeat.make_output_df()
-        
-        del cFeat
-
-        self.logger.info('Created an instance of DeepPrime')
-
-    # def __init__: END
-
-
-    def submit(self, pe_system:str, cell_type:str = 'HEK293T'):
-        print('start pe_scre', self.Ref_seq, self.ED_seq, )
-
-        return None
-
-    # def submit: END
-
-
-    def set_logging(self):
-
-        self.logger = logging.getLogger(self.OUT_PATH)
-        self.logger.setLevel(logging.DEBUG)
-
-        self.formatter = logging.Formatter(
-            '%(levelname)-5s @ %(asctime)s:\n\t %(message)s \n',
-            datefmt='%a, %d %b %Y %H:%M:%S',
-            )
-        
-        self.error = self.logger.error
-        self.warn  = self.logger.warn
-        self.debug = self.logger.debug
-        self.info  = self.logger.info
-
-        try:
-            os.makedirs(self.OUT_PATH, exist_ok=True)
-            os.makedirs(self.TEMP_DIR, exist_ok=True)
-            self.info('Creating Folder %s' % self.OUT_PATH)
-        except:
-            self.error('Creating Folder failed')
-            sys.exit(1)
-            
-        self.file_handler = logging.FileHandler('%s/log_%s.log' % (self.OUT_PATH, self.sID))
-        self.file_handler.setLevel(logging.DEBUG)
-        self.file_handler.setFormatter(self.formatter)
-        self.logger.addHandler(self.file_handler)
-        
-        if self.silence != True:
-            self.console_handler = logging.StreamHandler()
-            self.console_handler.setLevel(logging.DEBUG)
-            self.console_handler.setFormatter(self.formatter)
-            self.logger.addHandler(self.console_handler)
-
-        self.info('DeepPrime: pegRNA activity prediction models\n\t version: %s' % genet.__version__)
-
-
-        return None
-
-    # def set_logging: END
-
-
-    def check_input(self):
-        
-        if self.pbs_min < 1:
-            self.error('sID:%s\nPlease set PBS max length at least 1nt' % self.sID)
-            raise ValueError('Please check your input: pbs_min')
-        
-        if self.pbs_max > 17:
-            self.error('sID:%s\nPlease set PBS max length upto 17nt' % self.sID)
-            raise ValueError('Please check your input: pbs_max')
-        
-        if self.rtt_max > 40:
-            self.error('sID:%s\nPlease set RTT max length upto 40nt' % self.sID)
-            raise ValueError('Please check your input: rtt_max')
-
-        if self.edit_type not in ['sub', 'ins', 'del']:
-            self.error('sID:%s\n\t Please select proper edit type.\n\t Available edit tyle: sub, ins, del' % self.sID)
-            raise ValueError('Please check your input: edit_type')
-
-        if self.edit_len > 3:
-            self.error('sID:%s\n\t Please set edit length upto 3nt. Available edit length range: 1~3nt' % self.sID)
-            raise ValueError('Please check your input: edit_len')
-        
-        if self.edit_len < 1:
-            self.error('sID:%s\n\t Please set edit length at least 1nt. Available edit length range: 1~3nt' % self.sID)
-            raise ValueError('Please check your input: edit_len')
-
-        self.info('Input information\n\t ID: %s\n\t Refseq: %s\n\t EDseq :%s' % (self.sID, self.Ref_seq, self.ED_seq))
-
-        return None
-    
-    # def check_input: END
-
-
-    def do_something(self):
-        self.logger.info('Something happened.')
-
-        return None
-
-    # def do_something: END
-    
-
```

## genet/utils/__init__.py

```diff
@@ -1,10 +1,10 @@
 from .functional import *
 
 # for PyPI release
 # python setup.py bdist_wheel
 # twine upload dist/genet-0.5.2-py3-none-any.whl
 
-version_ = '0.8.0'
+version_ = '0.9.0'
 
 __version__ = version_
```

## Comparing `genet/predict/DeepSpCas9Variants.py` & `genet/predict/DeepCas9Variants.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 # Reference: https://blog.naver.com/PostView.naver?blogId=seodaewoo&logNo=222043145688&parentCategoryNo=&categoryNo=62&viewDate=&isShowPopularPosts=false&from=postView
-
-import tensorflow as tf
+import regex
 import numpy as np
 import pandas as pd
+import tensorflow as tf
 
 from genet.predict.PredUtils import *
 from genet.models import LoadModel
 
 
 class CasVariant:
     def __init__(self, effector:str):
@@ -16,21 +16,19 @@
         
         example) 
         >>> list_target30 = [
                         'TCACCTTCGTTTTTTTCCTTCTGCAGGAGG',
                         'CCTTCGTTTTTTTCCTTCTGCAGGAGGACA',
                         'CTTTCAAGAACTCTTCCACCTCCATGGTGT',
                         ]
-        \n
         '''
 
-        self.effector = effector
-
-        self.model_info = LoadModel('DeepSpCas9variants', effector)
-        self.model_dir  = self.model_info.model_dir
+        self.effector  = effector
+        self.model     = LoadModel('DeepCas9variants', effector)
+        self.model_dir = self.model.model_dir
 
 
     def predict(self, list_target30: list) -> pd.DataFrame:
         '''Input으로 30nt target context sequence 들이 담긴 list가 들어오면,
         각 sequence 마다의 prediction score를 계산해서 list로 return 하는 함수
         '''
         dataset_ = pd.DataFrame()
@@ -62,18 +60,87 @@
             interpreter.invoke()
 
             # Get the predictions
             predictions = interpreter.get_tensor(output_details[0]['index'])
             list_out.append(predictions[0][0])
 
         df_out = pd.DataFrame()
-        df_out['Sequence']    = list_target30
+        df_out['Target'] = list_target30
+        df_out['Spacer'] = [seq[4:24] for seq in list_target30]
+
         df_out[self.effector] = list_out
 
-        return df_out   
+        return df_out
+    
+    def search(self, seq: str) -> pd.DataFrame:
+        '''주어진 sequence 내에 가능한 모든 target sequence를 찾고, 
+        그 정보와 예측 점수를 계산하는 method
+        '''
+        
+        self.seq = seq.upper()
+        dict_re  = self.model.info['regex']
+        
+        seq_target, seq_guide, seq_strand, pos_start, pos_end = [], [], [], [], []
+        
+        for strand in ['+', '-']:
+            ptn = dict_re[strand]
+
+            for re_idx in regex.finditer(ptn, self.seq, overlapped=True):
+                if strand == '+': match = re_idx.group()
+                else            : match = reverse_complement(re_idx.group())
+        
+                seq_target.append(match)
+                seq_guide.append(match[4:24])
+                seq_strand.append(strand)
+                pos_start.append(re_idx.start())
+                pos_end.append(re_idx.end())
+                
+        
+        _dataset = pd.DataFrame()
+        _dataset['target + PAM'] = seq_target
+
+        # TFLite model loading / allocate tensor
+        interpreter =  tf.lite.Interpreter('%s/DeepCas9variants_model_WeightQuantization.tflite' % self.model_dir)
+        interpreter.allocate_tensors()
+
+        # 입출력 텐서 가져오기
+        input_details  = interpreter.get_input_details()
+        output_details = interpreter.get_output_details()
+
+        # 입력값 만들기 (preprocessing)
+        _dataset_seq_masked = preprocess_seq(seq_target, 30)
+        _dataset_seq_masked = pd.Series(list(_dataset_seq_masked), name='seq')
+        _dataset_all = pd.concat([_dataset,_dataset_seq_masked], axis=1)
+
+        X_test_seq = np.stack(_dataset_all['seq']).astype(np.float32)
+        list_out = []
+
+        for input_seq in X_test_seq:
+            input_seq = np.reshape(input_seq, (1, 30, 4))
+
+            # Set the input tensor data
+            interpreter.set_tensor(input_details[0]['index'], input_seq)
+
+            # Run the inference
+            interpreter.invoke()
+
+            # Get the predictions
+            predictions = interpreter.get_tensor(output_details[0]['index'])
+            list_out.append(predictions[0][0])
+
+
+        df_out = pd.DataFrame({'Target': seq_target,
+                               'Spacer': seq_guide,
+                               'Strand': seq_strand,
+                               'Start' : pos_start,
+                               'End'   : pos_end,})
+        
+        df_out[self.effector] = list_out
+        
+        return df_out
 
 
 
 def cas_variant_score_original(list_target30:list, gpu_env=0):
     '''DeepSpCas9variants score function
     The list_target30 should have a 30bp sequence in the form of a list.
```

## Comparing `genet-0.8.0.dist-info/RECORD` & `genet-0.9.0.dist-info/RECORD`

 * *Files 16% similar despite different names*

```diff
@@ -6,26 +6,26 @@
 genet/database/functional.py,sha256=_ap1uHTPYekvkPste4GaJkjq7_29kWroU3w9PDxQLpE,8457
 genet/design/DesignUtils.py,sha256=GtjWfDsijIbqgDIdIbX7W1A1dD1Jf1hW3GYwLqv5tu4,3275
 genet/design/__init__.py,sha256=EbVXcW-4ozxCtbDHNxBRHJdF1tnLaYxzztPKpI2mdNU,101
 genet/design/functional.py,sha256=_FKn1blEyss5YJz7aX1S2PPMFnpowDF89rrynE3rP34,42517
 genet/design/ref_transcripts.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 genet/design/modules/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 genet/models/__init__.py,sha256=oqpwg8SwNvIfhVzmhiO026lqxUY01r40Dgdgtaip0so,77
-genet/models/constants.py,sha256=o_nHZVplnb8bdi2f48ePdLj-O1EL30cK3nQo8xT8vf0,12566
-genet/models/functional.py,sha256=HqHqJ8DM1c_siut0IqF30wTlFW5ZwF-Pl3azLS7du_o,4989
-genet/predict/DeepPrime.py,sha256=Cl62D7889Ds_H2PA0dWbXHs4kiNsF_b76an-7Bu85vw,31496
+genet/models/constants.py,sha256=Q7y3YqGKqUAuE-isGUGN0aRTB2JFRe4Ydp8uPVstqWA,14132
+genet/models/functional.py,sha256=W9VfOi5Be8FMI8vHatb35urS-DJP6nDDmJein74zLIo,4957
+genet/predict/DeepCas9Variants.py,sha256=3fSLevTYTVoSBkBS5wlUG27z-uN6J0jqw9H1hjAFnzo,7216
+genet/predict/DeepPrime.py,sha256=CN2YGLsRf0XkmjOEl1fwL2jjyTlZsqHQaQ6OuUrICdM,36137
 genet/predict/DeepSmallCas9.py,sha256=U9biQeudea8HkPu9SJXNncXKJJ7_9tzJbQDSuBOyNv0,15012
-genet/predict/DeepSpCas9.py,sha256=HKL1cAmFQ_VwxmnH9L01jP87h6stAnv1FPi6NnSt080,7169
-genet/predict/DeepSpCas9Variants.py,sha256=NnVvQhEZa8kJWf96KWBBvIml3dbGRVOcNF6H7R7xieg,4601
-genet/predict/PredUtils.py,sha256=AwsUXVk4OHIx6LhPGXFytaXu3WCkmq2m9kIrDA6UfPA,846
-genet/predict/__init__.py,sha256=sjE5arlPefQEZOWX7j2Gg1GBvDfYxeulTrwxyHAYqnc,383
-genet/predict/functional.py,sha256=gik9zGouPDtJAkdulnv5ZBLCj3mjs4JWJZVPm2Amk_s,46548
+genet/predict/DeepSpCas9.py,sha256=EBK8wqf4xB_3Udtmeggn3LSYQ6Jnk39qaAVpTZwqJhQ,8988
+genet/predict/PredUtils.py,sha256=48PokjGWzHajb_4GK2mOhvJTzxepaRLrlEcYojZlcas,1251
+genet/predict/__init__.py,sha256=D3-R3KeEnzPO9Ug0fPoq_MFUp4fw21NIMzKsSkhlQmU,420
+genet/predict/functional.py,sha256=pI3Ndzrnc1P4naONqKjXU24jQIbcf_Qg790_CqIhmdo,32537
 genet/predict_dev/PredUtils.py,sha256=P5uV29-1Ei_UdFmQnkpFXwVHTIIp7ygtalcxZOJWvHg,1097
 genet/predict_dev/__init__.py,sha256=6qHU-6yVphVGc2ZKNYNXcVmEnovZSKtxfk6mIMAikfk,180
 genet/predict_dev/functional_dev.py,sha256=K_BxuAKBDzPIz46rw6tU8EE2uxXCEDRbzTvs0R_cias,15390
-genet/utils/__init__.py,sha256=8-8Qze_6_G4XtYnfDLwzhk8LiBhpc0Z30cmcPRtLhMI,180
+genet/utils/__init__.py,sha256=nwDLxS-st0qy6y4U5oHGGfUJArloxVqsZx_FRqFm8is,180
 genet/utils/functional.py,sha256=25qi_DaqhQk8E4WINfjdbachK9t5o3TMQ1RR85kfvK0,2150
 tests/__init__.py,sha256=BFhp5tyle0b2qhFpJ7tnbbjdPbPsWyi5aGVTUuNma7Y,43
-genet-0.8.0.dist-info/METADATA,sha256=zTZt5Kny7t7W1eYXBUKckXxLJ2y96Pyw09HUxpSubhg,15764
-genet-0.8.0.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-genet-0.8.0.dist-info/top_level.txt,sha256=r0lGZefzJjcHRFTtVrLE2EjICxN1ZkBKsFV_fgu3DuE,12
-genet-0.8.0.dist-info/RECORD,,
+genet-0.9.0.dist-info/METADATA,sha256=9jvhN9zbO2tdCM411hM6G5PQUk7qAjELwePCmJjTCfs,25527
+genet-0.9.0.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+genet-0.9.0.dist-info/top_level.txt,sha256=r0lGZefzJjcHRFTtVrLE2EjICxN1ZkBKsFV_fgu3DuE,12
+genet-0.9.0.dist-info/RECORD,,
```

