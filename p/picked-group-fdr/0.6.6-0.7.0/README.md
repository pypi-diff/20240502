# Comparing `tmp/picked_group_fdr-0.6.6-py3-none-any.whl.zip` & `tmp/picked_group_fdr-0.7.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,38 +1,38 @@
-Zip file size: 227323 bytes, number of entries: 110
+Zip file size: 233466 bytes, number of entries: 115
 -rw-r--r--  2.0 unx    11357 b- defN 80-Jan-01 00:00 LICENSE
 -rw-r--r--  2.0 unx     1528 b- defN 80-Jan-01 00:00 picked_group_fdr/__init__.py
 -rw-r--r--  2.0 unx      180 b- defN 80-Jan-01 00:00 picked_group_fdr/__main__.py
 -rw-r--r--  2.0 unx      831 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/__init__.py
 -rw-r--r--  2.0 unx      911 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/base.py
--rw-r--r--  2.0 unx     1307 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/evidence_ids.py
--rw-r--r--  2.0 unx     2281 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/fragpipe_protein_annotations.py
--rw-r--r--  2.0 unx     1664 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/id_type.py
--rw-r--r--  2.0 unx     1229 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/indistinguishable_proteins.py
--rw-r--r--  2.0 unx    13549 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/lfq.py
--rw-r--r--  2.0 unx     1809 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/modifications.py
--rw-r--r--  2.0 unx     2341 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/peptide_count.py
+-rw-r--r--  2.0 unx     1301 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/evidence_ids.py
+-rw-r--r--  2.0 unx     2313 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/fragpipe_protein_annotations.py
+-rw-r--r--  2.0 unx     1666 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/id_type.py
+-rw-r--r--  2.0 unx     1226 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/indistinguishable_proteins.py
+-rw-r--r--  2.0 unx    13615 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/lfq.py
+-rw-r--r--  2.0 unx     1805 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/modifications.py
+-rw-r--r--  2.0 unx     2359 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/peptide_count.py
 -rw-r--r--  2.0 unx     1932 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/protein_annotations.py
 -rw-r--r--  2.0 unx     3225 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/protein_probability.py
--rw-r--r--  2.0 unx     4645 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/sequence_coverage.py
--rw-r--r--  2.0 unx     1717 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/spectral_count.py
--rw-r--r--  2.0 unx     5231 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/sum_and_ibaq.py
--rw-r--r--  2.0 unx     2505 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/tmt.py
--rw-r--r--  2.0 unx     1368 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/top_peptide.py
--rw-r--r--  2.0 unx     9141 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/triqler.py
--rw-r--r--  2.0 unx     6873 b- defN 80-Jan-01 00:00 picked_group_fdr/competition.py
--rwxr-xr-x  2.0 unx    21784 b- defN 80-Jan-01 00:00 picked_group_fdr/digest.py
+-rw-r--r--  2.0 unx     4663 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/sequence_coverage.py
+-rw-r--r--  2.0 unx     1719 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/spectral_count.py
+-rw-r--r--  2.0 unx     5222 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/sum_and_ibaq.py
+-rw-r--r--  2.0 unx     2507 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/tmt.py
+-rw-r--r--  2.0 unx     1364 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/top_peptide.py
+-rw-r--r--  2.0 unx     9173 b- defN 80-Jan-01 00:00 picked_group_fdr/columns/triqler.py
+-rw-r--r--  2.0 unx     6910 b- defN 80-Jan-01 00:00 picked_group_fdr/competition.py
+-rwxr-xr-x  2.0 unx    21844 b- defN 80-Jan-01 00:00 picked_group_fdr/digest.py
 -rw-r--r--  2.0 unx   432703 b- defN 80-Jan-01 00:00 picked_group_fdr/digestfast.cpp
 -rw-r--r--  2.0 unx   220141 b- defN 80-Jan-01 00:00 picked_group_fdr/digestfast.html
 -rw-r--r--  2.0 unx     3923 b- defN 80-Jan-01 00:00 picked_group_fdr/digestfast.pyx
 -rw-r--r--  2.0 unx     5058 b- defN 80-Jan-01 00:00 picked_group_fdr/digestion_params.py
--rw-r--r--  2.0 unx     1893 b- defN 80-Jan-01 00:00 picked_group_fdr/entrapment.py
+-rw-r--r--  2.0 unx     1903 b- defN 80-Jan-01 00:00 picked_group_fdr/entrapment.py
 -rw-r--r--  2.0 unx     7231 b- defN 80-Jan-01 00:00 picked_group_fdr/fdr.py
 -rw-r--r--  2.0 unx     5843 b- defN 80-Jan-01 00:00 picked_group_fdr/graphs.py
--rw-r--r--  2.0 unx    10867 b- defN 80-Jan-01 00:00 picked_group_fdr/grouping.py
+-rw-r--r--  2.0 unx    10915 b- defN 80-Jan-01 00:00 picked_group_fdr/grouping.py
 -rw-r--r--  2.0 unx     3200 b- defN 80-Jan-01 00:00 picked_group_fdr/helpers.py
 -rw-r--r--  2.0 unx      134 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/classic_no_grouping.toml
 -rw-r--r--  2.0 unx      128 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/classic_no_grouping_no_remap.toml
 -rw-r--r--  2.0 unx      152 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/classic_protein_group.toml
 -rw-r--r--  2.0 unx      158 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/classic_rescued_subset_grouping.toml
 -rw-r--r--  2.0 unx      142 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/classic_subset_grouping.toml
 -rw-r--r--  2.0 unx      142 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/discard_picked.toml
@@ -42,71 +42,76 @@
 -rw-r--r--  2.0 unx      128 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/maxquant_mq_best.toml
 -rw-r--r--  2.0 unx      148 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/maxquant_mq_best_picked.toml
 -rw-r--r--  2.0 unx      133 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/maxquant_perc_best.toml
 -rw-r--r--  2.0 unx      155 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/maxquant_perc_best_picked.toml
 -rw-r--r--  2.0 unx      134 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/maxquant_picked.toml
 -rw-r--r--  2.0 unx      156 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/picked_protein_group.toml
 -rw-r--r--  2.0 unx      145 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/picked_protein_group_mq_input.toml
+-rw-r--r--  2.0 unx      154 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/picked_protein_group_mq_input_no_remap.toml
 -rw-r--r--  2.0 unx      150 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/picked_protein_group_no_remap.toml
 -rw-r--r--  2.0 unx      138 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/razor_picked.toml
 -rw-r--r--  2.0 unx      127 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/razor_picked_mq_input.toml
 -rw-r--r--  2.0 unx      150 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/sage.toml
 -rw-r--r--  2.0 unx      122 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/savitski.toml
 -rw-r--r--  2.0 unx      123 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/savitski_classic.toml
 -rw-r--r--  2.0 unx      125 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/savitski_mq_best.toml
 -rw-r--r--  2.0 unx      125 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/savitski_mq_mult.toml
 -rw-r--r--  2.0 unx      116 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/savitski_no_remap.toml
--rw-r--r--  2.0 unx     3514 b- defN 80-Jan-01 00:00 picked_group_fdr/methods.py
+-rw-r--r--  2.0 unx     5157 b- defN 80-Jan-01 00:00 picked_group_fdr/methods.py
 -rw-r--r--  2.0 unx     7790 b- defN 80-Jan-01 00:00 picked_group_fdr/observed_peptides.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 picked_group_fdr/parsers/__init__.py
--rw-r--r--  2.0 unx     5007 b- defN 80-Jan-01 00:00 picked_group_fdr/parsers/fragpipe.py
--rw-r--r--  2.0 unx     8752 b- defN 80-Jan-01 00:00 picked_group_fdr/parsers/maxquant.py
+-rw-r--r--  2.0 unx     1062 b- defN 80-Jan-01 00:00 picked_group_fdr/parsers/evidence.py
+-rw-r--r--  2.0 unx     7169 b- defN 80-Jan-01 00:00 picked_group_fdr/parsers/fragpipe.py
+-rw-r--r--  2.0 unx     8800 b- defN 80-Jan-01 00:00 picked_group_fdr/parsers/maxquant.py
 -rw-r--r--  2.0 unx     3597 b- defN 80-Jan-01 00:00 picked_group_fdr/parsers/modifications.py
--rw-r--r--  2.0 unx     6129 b- defN 80-Jan-01 00:00 picked_group_fdr/parsers/parsers.py
+-rw-r--r--  2.0 unx     4402 b- defN 80-Jan-01 00:00 picked_group_fdr/parsers/parsers.py
 -rw-r--r--  2.0 unx     4684 b- defN 80-Jan-01 00:00 picked_group_fdr/parsers/percolator.py
--rw-r--r--  2.0 unx     3309 b- defN 80-Jan-01 00:00 picked_group_fdr/parsers/psm.py
--rw-r--r--  2.0 unx     3510 b- defN 80-Jan-01 00:00 picked_group_fdr/parsers/sage.py
+-rw-r--r--  2.0 unx     1823 b- defN 80-Jan-01 00:00 picked_group_fdr/parsers/protein_groups.py
+-rw-r--r--  2.0 unx     3480 b- defN 80-Jan-01 00:00 picked_group_fdr/parsers/psm.py
+-rw-r--r--  2.0 unx     3533 b- defN 80-Jan-01 00:00 picked_group_fdr/parsers/sage.py
 -rw-r--r--  2.0 unx     1340 b- defN 80-Jan-01 00:00 picked_group_fdr/parsers/tsv.py
 -rw-r--r--  2.0 unx      331 b- defN 80-Jan-01 00:00 picked_group_fdr/peptide_info.py
--rw-r--r--  2.0 unx    17891 b- defN 80-Jan-01 00:00 picked_group_fdr/picked_group_fdr.py
+-rw-r--r--  2.0 unx     2057 b- defN 80-Jan-01 00:00 picked_group_fdr/peptide_protein_map.py
+-rw-r--r--  2.0 unx    12242 b- defN 80-Jan-01 00:00 picked_group_fdr/picked_group_fdr.py
 -rw-r--r--  2.0 unx      317 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/__init__.py
+-rw-r--r--  2.0 unx     4147 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/add_ibaq_columns.py
 -rw-r--r--  2.0 unx     3516 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/analyze_missing_peptides.py
--rw-r--r--  2.0 unx    11365 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/andromeda2pin.py
--rw-r--r--  2.0 unx     7355 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/entrapment_fdr.py
+-rw-r--r--  2.0 unx    12479 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/andromeda2pin.py
+-rw-r--r--  2.0 unx     7395 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/entrapment_fdr.py
 -rw-r--r--  2.0 unx    14045 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/filter_fdr_maxquant.py
--rw-r--r--  2.0 unx     6927 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/merge_pout.py
--rw-r--r--  2.0 unx     7510 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/pipeline.py
--rw-r--r--  2.0 unx     2013 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/run_mokapot.py
--rw-r--r--  2.0 unx     4050 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/sage_quantification.py
--rw-r--r--  2.0 unx    14856 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/update_evidence_from_pout.py
--rw-r--r--  2.0 unx    16452 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/update_fragpipe_results.py
--rw-r--r--  2.0 unx     6975 b- defN 80-Jan-01 00:00 picked_group_fdr/plotter.py
+-rw-r--r--  2.0 unx     7158 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/merge_pout.py
+-rw-r--r--  2.0 unx     9362 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/pipeline.py
+-rw-r--r--  2.0 unx     2036 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/run_mokapot.py
+-rw-r--r--  2.0 unx     4077 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/sage_quantification.py
+-rw-r--r--  2.0 unx    15397 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/update_evidence_from_pout.py
+-rw-r--r--  2.0 unx    17651 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/update_fragpipe_results.py
+-rw-r--r--  2.0 unx     6923 b- defN 80-Jan-01 00:00 picked_group_fdr/plotter.py
 -rw-r--r--  2.0 unx      417 b- defN 80-Jan-01 00:00 picked_group_fdr/precursor_quant.py
--rw-r--r--  2.0 unx     5600 b- defN 80-Jan-01 00:00 picked_group_fdr/protein_annotation.py
--rw-r--r--  2.0 unx     6861 b- defN 80-Jan-01 00:00 picked_group_fdr/protein_groups.py
+-rw-r--r--  2.0 unx     5594 b- defN 80-Jan-01 00:00 picked_group_fdr/protein_annotation.py
+-rw-r--r--  2.0 unx     6871 b- defN 80-Jan-01 00:00 picked_group_fdr/protein_groups.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 picked_group_fdr/quant/__init__.py
--rw-r--r--  2.0 unx     6222 b- defN 80-Jan-01 00:00 picked_group_fdr/quant/fragpipe.py
--rw-r--r--  2.0 unx     4246 b- defN 80-Jan-01 00:00 picked_group_fdr/quant/maxquant.py
--rw-r--r--  2.0 unx     7088 b- defN 80-Jan-01 00:00 picked_group_fdr/quant/sage.py
--rw-r--r--  2.0 unx     7017 b- defN 80-Jan-01 00:00 picked_group_fdr/quantification.py
+-rw-r--r--  2.0 unx     7293 b- defN 80-Jan-01 00:00 picked_group_fdr/quant/fragpipe.py
+-rw-r--r--  2.0 unx     4471 b- defN 80-Jan-01 00:00 picked_group_fdr/quant/maxquant.py
+-rw-r--r--  2.0 unx     8226 b- defN 80-Jan-01 00:00 picked_group_fdr/quant/sage.py
+-rw-r--r--  2.0 unx    10457 b- defN 80-Jan-01 00:00 picked_group_fdr/quantification.py
 -rw-r--r--  2.0 unx     7899 b- defN 80-Jan-01 00:00 picked_group_fdr/results.py
--rw-r--r--  2.0 unx     3489 b- defN 80-Jan-01 00:00 picked_group_fdr/score_origin.py
--rw-r--r--  2.0 unx     6348 b- defN 80-Jan-01 00:00 picked_group_fdr/scoring.py
--rw-r--r--  2.0 unx     8549 b- defN 80-Jan-01 00:00 picked_group_fdr/scoring_strategy.py
+-rw-r--r--  2.0 unx     3598 b- defN 80-Jan-01 00:00 picked_group_fdr/score_origin.py
+-rw-r--r--  2.0 unx     6357 b- defN 80-Jan-01 00:00 picked_group_fdr/scoring.py
+-rw-r--r--  2.0 unx     8749 b- defN 80-Jan-01 00:00 picked_group_fdr/scoring_strategy.py
 -rw-r--r--  2.0 unx      154 b- defN 80-Jan-01 00:00 picked_group_fdr/setup.py
 -rw-r--r--  2.0 unx    17000 b- defN 80-Jan-01 00:00 picked_group_fdr/simulation/simulate.py
 -rw-r--r--  2.0 unx     1061 b- defN 80-Jan-01 00:00 picked_group_fdr/utils/compare_razor_peptides.py
 -rw-r--r--  2.0 unx     1511 b- defN 80-Jan-01 00:00 picked_group_fdr/utils/compare_results.py
 -rw-r--r--  2.0 unx     3412 b- defN 80-Jan-01 00:00 picked_group_fdr/utils/get_genes_with_multiple_isoforms.py
--rw-r--r--  2.0 unx      372 b- defN 80-Jan-01 00:00 picked_group_fdr/writers/__init__.py
--rw-r--r--  2.0 unx     5107 b- defN 80-Jan-01 00:00 picked_group_fdr/writers/base.py
--rw-r--r--  2.0 unx     1889 b- defN 80-Jan-01 00:00 picked_group_fdr/writers/factory.py
+-rw-r--r--  2.0 unx      393 b- defN 80-Jan-01 00:00 picked_group_fdr/writers/__init__.py
+-rw-r--r--  2.0 unx     6807 b- defN 80-Jan-01 00:00 picked_group_fdr/writers/base.py
+-rw-r--r--  2.0 unx     1928 b- defN 80-Jan-01 00:00 picked_group_fdr/writers/factory.py
 -rw-r--r--  2.0 unx      271 b- defN 80-Jan-01 00:00 picked_group_fdr/writers/fragpipe.py
--rw-r--r--  2.0 unx     3874 b- defN 80-Jan-01 00:00 picked_group_fdr/writers/fragpipe_combined.py
+-rw-r--r--  2.0 unx     4905 b- defN 80-Jan-01 00:00 picked_group_fdr/writers/fragpipe_combined.py
 -rw-r--r--  2.0 unx     2747 b- defN 80-Jan-01 00:00 picked_group_fdr/writers/fragpipe_single.py
--rw-r--r--  2.0 unx     1735 b- defN 80-Jan-01 00:00 picked_group_fdr/writers/maxquant.py
+-rw-r--r--  2.0 unx     1915 b- defN 80-Jan-01 00:00 picked_group_fdr/writers/maxquant.py
 -rw-r--r--  2.0 unx      851 b- defN 80-Jan-01 00:00 picked_group_fdr/writers/minimal.py
--rw-r--r--  2.0 unx    11357 b- defN 80-Jan-01 00:00 picked_group_fdr-0.6.6.dist-info/LICENSE
--rw-r--r--  2.0 unx     5015 b- defN 80-Jan-01 00:00 picked_group_fdr-0.6.6.dist-info/METADATA
--rw-r--r--  2.0 unx       88 b- defN 80-Jan-01 00:00 picked_group_fdr-0.6.6.dist-info/WHEEL
-?rw-r--r--  2.0 unx    10504 b- defN 16-Jan-01 00:00 picked_group_fdr-0.6.6.dist-info/RECORD
-110 files, 1083616 bytes uncompressed, 210309 bytes compressed:  80.6%
+-rw-r--r--  2.0 unx    11357 b- defN 80-Jan-01 00:00 picked_group_fdr-0.7.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     2792 b- defN 80-Jan-01 00:00 picked_group_fdr-0.7.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       88 b- defN 80-Jan-01 00:00 picked_group_fdr-0.7.0.dist-info/WHEEL
+?rw-r--r--  2.0 unx    11019 b- defN 16-Jan-01 00:00 picked_group_fdr-0.7.0.dist-info/RECORD
+115 files, 1102265 bytes uncompressed, 215612 bytes compressed:  80.4%
```

## zipnote {}

```diff
@@ -135,14 +135,17 @@
 
 Filename: picked_group_fdr/methods/picked_protein_group.toml
 Comment: 
 
 Filename: picked_group_fdr/methods/picked_protein_group_mq_input.toml
 Comment: 
 
+Filename: picked_group_fdr/methods/picked_protein_group_mq_input_no_remap.toml
+Comment: 
+
 Filename: picked_group_fdr/methods/picked_protein_group_no_remap.toml
 Comment: 
 
 Filename: picked_group_fdr/methods/razor_picked.toml
 Comment: 
 
 Filename: picked_group_fdr/methods/razor_picked_mq_input.toml
@@ -171,14 +174,17 @@
 
 Filename: picked_group_fdr/observed_peptides.py
 Comment: 
 
 Filename: picked_group_fdr/parsers/__init__.py
 Comment: 
 
+Filename: picked_group_fdr/parsers/evidence.py
+Comment: 
+
 Filename: picked_group_fdr/parsers/fragpipe.py
 Comment: 
 
 Filename: picked_group_fdr/parsers/maxquant.py
 Comment: 
 
 Filename: picked_group_fdr/parsers/modifications.py
@@ -186,32 +192,41 @@
 
 Filename: picked_group_fdr/parsers/parsers.py
 Comment: 
 
 Filename: picked_group_fdr/parsers/percolator.py
 Comment: 
 
+Filename: picked_group_fdr/parsers/protein_groups.py
+Comment: 
+
 Filename: picked_group_fdr/parsers/psm.py
 Comment: 
 
 Filename: picked_group_fdr/parsers/sage.py
 Comment: 
 
 Filename: picked_group_fdr/parsers/tsv.py
 Comment: 
 
 Filename: picked_group_fdr/peptide_info.py
 Comment: 
 
+Filename: picked_group_fdr/peptide_protein_map.py
+Comment: 
+
 Filename: picked_group_fdr/picked_group_fdr.py
 Comment: 
 
 Filename: picked_group_fdr/pipeline/__init__.py
 Comment: 
 
+Filename: picked_group_fdr/pipeline/add_ibaq_columns.py
+Comment: 
+
 Filename: picked_group_fdr/pipeline/analyze_missing_peptides.py
 Comment: 
 
 Filename: picked_group_fdr/pipeline/andromeda2pin.py
 Comment: 
 
 Filename: picked_group_fdr/pipeline/entrapment_fdr.py
@@ -312,20 +327,20 @@
 
 Filename: picked_group_fdr/writers/maxquant.py
 Comment: 
 
 Filename: picked_group_fdr/writers/minimal.py
 Comment: 
 
-Filename: picked_group_fdr-0.6.6.dist-info/LICENSE
+Filename: picked_group_fdr-0.7.0.dist-info/LICENSE
 Comment: 
 
-Filename: picked_group_fdr-0.6.6.dist-info/METADATA
+Filename: picked_group_fdr-0.7.0.dist-info/METADATA
 Comment: 
 
-Filename: picked_group_fdr-0.6.6.dist-info/WHEEL
+Filename: picked_group_fdr-0.7.0.dist-info/WHEEL
 Comment: 
 
-Filename: picked_group_fdr-0.6.6.dist-info/RECORD
+Filename: picked_group_fdr-0.7.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## picked_group_fdr/columns/evidence_ids.py

```diff
@@ -1,10 +1,10 @@
 from __future__ import annotations
 
-from typing import List, Dict
+from typing import List
 import logging
 
 from .. import helpers
 from .base import ProteinGroupColumns
 
 # for type hints only
 from ..precursor_quant import PrecursorQuant
```

## picked_group_fdr/columns/fragpipe_protein_annotations.py

```diff
@@ -1,15 +1,15 @@
 from __future__ import annotations
 
 from typing import Dict
 import logging
 
 from picked_group_fdr import protein_groups as pg
 
-from ..protein_annotation import ProteinAnnotation
+from ..protein_annotation import ProteinAnnotation  # TODO: get rid of this import
 from .base import ProteinGroupColumns
 
 # for type hints only
 from .. import results
 
 
 logger = logging.getLogger(__name__)
```

## picked_group_fdr/columns/id_type.py

```diff
@@ -3,15 +3,15 @@
 from typing import List, Dict
 import logging
 
 from .. import helpers
 from .base import ProteinGroupColumns
 
 # for type hints only
-from ..precursor_quant import PrecursorQuant
+from .. import precursor_quant
 from .. import results
 
 
 logger = logging.getLogger(__name__)
 
 
 class IdentificationTypeColumns(ProteinGroupColumns):
@@ -33,15 +33,15 @@
             id_type = _identification_type_per_experiment(
                 pgr.precursorQuants, experiment_to_idx_map, post_err_prob_cutoff
             )
             pgr.extend(id_type)
 
 
 def _identification_type_per_experiment(
-    peptideIntensityList: List[PrecursorQuant],
+    peptideIntensityList: List[precursor_quant.PrecursorQuant],
     experimentToIdxMap: Dict[str, int],
     postErrProbCutoff: float,
 ):
     idType = [""] * len(experimentToIdxMap)
     for precursor in peptideIntensityList:
         idx = experimentToIdxMap[precursor.experiment]
         if helpers.is_mbr(precursor.post_err_prob) and idType[idx] != "By MS/MS":
```

## picked_group_fdr/columns/indistinguishable_proteins.py

```diff
@@ -1,35 +1,36 @@
 from __future__ import annotations
 
-from typing import List, Dict
 import logging
 
 from .base import ProteinGroupColumns
 
 # for type hints only
 from .. import results
 
 logger = logging.getLogger(__name__)
 
 
 class IndistinguishableProteinsColumns(ProteinGroupColumns):
     def append_headers(
         self,
         protein_group_results: results.ProteinGroupResults,
-    ) -> None:    
+    ) -> None:
         protein_group_results.append_header("Indistinguishable Proteins")
 
     def append_columns(
         self,
         protein_group_results: results.ProteinGroupResults,
         post_err_prob_cutoff: float,
     ) -> None:
         logger.info("Doing quantification: Indistinguishable Proteins")
         for pgr in protein_group_results:
             highest_peptide_count = 0
             indistinguishable_proteins = []
-            for protein_id, peptide_counts in zip(pgr.proteinIds.split(";"), pgr.peptideCountsUnique.split(";")):
+            for protein_id, peptide_counts in zip(
+                pgr.proteinIds.split(";"), pgr.peptideCountsUnique.split(";")
+            ):
                 if int(peptide_counts) >= highest_peptide_count:
                     if highest_peptide_count > 0:
                         indistinguishable_proteins.append(protein_id)
                     highest_peptide_count = int(peptide_counts)
-            pgr.append(", ".join(indistinguishable_proteins))
+            pgr.append(", ".join(indistinguishable_proteins))
```

## picked_group_fdr/columns/lfq.py

```diff
@@ -14,15 +14,15 @@
 from .. import helpers
 from .base import ProteinGroupColumns
 from .sum_and_ibaq import _get_intensities, get_silac_channels
 from .peptide_count import _unique_peptide_counts_per_experiment
 
 # imports for typing
 from .. import results
-from ..precursor_quant import PrecursorQuant
+from .. import precursor_quant
 
 
 logger = logging.getLogger(__name__)
 
 
 class LFQIntensityColumns(ProteinGroupColumns):
     minPeptideRatiosLFQ: int
@@ -118,15 +118,15 @@
                         f"    {experiment} {silacChannel}: {numProteinGroups[silacIdx]}"
                     )
             else:
                 logger.info(f"    {experiment}: {numProteinGroups[0]}")
 
 
 def _getLFQIntensities(
-    precursor_list: List[PrecursorQuant],
+    precursor_list: List[precursor_quant.PrecursorQuant],
     experiment_to_idx_map: Dict[str, int],
     postErrProbCutoff: float,
     minPeptideRatiosLFQ: int = 2,
     stabilizeLargeRatiosLFQ: bool = False,
     numSilacChannels: int = 0,
 ) -> List[float]:
     # in case of SILAC, we output LFQ intensites for each of the channels
@@ -166,34 +166,34 @@
     intensities = _solveLinearSystem(matrix, vector)
     intensities = _scaleEqualSum(intensities, totalIntensity)
 
     return intensities
 
 
 def _getPeptideIntensities(
-    precursor_list: List[PrecursorQuant],
+    precursor_list: List[precursor_quant.PrecursorQuant],
     experimentToIdxMap: Dict[str, int],
     postErrProbCutoff: float,
     numSilacChannels: int,
     numExperiments: int,
 ) -> Tuple[Dict[Tuple[str, int], List[float]], float]:
     """
     Collects all precursor intensities per experiment
     """
 
-    def filterMissingAndUnidentified(p: PrecursorQuant):
+    def filterMissingAndUnidentified(p: precursor_quant.PrecursorQuant):
         return p.intensity > 0.0 and (
             helpers.is_mbr(p.post_err_prob) or p.post_err_prob <= postErrProbCutoff
         )
 
     precursor_list = filter(filterMissingAndUnidentified, precursor_list)
 
     # for each (peptide, charge, experiment, fraction) tuple, sort the
     # lowest PEP (= most confident PSM) on top
-    def orderByPEP(p: PrecursorQuant):
+    def orderByPEP(p: precursor_quant.PrecursorQuant):
         return (
             p.peptide,
             p.charge,
             p.experiment,
             p.fraction,
             -1 * p.intensity,
             p.post_err_prob,
@@ -224,15 +224,15 @@
             prevExpFrac = currExpFrac
             prevPrecursor = currPrecursor
     return peptideIntensities, totalIntensity
 
 
 def _applyLargeRatioStabilization(
     logMedianPeptideRatios: Dict[Tuple[int, int], float],
-    precursor_list: List[PrecursorQuant],
+    precursor_list: List[precursor_quant.PrecursorQuant],
     experimentToIdxMap: Dict[str, int],
     postErrProbCutoff: float,
     numSilacChannels: int,
 ) -> Dict[Tuple[int, int], float]:
     summedIntensities = _get_intensities(
         precursor_list, experimentToIdxMap, postErrProbCutoff, numSilacChannels
     )
```

## picked_group_fdr/columns/modifications.py

```diff
@@ -1,17 +1,17 @@
 from __future__ import annotations
 
-from typing import List, Dict
+from typing import List
 import logging
 
 from .. import helpers
 from .base import ProteinGroupColumns
 
 # for type hints only
-from ..precursor_quant import PrecursorQuant
+from .. import precursor_quant
 from .. import results
 
 logger = logging.getLogger(__name__)
 
 
 class ModificationsColumns(ProteinGroupColumns):
     def append_headers(
@@ -32,15 +32,15 @@
             pepCounts = _collect_modifications(
                 pgr.precursorQuants, post_err_prob_cutoff
             )
             pgr.extend(pepCounts)
 
 
 def _collect_modifications(
-    precursor_list: List[PrecursorQuant],
+    precursor_list: List[precursor_quant.PrecursorQuant],
     post_err_prob_cutoff: float,
 ):
     assigned_mods = dict()
     observed_mods = dict()
     for precursor in precursor_list:
         if (
             helpers.is_mbr(precursor.post_err_prob)
```

## picked_group_fdr/columns/peptide_count.py

```diff
@@ -3,15 +3,15 @@
 from typing import List, Dict
 import logging
 
 from .. import helpers
 from .base import ProteinGroupColumns
 
 # for type hints only
-from ..precursor_quant import PrecursorQuant
+from .. import precursor_quant
 from .. import results
 
 logger = logging.getLogger(__name__)
 
 
 class UniquePeptideCountColumns(ProteinGroupColumns):
     def append_headers(
@@ -39,15 +39,15 @@
             pepCounts = _unique_peptide_counts_per_experiment(
                 pgr.precursorQuants, experiment_to_idx_map, post_err_prob_cutoff
             )
             pgr.extend(pepCounts)
 
 
 def _unique_peptide_counts_per_experiment(
-    precursor_list: List[PrecursorQuant],
+    precursor_list: List[precursor_quant.PrecursorQuant],
     experiment_to_idx_map: Dict[str, int],
     post_err_prob_cutoff: float,
 ):
     uniquePeptides = [set() for _ in range(len(experiment_to_idx_map))]
     for precursor in precursor_list:
         if (
             helpers.is_mbr(precursor.post_err_prob)
@@ -56,15 +56,15 @@
             uniquePeptides[experiment_to_idx_map[precursor.experiment]].add(
                 precursor.peptide
             )
     return list(map(len, uniquePeptides))
 
 
 def _unique_peptide_counts_combined(
-    precursor_list: List[PrecursorQuant],
+    precursor_list: List[precursor_quant.PrecursorQuant],
     post_err_prob_cutoff: float,
 ):
     uniquePeptides = set()
     for precursor in precursor_list:
         if (
             helpers.is_mbr(precursor.post_err_prob)
             or precursor.post_err_prob <= post_err_prob_cutoff
```

## picked_group_fdr/columns/sequence_coverage.py

```diff
@@ -5,15 +5,15 @@
 
 import numpy as np
 
 from .. import helpers
 from .base import ProteinGroupColumns
 
 # for type hints only
-from ..precursor_quant import PrecursorQuant
+from .. import precursor_quant
 from .. import results
 
 logger = logging.getLogger(__name__)
 
 
 class SequenceCoverageColumns(ProteinGroupColumns):
     protein_sequences: Dict[str, str]
@@ -52,29 +52,29 @@
                 post_err_prob_cutoff,
                 pgr.proteinIds,
             )
             pgr.extend(sequence_coverages)
 
     def get_sequence_coverages(
         self,
-        precursor_list: List[PrecursorQuant],
+        precursor_list: List[precursor_quant.PrecursorQuant],
         experiment_to_idx_map: Dict[str, int],
         post_err_prob_cutoff: float,
         protein_ids: str,
     ) -> List[str]:
         peptide_set_per_experiment = self.unique_peptides_per_experiment(
             precursor_list, experiment_to_idx_map, post_err_prob_cutoff
         )
         return self.calculate_sequence_coverages(
             peptide_set_per_experiment, protein_ids
         )
 
     def unique_peptides_per_experiment(
         self,
-        precursor_list: List[PrecursorQuant],
+        precursor_list: List[precursor_quant.PrecursorQuant],
         experiment_to_idx_map: Dict[str, int],
         post_err_prob_cutoff: float,
     ) -> List[Set[str]]:
         uniquePeptides = [set() for _ in range(len(experiment_to_idx_map))]
         for precursor in precursor_list:
             if (
                 helpers.is_mbr(precursor.post_err_prob)
```

## picked_group_fdr/columns/spectral_count.py

```diff
@@ -3,15 +3,15 @@
 from typing import List, Dict
 import logging
 
 from .. import helpers
 from .base import ProteinGroupColumns
 
 # for type hints only
-from ..precursor_quant import PrecursorQuant
+from .. import precursor_quant
 from .. import results
 
 logger = logging.getLogger(__name__)
 
 
 class SpectralCountColumns(ProteinGroupColumns):
     def append_headers(
@@ -35,15 +35,15 @@
                 pgr.precursorQuants, experiment_to_idx_map, post_err_prob_cutoff
             )
             pgr.append(sum(pepCounts))
             pgr.extend(pepCounts)
 
 
 def _spectral_counts_per_experiment(
-    precursor_list: List[PrecursorQuant],
+    precursor_list: List[precursor_quant.PrecursorQuant],
     experiment_to_idx_map: Dict[str, int],
     post_err_prob_cutoff: float,
 ):
     spectral_counts = [0] * len(experiment_to_idx_map)
     for precursor in precursor_list:
         if (
             not helpers.is_mbr(precursor.post_err_prob)
```

## picked_group_fdr/columns/sum_and_ibaq.py

```diff
@@ -1,20 +1,19 @@
 from __future__ import annotations
-import sys
 
 from typing import List, Dict
 import logging
 
 import numpy as np
 
 from .. import helpers
 from .base import ProteinGroupColumns
 
 # for type hints only
-from ..precursor_quant import PrecursorQuant
+from .. import precursor_quant
 from .. import results
 
 logger = logging.getLogger(__name__)
 
 
 def get_silac_channels(num_silac_channels: int):
     if num_silac_channels == 3:
@@ -108,15 +107,15 @@
             for silacIdx, silacChannel in enumerate(silac_channels):
                 logger.info(
                     f"    {experiment} {silacChannel}: {numProteinGroups[silacIdx+1]}"
                 )
 
 
 def _get_intensities(
-    peptideIntensityList: List[PrecursorQuant],
+    peptideIntensityList: List[precursor_quant.PrecursorQuant],
     experimentToIdxMap,
     postErrProbCutoff,
     numSilacChannels,
 ) -> List[float]:
     intensities = [0.0] * (len(experimentToIdxMap) * (1 + numSilacChannels))
     for precursor in peptideIntensityList:
         if np.isnan(precursor.intensity):
```

## picked_group_fdr/columns/tmt.py

```diff
@@ -5,15 +5,15 @@
 
 import numpy as np
 
 from .. import helpers
 from .base import ProteinGroupColumns
 
 # for type hints only
-from ..precursor_quant import PrecursorQuant
+from .. import precursor_quant
 from .. import results
 
 
 logger = logging.getLogger(__name__)
 
 
 class TMTIntensityColumns(ProteinGroupColumns):
@@ -51,15 +51,15 @@
                 post_err_prob_cutoff,
                 protein_group_results.num_tmt_channels,
             )
             pgr.extend(intensities)
 
 
 def _get_tmt_intensities(
-    precursor_list: List[PrecursorQuant],
+    precursor_list: List[precursor_quant.PrecursorQuant],
     experiment_to_idx_map: Dict[str, int],
     post_err_prob_cutoff: float,
     num_tmt_channels: int,
 ):
     intensities = [
         np.zeros(num_tmt_channels * 3) for i in range(len(experiment_to_idx_map))
     ]
```

## picked_group_fdr/columns/top_peptide.py

```diff
@@ -1,17 +1,17 @@
 from __future__ import annotations
 
-from typing import List, Dict
+from typing import List
 import logging
 
 from .. import helpers
 from .base import ProteinGroupColumns
 
 # for type hints only
-from ..precursor_quant import PrecursorQuant
+from .. import precursor_quant
 from .. import results
 
 logger = logging.getLogger(__name__)
 
 
 class TopPeptideProbabilityColumns(ProteinGroupColumns):
     def append_headers(
@@ -30,15 +30,15 @@
             top_peptide_probability = _top_peptide_probability(
                 pgr.precursorQuants
             )
             pgr.append("%.3f" % (top_peptide_probability, ))
 
 
 def _top_peptide_probability(
-    precursor_list: List[PrecursorQuant],
+    precursor_list: List[precursor_quant.PrecursorQuant],
 ) -> float:
     top_peptide_probability = 0.0
     for precursor in precursor_list:
         if (
             not helpers.is_mbr(precursor.post_err_prob) and
             1.0 - precursor.post_err_prob > top_peptide_probability
         ):
```

## picked_group_fdr/columns/triqler.py

```diff
@@ -10,15 +10,15 @@
 import triqler
 import triqler.parsers
 import triqler.hyperparameters
 import triqler.qvality
 import triqler.triqler
 
 from .. import helpers
-from ..parsers import parsers
+from ..parsers import parsers  # TODO: get rid of this import
 from .base import ProteinGroupColumns
 
 # for type hints only
 from .. import results
 
 logger = logging.getLogger(__name__)
```

## picked_group_fdr/competition.py

```diff
@@ -10,15 +10,17 @@
 from . import helpers
 
 # for type hints only
 from . import scoring_strategy
 from . import peptide_info
 
 
-def ProteinCompetitionStrategyFactory(method="picked_group"):
+def ProteinCompetitionStrategyFactory(
+    method="picked_group",
+) -> ProteinCompetitionStrategy:
     methods = {}
     methods["picked"] = PickedStrategy
     methods["picked_group"] = PickedGroupStrategy
     methods["classic"] = ClassicStrategy
     if method not in methods:
         raise ValueError(
             f"Unknown pickedStrategy {method['pickedStrategy']}, should be one of 'picked', 'picked_group' or 'classic'"
```

## picked_group_fdr/digest.py

```diff
@@ -542,34 +542,34 @@
         for protein in proteins:
             if protein not in seen_proteins:
                 seen_proteins.append(protein)
     return list(seen_proteins)
 
 
 def get_ibaq_peptide_to_protein_map(
-    fasta_files: List[str], digestion_params_list: List[DigestionParams]
+    fasta_files: List[str], digestion_params_list: List[DigestionParams], **kwargs
 ):
     digestion_params_list_ibaq = []
     for digestion_params in digestion_params_list:
         digestion_params.min_length = max([6, digestion_params.min_length])
         digestion_params.max_length = min([30, digestion_params.max_length])
         digestion_params.cleavages = 0
         digestion_params.methionine_cleavage = False
         digestion_params_list_ibaq.append(digestion_params)
     return get_peptide_to_protein_map_from_params(
-        fasta_files, digestion_params_list_ibaq
+        fasta_files, digestion_params_list_ibaq, **kwargs
     )
 
 
-def get_num_ibaq_peptides_per_protein_from_args(args, peptide_to_protein_maps):
+def get_num_ibaq_peptides_per_protein_from_args(args, peptide_to_protein_maps, **kwargs):
     digestion_params_list = get_digestion_params_list(args)
     if args.fasta:
         logger.info("In silico protein digest for iBAQ")
         num_ibaq_peptides_per_protein = get_num_ibaq_peptides_per_protein(
-            args.fasta, digestion_params_list
+            args.fasta, digestion_params_list, **kwargs
         )
     elif args.peptide_protein_map:
         logger.warning("Found peptide_protein_map (instead of fasta input): ")
         logger.warning(
             "- calculating iBAQ values using all peptides in peptide_protein_map."
         )
         logger.warning("- cannot compute sequence coverage.")
@@ -580,18 +580,18 @@
         raise ValueError(
             "No fasta or peptide to protein mapping file detected, please specify either the --fasta or --peptide_protein_map flags"
         )
     return num_ibaq_peptides_per_protein
 
 
 def get_num_ibaq_peptides_per_protein(
-    fasta_files: List[str], digestion_params_list: List[DigestionParams]
+    fasta_files: List[str], digestion_params_list: List[DigestionParams], **kwargs
 ) -> Dict[str, int]:
     peptide_to_protein_map_ibaq = get_ibaq_peptide_to_protein_map(
-        fasta_files, digestion_params_list
+        fasta_files, digestion_params_list, **kwargs
     )
     return get_num_peptides_per_protein(peptide_to_protein_map_ibaq)
 
 
 def get_num_peptides_per_protein(peptide_to_protein_map) -> Dict[str, int]:
     num_peptides_per_protein = collections.defaultdict(int)
     for _, proteins in peptide_to_protein_map.items():
```

## picked_group_fdr/entrapment.py

```diff
@@ -1,11 +1,11 @@
 from typing import List, Dict, Set
 import logging
 
-from .parsers import parsers
+from .parsers import protein_groups as pgp
 
 
 logger = logging.getLogger(__name__)
 
 
 def mark_entrapment_proteins(
     peptide_to_protein_map: Dict, mq_protein_groups_file: str
@@ -28,15 +28,15 @@
             peptide_to_protein_map[peptide] = mark_entrapment(
                 proteins, entrapment_proteins
             )
 
 
 def get_entrapment_proteins(mq_protein_groups_file: str) -> Set[str]:
     entrapment_proteins = set()
-    for protein_group, _ in parsers.parse_protein_groups_file_single(
+    for protein_group, _ in pgp.parse_protein_groups_file_single(
         mq_protein_groups_file
     ):
         for protein in protein_group:
             if "_entrapment" in protein:
                 entrapment_proteins.add(protein)
     return entrapment_proteins
```

## picked_group_fdr/grouping.py

```diff
@@ -17,14 +17,15 @@
 def ProteinGroupingStrategyFactory(method="rescued_subset"):
     methods = {}
     methods["no"] = NoGrouping
     methods["subset"] = SubsetGrouping
     methods["rescued_subset"] = RescuedSubsetGrouping
     methods["mq_native"] = MQNativeGrouping
     methods["rescued_mq_native"] = RescuedMQNativeGrouping
+    methods["pseudo_gene"] = PseudoGeneGrouping
     if method not in methods:
         raise ValueError(
             f"Unknown pickedStrategy {method['pickedStrategy']}, should be one of 'no', 'subset' or 'rescued_subset'"
         )
     return methods[method]()
```

## picked_group_fdr/methods.py

```diff
@@ -1,89 +1,126 @@
 import os
+from typing import List
 import toml
+from dataclasses import dataclass
 
-from picked_group_fdr import methods
-
-from .competition import ProteinCompetitionStrategyFactory
+from .competition import ProteinCompetitionStrategyFactory, ProteinCompetitionStrategy
 from .scoring_strategy import ProteinScoringStrategy
-from .grouping import ProteinGroupingStrategyFactory
+from .grouping import ProteinGroupingStrategyFactory, ProteinGroupingStrategy
 
 
-def get_methods(args):
-    """Get the picking, grouping and scoring strategy from toml files.
+@dataclass
+class MethodConfig:
+    picked_strategy: ProteinCompetitionStrategy
+    score_type: ProteinScoringStrategy
+    grouping_strategy: ProteinGroupingStrategy
+    label: str
+
+    def short_description(
+        self,
+        rescue_step: bool,
+        sep: str = "_",
+    ) -> str:
+        score_label = self.score_type.short_description()
+        grouping_label = self.grouping_strategy.short_description(rescue_step=rescue_step)
+        razor_label = self.score_type.short_description_razor()
+        fdr_label = self.picked_strategy.short_description()
+        return f"{score_label}{sep}{grouping_label}{sep}{razor_label}{sep}{fdr_label}"
+
+    def long_description(
+        self,
+        rescue_step: bool = True,
+        sep: str = ", ",
+    ) -> str:
+        score_label = self.score_type.long_description()
+        grouping_label = self.grouping_strategy.long_description(
+            rescue_step=rescue_step
+        )
+        razor_label = self.score_type.long_description_razor()
+        fdr_label = self.picked_strategy.long_description()
+        return f"{score_label}{sep}{grouping_label}{sep}{razor_label}{sep}{fdr_label}"
 
-    If no method is specified, use the picked protein group method, which was
-    the most sensitive well-calibrated method in a benchmark of methods.
 
-    pickedStrategy: PickedStrategy() = picked FDR
-                    ClassicStrategy() = classic FDR
+def get_methods(method_names: str, use_pseudo_genes: bool) -> List[MethodConfig]:
+    """Get the picking, grouping and scoring strategy from TOML files.
 
-    grouping:       MQNativeGrouping() = MaxQuant grouping from proteinGroups.txt
-                    SubsetGrouping() = Emulate protein grouping of MaxQuant based on evidence.txt
-                                       (currently does not work with simulated datasets since peptideToProteinMap does not contain entrapment labels)
-                    NoGrouping() = No protein grouping, each protein is in its own group
-                    +Rescued = Rescue protein groups by only considering peptides below 1% protein FDR threshold
+    If no method is specified, use the picked protein group method, which was
+    the most sensitive well-calibrated method in a benchmark of methods.
     """
     methods = ["picked_protein_group"]
-    if args.methods:
-        methods = args.methods.split(",")
+    if method_names:
+        methods = method_names.split(",")
 
-    return [parse_method_toml(method) for method in methods]
+    return [parse_method_toml(method, use_pseudo_genes) for method in methods]
 
 
-def parse_method_toml(method: str):
+def parse_method_toml(method_name: str, use_pseudo_genes: bool) -> MethodConfig:
+    """Parse a method configuration from a TOML file.
+
+    The function reads a TOML file containing the configuration of a method
+    used for protein group-level estimation. It retrieves parameters such as
+    the protein picking strategy, scoring type, grouping strategy, and label
+    for the method.
+
+    Picked Strategy Options:
+        - PickedStrategy(): Picked FDR
+        - ClassicStrategy(): Classic FDR
+
+    Grouping Options:
+        - MQNativeGrouping(): MaxQuant grouping from proteinGroups.txt
+        - SubsetGrouping(): Emulate protein grouping of MaxQuant based on evidence.txt
+                             (currently does not work with simulated datasets since
+                             peptideToProteinMap does not contain entrapment labels)
+        - NoGrouping(): No protein grouping, each protein is in its own group
+        - +Rescued: Rescue protein groups by only considering peptides below 1% protein FDR threshold
+
+    Args:
+        method_name (str): The name of the method or path to the TOML file containing the method configuration.
+        use_pseudo_genes (bool): Indicates whether pseudo genes should be used in grouping.
+
+    Raises:
+        FileNotFoundError: If the method TOML file cannot be found.
+
+    Returns:
+        dict: A dictionary containing the parsed method configuration parameters.
+            Keys:
+                - "pickedStrategy": The picked strategy instance.
+                - "scoreType": The scoring strategy instance.
+                - "grouping": The grouping strategy instance.
+                - "label": The label for the method.
+    """
     dir_path = os.path.dirname(os.path.realpath(__file__))
-    method_toml_file = os.path.join(dir_path, "methods", f"{method}.toml")
+    method_toml_file = os.path.join(dir_path, "methods", f"{method_name}.toml")
     if not os.path.isfile(method_toml_file):
-        if method.endswith(".toml") and os.path.isfile(method):
-            method_toml_file = method
+        if method_name.endswith(".toml") and os.path.isfile(method_name):
+            method_toml_file = method_name
         else:
             raise FileNotFoundError(
-                f"Could not find method {method}. Please ensure that it is one of the builtin methods or that it is a path to a TOML file with a .toml file extension."
+                f"Could not find method {method_name}. Please ensure that it is one of the builtin methods or that it is a path to a TOML file with a .toml file extension."
             )
 
-    method = toml.load(method_toml_file)
+    method_name = toml.load(method_toml_file)
+
+    if use_pseudo_genes:
+        method_name["grouping"] = "pseudo_gene"
 
-    picked_strategy = ProteinCompetitionStrategyFactory(method["pickedStrategy"])
-    score_type = method["scoreType"]
-    if method["sharedPeptides"] == "razor":
+    picked_strategy = ProteinCompetitionStrategyFactory(method_name["pickedStrategy"])
+    score_type = method_name["scoreType"]
+    if method_name["sharedPeptides"] == "razor":
         score_type += " razor"
     scoring_strategy = ProteinScoringStrategy(score_type)
-    grouping_strategy = ProteinGroupingStrategyFactory(method["grouping"])
+    grouping_strategy = ProteinGroupingStrategyFactory(method_name["grouping"])
 
-    return {
-        "pickedStrategy": picked_strategy,
-        "scoreType": scoring_strategy,
-        "grouping": grouping_strategy,
-        "label": method["label"],
-    }
-
-
-def short_description(
-    score_type, grouping_strategy, picked_strategy, rescue_step, sep="_"
-):
-    score_label = score_type.short_description()
-    grouping_label = grouping_strategy.short_description(rescue_step=rescue_step)
-    razor_label = score_type.short_description_razor()
-    fdr_label = picked_strategy.short_description()
-    return f"{score_label}{sep}{grouping_label}{sep}{razor_label}{sep}{fdr_label}"
-
-
-def long_description(
-    score_type, grouping_strategy, picked_strategy, rescue_step, sep=", "
-):
-    score_label = score_type.long_description()
-    grouping_label = grouping_strategy.long_description(rescue_step=rescue_step)
-    razor_label = score_type.long_description_razor()
-    fdr_label = picked_strategy.long_description()
-    return f"{score_label}{sep}{grouping_label}{sep}{razor_label}{sep}{fdr_label}"
-
-
-def get_method_description(config):
-    method_description_long = methods.long_description(
-        config["scoreType"],
-        config["grouping"],
-        config["pickedStrategy"],
-        rescue_step=True,
+    return MethodConfig(
+        picked_strategy, scoring_strategy, grouping_strategy, method_name["label"]
     )
-    label = config.get("label", "")
-    return label, method_description_long
+
+
+def requires_peptide_to_protein_map(method_configs: List[MethodConfig]) -> bool:
+    """Check if any configuration requires a peptide-to-protein map."""
+    for method_config in method_configs:
+        if (
+            method_config.grouping_strategy.needs_peptide_to_protein_map()
+            or method_config.score_type.remaps_peptides_to_proteins()
+        ):
+            return True
+    return False
```

## picked_group_fdr/parsers/fragpipe.py

```diff
@@ -1,15 +1,19 @@
 from __future__ import annotations
 
+from typing import List
 import logging
 
 from . import tsv
+from .. import writers
+from .. import helpers
 
 # for type hints only
 from .. import scoring_strategy
+from .. import results
 
 logger = logging.getLogger(__name__)
 
 """psm.tsv columns:
 1 Spectrum
 2 Spectrum File
 3 Peptide
@@ -47,15 +51,19 @@
 35 Protein Description
 36 Mapped Genes
 37 Mapped Proteins
 """
 
 
 def parse_fragpipe_psm_file(
-    reader, headers, get_proteins, score_type: scoring_strategy.ProteinScoringStrategy, **kwargs
+    reader,
+    headers,
+    get_proteins,
+    score_type: scoring_strategy.ProteinScoringStrategy,
+    **kwargs,
 ):
     pept_col = tsv.get_column_index(headers, "Peptide")
     score_col = tsv.get_column_index(
         headers, "SpectralSim"
     )  # could also use Hyperscore
     post_err_prob_col = tsv.get_column_index(headers, "PeptideProphet Probability")
     protein_col = tsv.get_column_index(headers, "Protein")
@@ -153,7 +161,66 @@
             proteins += row[other_proteins_col].split(", ")
 
         intensities = [
             (experiment, float(row[col_idx])) for col_idx, experiment in intensity_cols
         ]
 
         yield peptide, charge, assigned_mods, proteins, intensities
+
+
+def parse_fragpipe_combined_protein_file(
+    combined_protein_file: str, additional_headers: List[str] = None
+) -> results.ProteinGroupResults:
+    if additional_headers is None:
+        additional_headers = []
+
+    delimiter = "\t"
+    if combined_protein_file.endswith(".csv"):
+        delimiter = ","
+
+    reader = tsv.get_tsv_reader(combined_protein_file, delimiter)
+    headers = next(reader)
+
+    cols = {
+        x: headers.index(x)
+        for x in writers.PROTEIN_GROUP_HEADERS
+        + ["Protein group", "Protein Probability"]
+        + additional_headers
+        if x in headers
+    }
+
+    logger.info("Parsing FragPipe combined_protein_tsv file")
+    protein_group_results = []
+    for row in reader:
+        protein_group_results.append(
+            parse_fragpipe_combined_protein_file_row(row, cols, additional_headers)
+        )
+
+    protein_group_results = results.ProteinGroupResults(protein_group_results)
+    protein_group_results.append_headers(additional_headers)
+
+    return protein_group_results
+
+
+def parse_fragpipe_combined_protein_file_row(row, cols, additional_headers):
+    def _get_field(x, default_value=""):
+        return row[cols[x]] if x in cols else default_value
+
+    return results.ProteinGroupResult(
+        proteinIds=_get_field("Protein group"),
+        majorityProteinIds=_get_field("Majority protein IDs"),
+        peptideCountsUnique=_get_field(
+            "Peptide counts (unique)",
+            ";".join(["1"] * len(_get_field("Protein group").split(";"))),
+        ),
+        bestPeptide="",
+        numberOfProteins=int(_get_field("Number of proteins", -1)),
+        qValue=float(_get_field("Q-value", 0.0)),
+        score=float(_get_field("Score", _get_field("Protein Probability"))),
+        reverse=_get_field(
+            "Reverse",
+            "+" if helpers.is_decoy(_get_field("Protein group").split(";")) else "",
+        ),
+        potentialContaminant=_get_field("Potential contaminant"),
+        precursorQuants=[],
+        extraColumns=[_get_field(x) for x in additional_headers],
+    )
```

## picked_group_fdr/parsers/maxquant.py

```diff
@@ -1,27 +1,26 @@
 from __future__ import annotations
 
 from dataclasses import dataclass
 from enum import Enum
 import logging
 from typing import List
 
-from .parsers import tsv
-
 from . import tsv
 from .. import helpers
-from .. import results
-from .. import writers
+from .. import results  # TODO: get rid of this import
+from .. import writers  # TODO: get rid of this import
 
 # for type hints only
 from .. import scoring_strategy
 
 
 logger = logging.getLogger(__name__)
 
+
 def parse_mq_evidence_file(
     reader,
     headers,
     get_proteins,
     score_type: scoring_strategy.ProteinScoringStrategy,
     for_quantification: bool = False,
     **kwargs,
@@ -129,24 +128,24 @@
             silac_cols.append(
                 get_header_col("intensity h", required=for_quantification)
             )
     return silac_cols
 
 
 def parse_mq_protein_groups_file(
-    mqProteinGroupsFile: str, additional_headers: List[str] = None
+    mq_protein_groups_file: str, additional_headers: List[str] = None
 ) -> results.ProteinGroupResults:
     if additional_headers is None:
         additional_headers = []
 
     delimiter = "\t"
-    if mqProteinGroupsFile.endswith(".csv"):
+    if mq_protein_groups_file.endswith(".csv"):
         delimiter = ","
 
-    reader = tsv.get_tsv_reader(mqProteinGroupsFile, delimiter)
+    reader = tsv.get_tsv_reader(mq_protein_groups_file, delimiter)
     headers = next(reader)
 
     cols = {
         x: headers.index(x)
         for x in writers.PROTEIN_GROUP_HEADERS + additional_headers
         if x in headers
     }
```

## picked_group_fdr/parsers/parsers.py

```diff
@@ -3,67 +3,17 @@
 from pathlib import Path
 
 import numpy as np
 import pandas as pd
 
 from . import tsv
 
-
 logger = logging.getLogger(__name__)
 
 
-def parse_protein_groups_file_multiple(
-    protein_groups_files: List[str], are_decoy_file: List[bool], **kwargs
-):
-    for protein_groups_file, is_decoy_file in zip(protein_groups_files, are_decoy_file):
-        yield from parse_protein_groups_file_single(
-            protein_groups_file, is_decoy_file=is_decoy_file, **kwargs
-        )
-
-
-def parse_protein_groups_file_single(
-    protein_groups_file: str,
-    protein_column: str = "Protein IDs",
-    score_column: str = "Score",
-    is_decoy_file: bool = False,
-):
-    """Parse protein groups file from MaxQuant or ProteomeDiscoverer.
-
-    For PD with Chimerys, the column names are:
-    - protein_column="Accession"
-    - score_column="Score CHIMERY CHIMERYS"
-
-    Args:
-        protein_groups_file (_type_): _description_
-        protein_column (str, optional): _description_. Defaults to 'Protein IDs'.
-        score_column (str, optional): _description_. Defaults to 'Score'.
-        is_decoy_file (bool, optional): _description_. Defaults to False.
-
-    Yields:
-        _type_: _description_
-    """
-    delimiter = tsv.get_delimiter(protein_groups_file)
-
-    reader = tsv.get_tsv_reader(protein_groups_file, delimiter)
-    headers = next(reader)  # save the header
-
-    score_col = tsv.get_column_index(headers, score_column)
-    protein_col = tsv.get_column_index(headers, protein_column)
-
-    logger.info(f"Parsing proteinGroups file: {protein_groups_file}")
-    for row in reader:
-        proteins = list(map(str.strip, row[protein_col].split(";")))
-        if is_decoy_file:
-            proteins = [f"REV__{p}" for p in proteins]
-        score = -100.0
-        if len(row[score_col]) > 0:
-            score = float(row[score_col])
-        yield proteins, score
-
-
 def parse_peptides_files_multiple(
     peptides_files: List[str], are_decoy_file: List[bool], **kwargs
 ):
     for peptide_file, is_decoy_file in zip(peptides_files, are_decoy_file):
         yield from parse_peptides_file_single(
             peptide_file, is_decoy_file=is_decoy_file, **kwargs
         )
@@ -170,7 +120,9 @@
     # Extract file names without extensions
     df["Name"] = df["Name"].apply(lambda x: Path(x).stem)
     df["Experiment"] = df["Experiment"].fillna(df["Name"])
     df["Fraction"] = df["Fraction"].fillna(-1)
     df["Condition"] = df["Condition"].fillna(df["Experiment"])
 
     return df
+
+
```

## picked_group_fdr/parsers/psm.py

```diff
@@ -1,18 +1,18 @@
 from __future__ import annotations
 
 from typing import Callable, Dict, List, Optional
 import logging
 
-from .. import digest
+from .. import digest  # TODO: get rid of this import
 from .. import helpers
-from .. import scoring_strategy
-
 from . import tsv
 
+# for type hints only
+from .. import scoring_strategy
 
 logger = logging.getLogger(__name__)
 
 
 def get_peptide_to_protein_mapper(
     peptide_to_protein_map: digest.PeptideToProteinMap,
     score_type: scoring_strategy.ProteinScoringStrategy,
@@ -58,17 +58,14 @@
 def parse_evidence_file_single(
     evidence_file: str,
     peptide_to_protein_map: Dict,
     score_type: Optional[scoring_strategy.ProteinScoringStrategy],
     for_quantification: bool = False,
     suppress_missing_peptide_warning: bool = False,
 ):
-    if score_type is None:
-        score_type = scoring_strategy.ProteinScoringStrategy("bestPEP")
-
     delimiter = tsv.get_delimiter(evidence_file)
     reader = tsv.get_tsv_reader(evidence_file, delimiter)
     headers = next(reader)
 
     get_proteins = get_peptide_to_protein_mapper(
         peptide_to_protein_map, score_type, suppress_missing_peptide_warning
     )
@@ -81,14 +78,20 @@
 def parse_evidence_file_multiple(
     evidence_files: List[str],
     peptide_to_protein_maps: List[Dict],
     score_type: scoring_strategy.ProteinScoringStrategy,
     for_quantification: bool = False,
     suppress_missing_peptide_warning: bool = False,
 ):
+    if not score_type.remaps_peptides_to_proteins():
+        peptide_to_protein_maps = [None]
+
+    if len(peptide_to_protein_maps) == 1:
+        peptide_to_protein_maps = peptide_to_protein_maps * len(evidence_files)
+
     for evidence_file, peptide_to_protein_map in zip(
         evidence_files, peptide_to_protein_maps
     ):
         yield from parse_evidence_file_single(
             evidence_file,
             peptide_to_protein_map,
             score_type,
```

## picked_group_fdr/parsers/sage.py

```diff
@@ -3,14 +3,16 @@
 import logging
 from pathlib import Path
 from typing import Optional
 
 import numpy as np
 
 from . import tsv
+
+# for type hints only
 from .. import scoring_strategy
 
 logger = logging.getLogger(__name__)
 
 """https://sage-docs.vercel.app/docs/results/search
 
 results.sage.tsv columns:
```

## picked_group_fdr/picked_group_fdr.py

```diff
@@ -1,50 +1,51 @@
-from pathlib import Path
 import sys
 import os
 import logging
 import argparse
 from timeit import default_timer as timer
-from typing import Any, List, Dict, Tuple, Union
+from typing import List, Dict, Union
 
 import numpy as np
 
 from . import __version__, __copyright__
 from . import digest
 from . import protein_annotation
-from . import helpers
-from . import entrapment
+from . import peptide_protein_map
 from . import methods
 from . import fdr
+from .parsers import evidence
 from . import writers
 from . import quantification
 from .digestion_params import (
     add_digestion_arguments,
-    get_digestion_params_list,
-    DigestionParams,
 )
-from .parsers import psm
-from .parsers import parsers
-from .protein_groups import ProteinGroups
-from .grouping import PseudoGeneGrouping
 from .results import ProteinGroupResults
 from .plotter import PlotterFactory
 from .peptide_info import PeptideInfoList
 
 # for type hints only
-from .scoring_strategy import ProteinScoringStrategy
-from .grouping import ProteinGroupingStrategy
-from .competition import ProteinCompetitionStrategy
 from .plotter import Plotter, NoPlotter
 
 logger = logging.getLogger(__name__)
 
 GREETER = f"PickedGroupFDR version {__version__}\n{__copyright__}"
 
 
+def main(argv: List[str]) -> None:
+    """Main function."""
+    logger.info(GREETER)
+    logger.info(
+        f'Issued command: {os.path.basename(__file__)} {" ".join(map(str, argv))}'
+    )
+
+    args = parse_args(argv)
+    run_picked_group_fdr(args)
+
+
 class ArgumentParserWithLogger(argparse.ArgumentParser):
     def error(self, message):
         logger.error(f"Error parsing input arguments: {message}")
         super().error(message)
 
 
 def parse_args(argv):
@@ -78,14 +79,15 @@
                 --mq_evidence.""",
     )
 
     apars.add_argument(
         "--combined_ion",
         default=None,
         metavar="I",
+        nargs="+",
         help="""Path to combined_ion.tsv produced by IonQuant/FragPipe. This enables
                 quantification of protein groups by PickedGroupFDR.""",
     )
 
     apars.add_argument(
         "--sage_results",
         default=None,
@@ -95,15 +97,16 @@
                 --mq_evidence.""",
     )
 
     apars.add_argument(
         "--sage_lfq_tsv",
         default=None,
         metavar="I",
-        help="""Path to lfq.tsv produced by Sage. This enables
+        nargs="+",
+        help="""Path to lfq.tsv file(s) produced by Sage. This enables
                 quantification of protein groups by PickedGroupFDR.""",
     )
 
     apars.add_argument(
         "--protein_groups_out",
         default=None,
         metavar="PG",
@@ -111,17 +114,17 @@
     )
 
     apars.add_argument(
         "--output_format",
         default="auto",
         metavar="PG",
         help="""Protein groups output format. Options are "auto", "maxquant" and 
-                "fragpipe". "auto": decide based on input file format, will default to 
-                "maxquant" if no suitable format is known; "maxquant" (proteinGroups.txt
-                format) and "fragpipe" (combined_protein.tsv format).""",
+                "fragpipe". "auto": decide based on input file format, uses
+                "maxquant" if no suitable format is known; "maxquant": proteinGroups.txt
+                format; "fragpipe": combined_protein.tsv format.""",
     )
 
     apars.add_argument(
         "--fasta",
         default=None,
         metavar="F",
         nargs="+",
@@ -150,15 +153,15 @@
     )
 
     apars.add_argument(
         "--peptide_protein_map",
         default=None,
         metavar="M",
         nargs="+",
-        help="""File with mapping from peptides to proteins; alternative for 
+        help="""Tab-separated file with mapping from peptides to proteins; alternative for 
                 --fasta flag if digestion is time consuming.""",
     )
 
     apars.add_argument(
         "--keep_all_proteins",
         default=None,
         help="""Keep proteins that do not have peptides below the PSM FDR filter.""",
@@ -202,183 +205,134 @@
 
     # ------------------------------------------------
     args = apars.parse_args(argv)
 
     return args
 
 
-def main(argv) -> None:
-    logger.info(GREETER)
-    logger.info(
-        f'Issued command: {os.path.basename(__file__)} {" ".join(map(str, argv))}'
-    )
-
-    args = parse_args(argv)
-
+def run_picked_group_fdr(args: argparse.Namespace) -> None:
+    """Run PickedGroupFDR algorithm."""
     start = timer()
 
     # set seed for random shuffling of protein groups, see competition.do_competition()
     np.random.seed(1)
 
-    configs = methods.get_methods(args)
-    plotter = PlotterFactory.get_plotter(args.figure_base_fn, args.plot_figures)
     protein_annotations, use_pseudo_genes = protein_annotation.get_protein_annotations(
         args.fasta, args.fasta_contains_decoys, args.gene_level
     )
+    method_configs = methods.get_methods(args.methods, use_pseudo_genes)
 
-    if use_pseudo_genes:
-        for config in configs:
-            config["grouping"] = PseudoGeneGrouping()
-
-    peptide_to_protein_maps = get_peptide_to_protein_maps_if_needed(
-        args, configs, use_pseudo_genes
-    )
-    for config in configs:
-        label, method_description_long = methods.get_method_description(config)
-        logger.info(
-            f"Protein group level estimation method: {label} ({method_description_long})"
+    peptide_to_protein_maps = [None]
+    if methods.requires_peptide_to_protein_map(method_configs):
+        peptide_to_protein_maps = peptide_protein_map.get_peptide_to_protein_maps_from_args(
+            args, use_pseudo_genes
         )
 
-        evidence_files = config["scoreType"].get_evidence_file(args)
-        if not evidence_files:
-            logger.warning(
-                (
-                    f'No evidence input file found, skipping method "{label}". Check '
-                    "if an appropriate method was specified by the --methods flag."
-                )
-            )
-            continue
-
-        peptide_info_list = parse_evidence_files(
-            evidence_files,
+    plotter = PlotterFactory.get_plotter(args.figure_base_fn, args.plot_figures)
+    for method_config in method_configs:
+        run_method(
+            args,
+            method_config,
             peptide_to_protein_maps,
-            config["scoreType"],
-            args.suppress_missing_peptide_warning,
-        )
-
-        plotter.set_series_label_base(config.get("label", None))
-        protein_group_results = get_protein_group_results(
-            peptide_info_list,
-            args.mq_protein_groups,
-            config["pickedStrategy"],
-            config["scoreType"],
-            config["grouping"],
+            protein_annotations,
             plotter,
-            args.keep_all_proteins,
+            use_pseudo_genes,
+            apply_filename_suffix=len(method_configs) > 1,
         )
 
-        protein_groups_writer = writers.MinimalProteinGroupsWriter(protein_annotations)
-        post_err_probs = None
-        if args.do_quant:
-            (
-                protein_group_results,
-                protein_groups_writer,
-                post_err_probs,
-            ) = do_quantification(
-                config["scoreType"],
-                args,
-                protein_group_results,
-                protein_annotations,
-                use_pseudo_genes,
-                peptide_to_protein_maps,
-            )
-
-        protein_groups_writer.append_quant_columns(
-            protein_group_results, post_err_probs, args.psm_fdr_cutoff
-        )
-
-        if args.protein_groups_out:
-            write_protein_groups(
-                protein_groups_writer,
-                protein_group_results,
-                args.protein_groups_out,
-                config,
-                apply_suffix=len(configs) > 1,
-            )
-
     end = timer()
     logger.info(
         f"PickedGroupFDR execution took {'%.1f' % (end - start)} seconds wall clock time"
     )
 
     plotter.decorate_plots()
     plotter.save_plots()
     plotter.show()
 
 
-def get_peptide_to_protein_maps_if_needed(
+def run_method(
     args: argparse.Namespace,
-    configs: Dict[str, Any],
+    method_config: methods.MethodConfig,
+    peptide_to_protein_maps: List[digest.PeptideToProteinMap],
+    protein_annotations: Dict[str, protein_annotation.ProteinAnnotation],
+    plotter: Plotter,
     use_pseudo_genes: bool,
-) -> List[digest.PeptideToProteinMap]:
-    parse_id = digest.parse_until_first_space
-    if args.gene_level and not use_pseudo_genes:
-        parse_id = protein_annotation.parse_gene_name_func
-
-    for config in configs:
-        if (
-            config["grouping"].needs_peptide_to_protein_map()
-            or config["scoreType"].remaps_peptides_to_proteins()
-        ):
-            digestion_params_list = get_digestion_params_list(args)
-            return get_peptide_to_protein_maps(
-                args.fasta,
-                args.peptide_protein_map,
-                digestion_params_list,
-                args.mq_protein_groups,
-                parse_id=parse_id,
-            )
-    return list()
-
+    apply_filename_suffix: bool,
+) -> None:
+    logger.info(
+        f"Protein group level estimation method: {method_config.label} ({method_config.long_description()})"
+    )
 
-def get_peptide_to_protein_maps(
-    fasta_file: str,
-    peptide_protein_map_file: str,
-    digestion_params_list: List[DigestionParams],
-    mq_protein_groups_file: str,
-    **kwargs,
-):
-    peptide_to_protein_maps = list()
-    if fasta_file:
-        for digestion_params in digestion_params_list:
-            peptide_to_protein_maps.append(
-                digest.get_peptide_to_protein_map_from_params(
-                    fasta_file, [digestion_params], **kwargs
-                )
-            )
-            entrapment.mark_entrapment_proteins(
-                peptide_to_protein_maps[-1], mq_protein_groups_file
-            )
-    elif peptide_protein_map_file:
-        logger.info("Loading peptide to protein map")
-        for peptide_protein_map_file in peptide_protein_map_file:
-            peptide_to_protein_maps.append(
-                digest.get_peptide_to_protein_map_from_file(
-                    peptide_protein_map_file, use_hash_key=False
-                )
-            )
-    else:
-        raise ValueError(
+    evidence_files = method_config.score_type.get_evidence_file(args)
+    if not evidence_files:
+        logger.warning(
             (
-                "No fasta or peptide to protein mapping file detected, please"
-                "specify either the --fasta or --peptide_protein_map flags."
+                f'No evidence input file found, skipping method "{method_config.label}". Check '
+                "if an appropriate method was specified by the --methods flag."
             )
         )
-    return peptide_to_protein_maps
+        return
+
+    peptide_info_list = evidence.parse_evidence_files(
+        evidence_files,
+        peptide_to_protein_maps,
+        method_config.score_type,
+        args.suppress_missing_peptide_warning,
+    )
+
+    plotter.set_series_label_base(method_config.label)
+    protein_group_results = get_protein_group_results(
+        peptide_info_list,
+        args.mq_protein_groups,
+        method_config,
+        plotter,
+        args.keep_all_proteins,
+    )
+
+    protein_groups_writer = writers.MinimalProteinGroupsWriter(protein_annotations)
+    post_err_probs = None
+    if args.do_quant:
+        (
+            protein_group_results,
+            protein_groups_writer,
+            post_err_probs,
+        ) = quantification.do_quantification(
+            method_config.score_type,
+            args,
+            protein_group_results,
+            protein_annotations,
+            use_pseudo_genes,
+            peptide_to_protein_maps,
+            args.suppress_missing_peptide_warning,
+        )
+
+    writers.finalize_output(
+        protein_group_results,
+        protein_groups_writer,
+        post_err_probs,
+        args.protein_groups_out,
+        args.psm_fdr_cutoff,
+        apply_filename_suffix,
+        method_config,
+    )
 
 
 def get_protein_group_results(
     peptide_info_list: PeptideInfoList,
     mq_protein_groups_file: str,
-    picked_strategy: ProteinCompetitionStrategy,
-    score_type: ProteinScoringStrategy,
-    grouping_strategy: ProteinGroupingStrategy,
+    method_config: methods.MethodConfig,
     plotter: Union[Plotter, NoPlotter],
     keep_all_proteins: bool,
 ) -> ProteinGroupResults:
+    picked_strategy, score_type, grouping_strategy = (
+        method_config.picked_strategy,
+        method_config.score_type,
+        method_config.grouping_strategy,
+    )
+
     protein_groups = grouping_strategy.group_proteins(
         peptide_info_list, mq_protein_groups_file
     )
 
     # for razor peptide strategy
     score_type.set_peptide_counts_per_protein(peptide_info_list)
 
@@ -432,123 +386,17 @@
             picked_protein_group_peptide_infos,
             protein_scores,
             reported_qvals,
             peptide_score_cutoff,
             keep_all_proteins,
         )
 
-    plotter.set_series_label(
-        score_type, grouping_strategy, picked_strategy, rescue_step=rescue_step
-    )
+    plotter.set_series_label(method_config, rescue_step=rescue_step)
     plotter.plot_qval_calibration_and_performance(
         reported_qvals, observed_qvals, absent_ratio=1.0
     )
 
     return protein_group_results
 
 
-def parse_evidence_files(
-    evidence_files: List[str],
-    peptide_to_protein_maps: List[digest.PeptideToProteinMap],
-    score_type: ProteinScoringStrategy,
-    suppress_missing_peptide_warning: bool,
-) -> PeptideInfoList:
-    """Returns best score per peptide"""
-    if not score_type.remaps_peptides_to_proteins():
-        peptide_to_protein_maps = [None]
-
-    if len(peptide_to_protein_maps) == 1:
-        peptide_to_protein_maps = peptide_to_protein_maps * len(evidence_files)
-
-    peptide_info_list = dict()
-    for peptide, proteins, _, score in psm.parse_evidence_file_multiple(
-        evidence_files,
-        peptide_to_protein_maps=peptide_to_protein_maps,
-        score_type=score_type,
-        suppress_missing_peptide_warning=suppress_missing_peptide_warning,
-    ):
-        peptide = helpers.clean_peptide(peptide)
-        if np.isnan(score) or score >= peptide_info_list.get(peptide, [np.inf])[0]:
-            continue
-
-        peptide_info_list[peptide] = [score, proteins]
-
-    return peptide_info_list
-
-
-def do_quantification(
-    score_type: ProteinScoringStrategy,
-    args: argparse.Namespace,
-    protein_group_results: ProteinGroupResults,
-    protein_annotations: Dict[str, protein_annotation.ProteinAnnotation],
-    use_pseudo_genes: bool,
-    peptide_to_protein_maps: List[digest.PeptideToProteinMap],
-) -> Tuple[ProteinGroupResults, writers.ProteinGroupsWriter, List]:
-    if not score_type.can_do_quantification():
-        logger.warning(
-            "Skipping quantification: need input file with precursor quantifications."
-        )
-        return protein_group_results
-
-    logger.info("Preparing for quantification")
-
-    score_origin = score_type.score_origin.long_description().lower()
-    if args.output_format == "auto" and score_origin in ["maxquant", "fragpipe"]:
-        args.output_format = score_origin
-
-    parse_id = digest.parse_until_first_space
-    if args.gene_level and not use_pseudo_genes:
-        parse_id = protein_annotation.parse_gene_name_func
-
-    protein_groups_writer = writers.get_protein_groups_output_writer(
-        protein_group_results,
-        args.output_format,
-        args,
-        protein_annotations,
-        parse_id,
-        peptide_to_protein_maps,
-    )
-
-    discard_shared_peptides = True
-
-    protein_groups = ProteinGroups.from_protein_group_results(protein_group_results)
-    experimental_design = quantification.get_experimental_design(args)
-
-    protein_group_results, post_err_probs = score_type.get_quantification_parser()(
-        score_type.get_evidence_file(args),
-        score_type.get_quantification_file(args),
-        protein_groups,
-        protein_group_results,
-        peptide_to_protein_maps,
-        experimental_design,
-        discard_shared_peptides,
-    )
-
-    return protein_group_results, protein_groups_writer, post_err_probs
-
-
-def write_protein_groups(
-    protein_groups_writer: writers.ProteinGroupsWriter,
-    protein_group_results: ProteinGroupResults,
-    protein_groups_out: str,
-    config: Dict[str, Any],
-    apply_suffix: bool,
-) -> None:
-    if apply_suffix:
-        base, ext = os.path.splitext(protein_groups_out)
-        label = config.get("label", None)
-        if label is None:
-            label = methods.short_description(
-                config["scoreType"], config["grouping"], config["pickedStrategy"], True
-            )
-        else:
-            label = label.lower().replace(" ", "_")
-        protein_groups_out = f"{base}_{label}{ext}"
-
-    Path(protein_groups_out).parent.mkdir(parents=True, exist_ok=True)
-
-    protein_groups_writer.write(protein_group_results, protein_groups_out)
-    logger.info(f"Protein group results have been written to: {protein_groups_out}")
-
-
 if __name__ == "__main__":
     main(sys.argv[1:])
```

## picked_group_fdr/pipeline/andromeda2pin.py

```diff
@@ -1,12 +1,12 @@
 #!/usr/bin/python
 
-'''
+"""
 Converts Andromeda evidence.txt output to tab delimited percolator input file
-'''
+"""
 
 import sys
 import os
 import logging
 from typing import List
 
 import numpy as np
@@ -21,119 +21,190 @@
 
 # hacky way to get package logger when running as module
 logger = logging.getLogger(__package__ + "." + __file__)
 
 
 # TODO allow mqpar.xml as input
 def main(argv):
-    logger.info(f'Andromeda2Pin version {__version__}\n{__copyright__}')
-    logger.info(f'Issued command: {os.path.basename(__file__)} {" ".join(map(str, argv))}')
-    
+    logger.info(f"Andromeda2Pin version {__version__}\n{__copyright__}")
+    logger.info(
+        f'Issued command: {os.path.basename(__file__)} {" ".join(map(str, argv))}'
+    )
+
     args = parseArgs(argv)
-    
-    andromedaTargetOutFNs = getMqEvidenceFiles(args.mq_evidence_file)        
-    
+
+    andromedaTargetOutFNs = getMqEvidenceFiles(args.mq_evidence_file)
+
     percInFN = args.outputTab
     decoyPattern = args.pattern
-    #numHits = args.matches
+    # numHits = args.matches
     numHits = 1
-    
+
     if len(percInFN) > 0:
         if os.path.isfile(percInFN):
-            logger.info(f"Found output file {percInFN}, remove this file to re-run andromeda2pin.")
+            logger.info(
+                f"Found output file {percInFN}, remove this file to re-run andromeda2pin."
+            )
             return
         logger.info(f"Writing results to: {percInFN}")
         writer = tsv.get_tsv_writer(percInFN + ".tmp")
     else:
         logger.info("Writing results to stdout")
         writer = tsv.get_tsv_writer(sys.stdout)
 
     digestion_params_list = get_digestion_params_list(args)
-    
-    charges = list(range(2,7))
+
+    charges = list(range(2, 7))
     writeHeaders(writer, charges)
-    
-    for andromedaTargetOutFN, digestion_params in zip(andromedaTargetOutFNs, digestion_params_list):
-        peptideToProteinMap = digest.get_peptide_to_protein_map_from_params(args.databases, [digestion_params])
-        convertAndromedaOutToPin(andromedaTargetOutFN, writer, charges, numHits, peptideToProteinMap, decoyPattern = decoyPattern)
-    
+
+    for andromedaTargetOutFN, digestion_params in zip(
+        andromedaTargetOutFNs, digestion_params_list
+    ):
+        peptideToProteinMap = digest.get_peptide_to_protein_map_from_params(
+            args.databases, [digestion_params]
+        )
+        convertAndromedaOutToPin(
+            andromedaTargetOutFN,
+            writer,
+            charges,
+            numHits,
+            peptideToProteinMap,
+            args.suppress_missing_peptide_warning,
+            decoyPattern=decoyPattern,
+        )
+
     if len(percInFN) > 0:
         os.rename(percInFN + ".tmp", percInFN)
     logger.info("Finished writing percolator input")
 
 
 def parseArgs(argv):
     import argparse
+
     apars = ArgumentParserWithLogger(
-            formatter_class=argparse.ArgumentDefaultsHelpFormatter)
-    
-    apars.add_argument('mq_evidence_file', default=None, nargs='+', metavar = "evidence.txt",
-     help='''MaxQuant evidence file(s), or a meta file. If you want to combine 
+        formatter_class=argparse.ArgumentDefaultsHelpFormatter
+    )
+
+    apars.add_argument(
+        "mq_evidence_file",
+        default=None,
+        nargs="+",
+        metavar="evidence.txt",
+        help="""MaxQuant evidence file(s), or a meta file. If you want to combine 
              multiple evidence files, use spaces to separate the file paths or
              use a meta file. Meta files are text files containing the paths of 
              evidence files, one path per line.
-             ''')
-                                                    
-    apars.add_argument('-o', '--outputTab', default = None, metavar='pin.tab', 
-                                         help='''Save output in a tab delimited file
-                                                    ''')
-    
-    #apars.add_argument('-m', '--matches', default = 1, metavar='M', type=int, 
-    #                                     help='''Maximal number of matches to take in consideration 
-    #                                                     per spectrum
-    #                                                ''')
-    apars.add_argument('-P', '--pattern', default = "REV__", metavar='P',
-                                         help='''Pattern used to identify the decoy PSMs.
-                                                    ''')
-    
-    apars.add_argument('-F', '--databases', default = None, metavar='F', nargs = "+",
-                                         help='''Fasta database used in the search 
-                                                         against the spectra file.
-                                                    ''')
-    
+             """,
+    )
+
+    apars.add_argument(
+        "-o",
+        "--outputTab",
+        default=None,
+        metavar="pin.tab",
+        help="""Save output in a tab delimited file""",
+    )
+
+    # apars.add_argument(
+    #     "-m",
+    #     "--matches",
+    #     default=1,
+    #     metavar="M",
+    #     type=int,
+    #     help="""Maximal number of matches to take in consideration per spectrum.""",
+    # )
+
+    apars.add_argument(
+        "-P",
+        "--pattern",
+        default="REV__",
+        metavar="P",
+        help="""Pattern used to identify the decoy PSMs.""",
+    )
+
+    apars.add_argument(
+        "-F",
+        "--databases",
+        default=None,
+        metavar="F",
+        nargs="+",
+        help="""Fasta database used in the search against the spectra file.""",
+    )
+
+    apars.add_argument(
+        "--suppress_missing_peptide_warning",
+        help="Suppress missing peptide warning when mapping peptides to proteins.",
+        action="store_true",
+    )
+
     add_digestion_arguments(apars)
-                                                    
+
     # ------------------------------------------------
     args = apars.parse_args(argv)
-    
+
     return args
 
 
 def isMqEvidenceHeader(header: str, delimiter: str):
     """Check if header looks like it comes from an MaxQuant evidence file.
-    
-    If there are at least 5 columns and contains the word "sequence", we can safely 
+
+    If there are at least 5 columns and contains the word "sequence", we can safely
     assume this is a MQ evidence file and not a metafile.
     """
     return header.count(delimiter) > 4 and "sequence" in header.lower()
 
 
 def getMqEvidenceFiles(mq_evidence_files: List[str]):
     andromedaTargetOutFNs = []
     delimiter = tsv.get_delimiter(mq_evidence_files[0])
-    with open(mq_evidence_files[0], 'r') as f:
+    with open(mq_evidence_files[0], "r") as f:
         firstLine = True
         for line in f:
             if firstLine:
                 if isMqEvidenceHeader(line, delimiter):
                     andromedaTargetOutFNs = mq_evidence_files
                     break
                 else:
-                    logger.info("Meta file detected, interpreting each line as a path to an evidence file")
+                    logger.info(
+                        "Meta file detected, interpreting each line as a path to an evidence file"
+                    )
             andromedaTargetOutFNs.append(line.rstrip())
             firstLine = False
     return andromedaTargetOutFNs
 
 
 def writeHeaders(writer, charges):
-    writer.writerow(["SpecId", "Label", "FileName", "ScanNr", "ExpMass", "AndromedaScore", "DeltaScore", "PepLen"] + ["Charge" + str(i) for i in charges] + ["Mass", "enzN", "enzC", "enzInt", "numMods", "dM", "absdM", "Peptide", "Proteins"])
-    #writer.writerow(["DefaultDirection", "-", "-", "-", "-", 1, 0.5, 0] + [0 for i in charges] + [0, 0, 0, -1.5, -2, 0, -1])
+    writer.writerow(
+        [
+            "SpecId",
+            "Label",
+            "FileName",
+            "ScanNr",
+            "ExpMass",
+            "AndromedaScore",
+            "DeltaScore",
+            "PepLen",
+        ]
+        + ["Charge" + str(i) for i in charges]
+        + [
+            "Mass",
+            "enzN",
+            "enzC",
+            "enzInt",
+            "numMods",
+            "dM",
+            "absdM",
+            "Peptide",
+            "Proteins",
+        ]
+    )
+    # writer.writerow(["DefaultDirection", "-", "-", "-", "-", 1, 0.5, 0] + [0 for i in charges] + [0, 0, 0, -1.5, -2, 0, -1])
 
 
-def parseMqEvidenceFile(mqEvidenceFile, razor = False):
+def parseMqEvidenceFile(mqEvidenceFile, razor=False):
     """
     Columns needed (all headers are converted to lower case for the comparison, so no need to fix that):
     - Modified sequence
     - MS/MS Scan number
     - Raw file
     - Charge
     - Mass
@@ -141,141 +212,213 @@
     - One out of: Leading proteins / Proteins
     - Score
     - Delta score
     - Experiment (optional)
     """
     delimiter = tsv.get_delimiter(mqEvidenceFile)
     reader = tsv.get_tsv_reader(mqEvidenceFile, delimiter)
-    headers = next(reader) # save the header
-    headers = list(map(lambda x : x.lower(), headers))
-    
-    # People often provide custom evidence files generated by R which replaces spaces 
+    headers = next(reader)  # save the header
+    headers = list(map(lambda x: x.lower(), headers))
+
+    # People often provide custom evidence files generated by R which replaces spaces
     # with periods, undo that here
-    if mqEvidenceFile.endswith('.csv'):
+    if mqEvidenceFile.endswith(".csv"):
         headers = [x.replace(".", " ") for x in headers]
-    
-    peptCol = headers.index('modified sequence')
-    idCol = headers.index('ms/ms scan number')
-    fileCol = headers.index('raw file')
-    chargeCol = headers.index('charge')
-    massCol = headers.index('mass')
-    
+
+    peptCol = headers.index("modified sequence")
+    idCol = headers.index("ms/ms scan number")
+    fileCol = headers.index("raw file")
+    chargeCol = headers.index("charge")
+    massCol = headers.index("mass")
+
     deltaMassCol = -1
-    if 'mass error [ppm]' in headers:
-        deltaMassCol = headers.index('mass error [ppm]')
+    if "mass error [ppm]" in headers:
+        deltaMassCol = headers.index("mass error [ppm]")
 
-    if 'leading proteins' in headers:
-        proteinCol = headers.index('leading proteins') # all proteins the peptide matches to, does not return REV__ proteins
+    if "leading proteins" in headers:
+        proteinCol = headers.index(
+            "leading proteins"
+        )  # all proteins the peptide matches to, does not return REV__ proteins
     else:
-        proteinCol = headers.index('proteins')
-    scoreCol = headers.index('score')
-    deltaScoreCol = headers.index('delta score')
+        proteinCol = headers.index("proteins")
+    scoreCol = headers.index("score")
+    deltaScoreCol = headers.index("delta score")
 
     experimentCol = -1
-    if 'experiment' in headers:
-        experimentCol = headers.index('experiment')        
-    
+    if "experiment" in headers:
+        experimentCol = headers.index("experiment")
+
     logger.info("Parsing MaxQuant evidence.txt file")
     for lineIdx, row in enumerate(reader):
         if lineIdx % 500000 == 0:
             logger.info(f"    Reading line {lineIdx}")
-        
+
         if len(row[idCol]) == 0:
             continue
-        
+
         scanNr = int(row[idCol])
         charge = int(row[chargeCol])
         fileName = row[fileCol]
-        peptide = "-." + row[peptCol][1:-1].replace('pS', 'S[80]').replace('pT', 'T[80]').replace('pY', 'Y[80]').replace('(ph)', '[80]').replace('(ox)', '[16]').replace('(ac)', '[42]').replace('(Acetyl (Protein N-term))', '[42]').replace('(Oxidation (M))', '[16]') + ".-"
+        peptide = (
+            "-."
+            + row[peptCol][1:-1]
+            .replace("pS", "S[80]")
+            .replace("pT", "T[80]")
+            .replace("pY", "Y[80]")
+            .replace("(ph)", "[80]")
+            .replace("(ox)", "[16]")
+            .replace("(ac)", "[42]")
+            .replace("(Acetyl (Protein N-term))", "[42]")
+            .replace("(Oxidation (M))", "[16]")
+            + ".-"
+        )
         proteins = row[proteinCol].split(";")
         if experimentCol >= 0:
             experiment = row[experimentCol]
         else:
             experiment = "Experiment1"
 
         score = float(row[scoreCol])
         deltaScore = float(row[deltaScoreCol])
         mass = float(row[massCol])
         deltaMass = float(row[deltaMassCol])
-        
+
         if np.isnan(deltaMass):
             deltaMass = 0.0
-        
+
         if not np.isnan(score) and score > 0.0:
             yield scanNr, charge, fileName, peptide, proteins, experiment, score, deltaScore, mass, deltaMass
 
 
-def convertAndromedaOutToPin(andromedaOutFN, writer, charges, numHits, peptideToProteinMap, decoyPattern = ""):
+def convertAndromedaOutToPin(
+    andromedaOutFN,
+    writer,
+    charges,
+    numHits,
+    peptideToProteinMap,
+    suppress_missing_peptide_warning,
+    decoyPattern="",
+):
     logger.info(f"Reading {andromedaOutFN}")
-    
-    for scanNr, charge, fileName, peptide, tmp_proteins, experiment, andromedaScore, deltaScore, expMass, deltaMass in parseMqEvidenceFile(andromedaOutFN):
+
+    for (
+        scanNr,
+        charge,
+        fileName,
+        peptide,
+        tmp_proteins,
+        experiment,
+        andromedaScore,
+        deltaScore,
+        expMass,
+        deltaMass,
+    ) in parseMqEvidenceFile(andromedaOutFN):
         rank = 1
         psmId = fileName + "_" + str(scanNr) + "_" + str(charge) + "_" + str(rank)
-        modPeptide, cleanPeptide, pepLen, enzN, enzC, enzInt, numMods = getPeptideStats(peptide, deltaMass)
+        modPeptide, cleanPeptide, pepLen, enzN, enzC, enzInt, numMods = getPeptideStats(
+            peptide, deltaMass
+        )
         absDeltaMass = abs(deltaMass)
-        
+
         if pepLen < 6:
             continue
 
         if len(peptideToProteinMap) > 0:
             proteins = digest.get_proteins(peptideToProteinMap, cleanPeptide[2:-2])
             if len(proteins) == 0:
-                if not helpers.is_contaminant(tmp_proteins):
-                    logger.warning(f"Could not find peptide {peptide} ({str(tmp_proteins)}) in fasta database, skipping PSM")
+                if (
+                    not helpers.is_contaminant(tmp_proteins)
+                    and not suppress_missing_peptide_warning
+                ):
+                    logger.warning(
+                        f"Could not find peptide {peptide} ({str(tmp_proteins)}) in fasta database, skipping PSM"
+                    )
                 continue
-        
+
         if len(decoyPattern) > 0:
             if sum(1 for p in proteins if p.startswith(decoyPattern)) == len(proteins):
                 label = -1
             else:
                 label = 1
-        
-        r = [psmId, label, fileName, scanNr, expMass, andromedaScore, deltaScore, pepLen] + [1 if charge == i else 0 for i in charges] + [expMass, enzN, enzC, enzInt, numMods, deltaMass, absDeltaMass, modPeptide] + proteins
+
+        r = (
+            [
+                psmId,
+                label,
+                fileName,
+                scanNr,
+                expMass,
+                andromedaScore,
+                deltaScore,
+                pepLen,
+            ]
+            + [1 if charge == i else 0 for i in charges]
+            + [
+                expMass,
+                enzN,
+                enzC,
+                enzInt,
+                numMods,
+                deltaMass,
+                absDeltaMass,
+                modPeptide,
+            ]
+            + proteins
+        )
         writer.writerow(r)
 
-def getPeptideStats(peptide, deltaMass, accurateModMasses = False):
+
+def getPeptideStats(peptide, deltaMass, accurateModMasses=False):
     cleanPeptide = peptide[:2]
     modPeptide = peptide[:2]
     numMods, enzInt = 0, 0
     aaIdx = 2
     while aaIdx < len(peptide):
         if peptide[aaIdx] == "[":
             modStart = aaIdx
-            while peptide[aaIdx+1].isdigit():
+            while peptide[aaIdx + 1].isdigit():
                 aaIdx += 1
             mod = "["
-            
+
             multFactor = 1
             if peptide[modStart] == "-":
                 multFactor = -1
-            modMass = multFactor * float(peptide[modStart+1:aaIdx+1])
-                    
+            modMass = multFactor * float(peptide[modStart + 1 : aaIdx + 1])
+
             # modification masses are typically not integers, add the deltamass to the first mod to ensure calcmass = expmass
             if accurateModMasses and numMods == 0:
                 modMass += deltaMass
                 mod += str(round(modMass, 4))
             else:
                 mod += str(int(modMass))
-            
+
             mod += "]"
             aaIdx += 1
             modPeptide += mod
             numMods += 1
         elif peptide[aaIdx] == ".":
             modPeptide += peptide[aaIdx:]
             cleanPeptide += peptide[aaIdx:]
             break
         else:
             modPeptide += peptide[aaIdx]
             cleanPeptide += peptide[aaIdx]
-            if digest.is_enzymatic_advanced(cleanPeptide[-2], cleanPeptide[-1], not_post = [], methionine_cleavage = False):
+            if digest.is_enzymatic_advanced(
+                cleanPeptide[-2],
+                cleanPeptide[-1],
+                not_post=[],
+                methionine_cleavage=False,
+            ):
                 enzInt += 1
         aaIdx += 1
-    enzN = int(digest.is_enzymatic_advanced(cleanPeptide[0], cleanPeptide[2], not_post = [])) # Andromeda uses Trypsin/P
-    enzC = int(digest.is_enzymatic_advanced(cleanPeptide[-3], cleanPeptide[-1], not_post = []))
+    enzN = int(
+        digest.is_enzymatic_advanced(cleanPeptide[0], cleanPeptide[2], not_post=[])
+    )  # Andromeda uses Trypsin/P
+    enzC = int(
+        digest.is_enzymatic_advanced(cleanPeptide[-3], cleanPeptide[-1], not_post=[])
+    )
     pepLen = len(cleanPeptide) - 4
     return modPeptide, cleanPeptide, pepLen, enzN, enzC, enzInt, numMods
 
 
 if __name__ == "__main__":
-     main(sys.argv[1:])
-
+    main(sys.argv[1:])
```

## picked_group_fdr/pipeline/entrapment_fdr.py

```diff
@@ -2,14 +2,15 @@
 import logging
 import os
 
 import numpy as np
 
 from .. import __version__, __copyright__
 from ..parsers import parsers
+from ..parsers import protein_groups as pgp
 from .. import helpers
 from .. import fdr
 from ..scoring import BestAndromedaScore
 from ..plotter import PlotterFactory
 from ..picked_group_fdr import ArgumentParserWithLogger
 
 # hacky way to get package logger when running as module
@@ -167,15 +168,15 @@
                         args.protein_groups_files, args.plot_labels, args.is_decoy_file
                     )
                     if l == label
                 ]
             )
             protein_groups, protein_scores = zip(
                 *list(
-                    parsers.parse_protein_groups_file_multiple(
+                    pgp.parse_protein_groups_file_multiple(
                         protein_group_files,
                         are_decoy_file=is_decoy_file,
                         protein_column=args.protein_col,
                         score_column=args.score_col,
                     )
                 )
             )
```

## picked_group_fdr/pipeline/merge_pout.py

```diff
@@ -83,18 +83,25 @@
     peptide_to_protein_map = collections.defaultdict(list)
     if len(args.fasta) > 0:
         digestion_params_list = digest.get_digestion_params_list(args)
         peptide_to_protein_map = digest.get_peptide_to_protein_map_from_params(
             args.fasta, digestion_params_list
         )
 
-    merge_pout(args.perc_results, peptide_to_protein_map, args.perc_merged)
+    merge_pout(
+        args.perc_results,
+        peptide_to_protein_map,
+        args.perc_merged,
+        args.suppress_missing_peptide_warning,
+    )
 
 
-def merge_pout(perc_results, peptideToProteinMap, perc_merged):
+def merge_pout(
+    perc_results, peptideToProteinMap, perc_merged, suppress_missing_peptide_warning
+):
     seenPeptides = dict()
     missingPeptides, matchedPeptides = 0, 0
     for poutFile in perc_results:
         poutReader = tsv.get_tsv_reader(poutFile)
         headers = next(poutReader)
 
         (
@@ -146,15 +153,18 @@
                         row[qvalCol],
                         row[postErrProbCol],
                         "-." + peptide + ".-",
                     ] + proteins
                     matchedPeptides += 1
                     seenPeptides[peptide] = (qValue, row, isDecoy)
                 else:
-                    if not helpers.is_contaminant(proteins):
+                    if (
+                        not helpers.is_contaminant(proteins)
+                        and not suppress_missing_peptide_warning
+                    ):
                         logger.debug(
                             f"Could not find peptide {peptide} in fasta file, check your database and if the correct digestion parameters were specified"
                         )
                     missingPeptides += 1
 
         logger.info(
             f"Processing row {i}: #Missing peptides: {missingPeptides}, #Matched peptides: {matchedPeptides}"
```

## picked_group_fdr/pipeline/pipeline.py

```diff
@@ -22,14 +22,15 @@
     fasta_files: List[str],
     output_dir: str,
     digest_params_list: List[DigestionParams],
     input_type: str,
     do_quant: bool,
     lfq_min_peptide_ratios: int,
     fdr_cutoff: float,
+    suppress_missing_peptide_warning: bool = False,
 ):
     try:
         if len(output_dir) == 0:
             raise RuntimeError("Please specify an output folder")
         if not os.path.isdir(output_dir):
             os.makedirs(output_dir)
 
@@ -38,42 +39,60 @@
             f"{output_dir}/proteinGroups.fdr{fdr_cutoff*100:g}.txt"
         )
         if input_type in ["rescoring", "mq"]:
             pout_input_type = "prosit"
             if input_type == "mq":
                 pout_input_type = "andromeda"
                 pin_files = run_andromeda_to_pin(
-                    evidence_files, fasta_files, output_dir, digest_params_list
+                    evidence_files,
+                    fasta_files,
+                    output_dir,
+                    digest_params_list,
+                    suppress_missing_peptide_warning,
                 )
                 pout_files = run_mokapot(pin_files, output_dir)
 
             evidence_files_rescored = [
                 f"{output_dir}/evidence_{idx}.txt" for idx in range(len(evidence_files))
             ]
             run_update_evidence(
-                evidence_files, pout_files, evidence_files_rescored, pout_input_type
+                evidence_files,
+                pout_files,
+                evidence_files_rescored,
+                pout_input_type,
+                suppress_missing_peptide_warning,
             )
             run_picked_group_fdr(
                 evidence_files_rescored,
                 protein_groups_out,
                 fasta_files,
                 digest_params_list,
                 do_quant,
                 lfq_min_peptide_ratios,
+                suppress_missing_peptide_warning,
             )
         elif input_type == "percolator_remap":  # currently not accessible by the GUI
             pout_merged = f"{output_dir}/pout_merged.txt"
             run_merge_pout_remap(
-                pout_files, fasta_files, output_dir, digest_params_list
+                pout_files,
+                fasta_files,
+                output_dir,
+                digest_params_list,
+                suppress_missing_peptide_warning,
             )
             run_picked_group_fdr_percolator_input_remap(
-                pout_merged, fasta_files, protein_groups_out
+                pout_merged,
+                fasta_files,
+                protein_groups_out,
+                suppress_missing_peptide_warning,
             )
         elif input_type == "percolator":
-            run_picked_group_fdr_percolator_input(pout_files, protein_groups_out)
+            run_picked_group_fdr_percolator_input(
+                pout_files, protein_groups_out, suppress_missing_peptide_warning
+            )
         else:
             logger.error(
                 f"Error while running Picked Group FDR, unknown input type: {input_type}."
             )
 
         run_filter_fdr_maxquant(
             [protein_groups_out], protein_groups_filtered_out, fdr_cutoff
@@ -88,25 +107,29 @@
 
 
 def run_andromeda_to_pin(
     evidence_files: List[str],
     fasta_files: List[str],
     output_dir: str,
     digest_params_list: List[DigestionParams],
+    suppress_missing_peptide_warning: bool,
 ):
     pin_files = list()
     for idx, (evidence_file, digest_params) in enumerate(
         zip(evidence_files, digest_params_list)
     ):
         digest_params_str = digestion_params_list_to_arg_list([digest_params])
         pin_file = f"{output_dir}/pin_{idx}.tab"
         andromeda2pin.main(
             [evidence_file, "--outputTab", pin_file, "--databases"]
             + fasta_files
             + digest_params_str
+            + suppress_missing_peptide_warning_flag(
+                suppress_missing_peptide_warning,
+            )
         )
         pin_files.append(pin_file)
     return pin_files
 
 
 def run_mokapot(pin_files: List[str], output_dir: str):
     pout_files = []
@@ -126,14 +149,15 @@
 
 
 def run_update_evidence(
     evidence_files: List[str],
     pout_files: List[str],
     evidence_files_rescored: List[str],
     pout_input_type: str,
+    suppress_missing_peptide_warning: bool,
 ):
     if len(evidence_files) != len(evidence_files_rescored):
         logger.error("Unequal number of input and output evidence files.")
 
     for evidence_file, evidence_file_rescored in zip(
         evidence_files, evidence_files_rescored
     ):
@@ -142,108 +166,135 @@
             + pout_files
             + [
                 "--mq_evidence_out",
                 evidence_file_rescored,
                 "--pout_input_type",
                 pout_input_type,
             ]
+            + suppress_missing_peptide_warning_flag(
+                suppress_missing_peptide_warning,
+            )
         )
 
 
 def run_picked_group_fdr(
     evidence_files: List[str],
     protein_groups_out: str,
     fasta_files: List[str],
     digest_params_list: List[DigestionParams],
     do_quant: bool,
     lfq_min_peptide_ratios: int,
+    suppress_missing_peptide_warning: bool,
 ):
     digest_params_str = digestion_params_list_to_arg_list(digest_params_list)
     quant_flags = []
     if do_quant:
         quant_flags = [
             "--do_quant",
             "--lfq_min_peptide_ratios",
             str(lfq_min_peptide_ratios),
         ]
+
     picked_group_fdr.main(
         ["--mq_evidence"]
         + evidence_files
         + [
             "--methods",
             "picked_protein_group_mq_input",
             "--do_quant",
             "--protein_groups_out",
             protein_groups_out,
             "--fasta",
         ]
         + fasta_files
         + digest_params_str
         + quant_flags
+        + suppress_missing_peptide_warning_flag(
+            suppress_missing_peptide_warning,
+        )
     )
 
 
 def run_merge_pout(
     pout_files: List[str],
     pout_merged: str,
+    suppress_missing_peptide_warning: bool,
 ):
     merge_pout.main(
         ["--perc_results"]
         + pout_files
         + ["--perc_merged", pout_merged]
+        + suppress_missing_peptide_warning_flag(
+            suppress_missing_peptide_warning,
+        )
     )
 
 
 def run_merge_pout_remap(
     pout_files: List[str],
     fasta_files: List[str],
     pout_merged: str,
     digest_params_list: List[DigestionParams],
+    suppress_missing_peptide_warning: bool,
 ):
     digest_params_str = digestion_params_list_to_arg_list(digest_params_list)
     merge_pout.main(
         ["--perc_results"]
         + pout_files
         + ["--perc_merged", pout_merged, "--fasta"]
         + fasta_files
         + digest_params_str
+        + suppress_missing_peptide_warning_flag(
+            suppress_missing_peptide_warning,
+        )
     )
 
 
 def run_picked_group_fdr_percolator_input(
-    pout_files: List[str], protein_groups_out: str
+    pout_files: List[str],
+    protein_groups_out: str,
+    suppress_missing_peptide_warning: bool,
 ):
     picked_group_fdr.main(
         [
             "--perc_evidence",
         ]
         + pout_files
         + [
             "--methods",
             "picked_protein_group_no_remap",
             "--protein_groups_out",
             protein_groups_out,
         ]
+        + suppress_missing_peptide_warning_flag(
+            suppress_missing_peptide_warning,
+        )
     )
 
 
 def run_picked_group_fdr_percolator_input_remap(
-    pout_merged: str, fasta_files: List[str], protein_groups_out: str
+    pout_merged: str,
+    fasta_files: List[str],
+    protein_groups_out: str,
+    suppress_missing_peptide_warning: bool,
 ):
     picked_group_fdr.main(
         [
             "--perc_evidence",
             pout_merged,
             "--methods",
             "picked_protein_group_no_remap",
             "--protein_groups_out",
             protein_groups_out,
             "--fasta",
         ]
         + fasta_files
+        + suppress_missing_peptide_warning_flag(
+            suppress_missing_peptide_warning,
+        )
     )
 
 
 def run_filter_fdr_maxquant(
     protein_groups_files: List[str], protein_groups_out: str, fdr_cutoff: float = 0.01
 ):
     filter_fdr_maxquant.main(
@@ -252,7 +303,15 @@
         + [
             "--mq_protein_groups_out",
             protein_groups_out,
             "--fdr_cutoff",
             str(fdr_cutoff),
         ]
     )
+
+
+def suppress_missing_peptide_warning_flag(
+    suppress_missing_peptide_warning,
+) -> List[str]:
+    if suppress_missing_peptide_warning:
+        return ["--suppress_missing_peptide_warning"]
+    return []
```

## picked_group_fdr/pipeline/run_mokapot.py

```diff
@@ -5,15 +5,15 @@
 import datetime
 
 import mokapot
 from mokapot import __version__
 from mokapot.model import PercolatorModel
 
 
-def run_mokapot(perc_folder, test_fdr, train_fdr, max_workers):
+def run_mokapot(perc_folder, test_fdr, train_fdr, max_workers, seed=1):
     psms_result_file = os.path.join(perc_folder, 'andromeda.mokapot.psms.txt')
     if os.path.isfile(psms_result_file):
       print(f"Found mokapot output file {psms_result_file}, remove this file to rerun mokapot.")
       return
 
     start = time.time()
 
@@ -40,16 +40,16 @@
     logging.info("Command issued:")
     logging.info("%s", " ".join(sys.argv))
     logging.info("")
     logging.info("Starting Analysis")
     logging.info("=================")
 
     psms = mokapot.read_pin(os.path.join(perc_folder, "andromeda.tab"))
-    model = PercolatorModel(train_fdr=train_fdr)
-    results, models = mokapot.brew(psms, model=model, test_fdr=test_fdr, max_workers=max_workers)
+    model = PercolatorModel(train_fdr=train_fdr, rng=seed)
+    results, _ = mokapot.brew(psms, model=model, test_fdr=test_fdr, max_workers=max_workers, rng=seed)
     results.to_txt(dest_dir = perc_folder, file_root="andromeda", decoys = True)
 
     total_time = round(time.time() - start)
     total_time = str(datetime.timedelta(seconds=total_time))
 
     logging.info("")
     logging.info("=== DONE! ===")
```

## picked_group_fdr/pipeline/sage_quantification.py

```diff
@@ -54,15 +54,16 @@
     )
 
     apars.add_argument(
         "--sage_lfq_tsv",
         default=None,
         metavar="I",
         required=True,
-        help="""Path to lfq.tsv produced by Sage. This enables
+        nargs="+",
+        help="""Path to lfq.tsv file(s) produced by Sage. This enables
                 quantification of protein groups by PickedGroupFDR in 
                 combined_protein.tsv.""",
     )
 
     apars.add_argument(
         "--protein_groups_out",
         default="./combined_protein.tsv",
```

## picked_group_fdr/pipeline/update_evidence_from_pout.py

```diff
@@ -80,14 +80,20 @@
         default="auto",
         metavar="IT",
         help="""Input type of MaxQuant output file. Can be 
                 "peptides", "evidence", "msms" or "auto" 
                 (automatic detection).""",
     )
 
+    apars.add_argument(
+        "--suppress_missing_peptide_warning",
+        help="Suppress missing peptide warning when mapping peptides to proteins.",
+        action="store_true",
+    )
+
     # ------------------------------------------------
     args = apars.parse_args(argv)
 
     return args
 
 
 def main(argv) -> None:
@@ -110,51 +116,55 @@
 
     update_func(
         args.mq_evidence,
         args.perc_results,
         args.mq_evidence_out,
         args.mq_msms,
         args.pout_input_type,
+        args.suppress_missing_peptide_warning,
     )
 
     os.rename(args.mq_evidence_out + ".tmp", args.mq_evidence_out)
 
 
 def update_evidence_file(
     evidence_files: List[str],
     pout_files: List[str],
     out_evidence_file: str,
     msms_files: List[str],
     pout_input_type: str,
+    suppress_missing_peptide_warning: bool,
 ) -> None:
     fixed_mods, results_dict = get_percolator_results(pout_files, pout_input_type)
 
     logger.info("Writing updated combined evidence file")
     writer = tsv.get_tsv_writer(out_evidence_file + ".tmp")
     first_headers = []
     for evidence_file in evidence_files:
         first_headers = update_evidence_single(
             evidence_file,
             writer,
             first_headers,
             fixed_mods,
             results_dict,
             pout_input_type,
+            suppress_missing_peptide_warning,
         )
 
     logger.info(f"Results written to {out_evidence_file}")
 
 
 def update_evidence_single(
     evidence_file: str,
     writer: "_csv._writer",
     first_headers: List[str],
     fixed_mods: Dict[str, str],
     results_dict: Dict[str, Dict[Tuple[int, str], Tuple[float, float]]],
     pout_input_type: str,
+    suppress_missing_peptide_warning: bool,
 ) -> List[str]:
     logger.info(f"Processing {evidence_file}")
     reader = tsv.get_tsv_reader(evidence_file)
 
     headers_original = next(reader)  # save the header
     headers = list(map(lambda x: x.lower(), headers_original))
     if len(first_headers) == 0:
@@ -195,20 +205,22 @@
 
         perc_result, peptide = find_percolator_psm(
             psm, fixed_mods, results_dict, pout_input_type
         )
         if not perc_result:
             if is_unexplainable_missing_psm(psm, peptide, pout_input_type):
                 unexplained_missing_PSMs += 1
-                logger.debug("Unexplained missing PSM:")
+                if not suppress_missing_peptide_warning:
+                    logger.debug("Unexplained missing PSM:")
                 if unexplained_missing_PSMs <= 10:
                     unexplained_peptides.append(psm.peptide)
-            logger.debug(
-                f"Missing PSM in percolator output: {psm.raw_file}, {peptide}, {psm.scannr}"
-            )
+            if not suppress_missing_peptide_warning:
+                logger.debug(
+                    f"Missing PSM in percolator output: {psm.raw_file}, {peptide}, {psm.scannr}"
+                )
             continue
 
         perc_score, perc_post_err_prob = perc_result
         if not psm.is_decoy:
             prosit_PEPs.append((perc_post_err_prob, psm.id_type))
 
         row[score_col] = perc_score
@@ -299,14 +311,15 @@
 
 def update_peptides_file(
     peptide_files: List[str],
     pout_files: List[str],
     out_peptide_file: str,
     msms_files: List[str],
     pout_input_type: str,
+    suppress_missing_peptide_warning: bool,
 ) -> None:
     _, results_dict = get_percolator_results(pout_files, pout_input_type)
 
     peptide_results_dict = convert_PSM_dict_to_peptide_dict(results_dict)
 
     logger.info("Writing updated peptides file")
     writer = tsv.get_tsv_writer(out_peptide_file + ".tmp")
```

## picked_group_fdr/pipeline/update_fragpipe_results.py

```diff
@@ -1,7 +1,13 @@
+"""
+Updates protein and gene name specific columns in `psm.tsv` and `protein.tsv` 
+file for each FragPipe experiment folder using a protein grouping result from 
+Picked Group FDR in MaxQuant's proteinGroups.txt format.
+"""
+
 from pathlib import Path
 import sys
 import os
 import logging
 from typing import Dict, List, Optional
 
 import pandas as pd
@@ -18,14 +24,15 @@
 from ..parsers import maxquant
 from ..parsers import tsv
 from ..parsers import fragpipe
 from ..quant.fragpipe import add_precursor_quants, add_precursor_quants_multiple
 from ..protein_annotation import ProteinAnnotation
 from ..protein_groups import ProteinGroups
 from ..results import ProteinGroupResults
+from ..scoring_strategy import ProteinScoringStrategy
 
 # hacky way to get package logger when running as module
 logger = logging.getLogger(__package__ + "." + __file__)
 
 
 def parse_args(argv):
     import argparse
@@ -62,28 +69,35 @@
         help="Path to proteinGroups.txt produced by PickedGroupFDR.",
     )
 
     apars.add_argument(
         "--combined_ion",
         default=None,
         metavar="I",
-        help="""Path to combined_ion.tsv produced by IonQuant/FragPipe. This enables
+        nargs="+",
+        help="""Path to combined_ion.tsv file(s) produced by IonQuant/FragPipe. This enables
                 quantification of protein groups by PickedGroupFDR in 
                 combined_protein.tsv.""",
     )
 
     apars.add_argument(
         "--output_folder",
         default=None,
         metavar="DIR",
         help="""Output folder (optional). If this argument is not specified, the
                 original psm.tsv and protein.tsv are overwritten, keeping copies
                 of the original files as psm.original.tsv and protein.original.tsv.""",
     )
 
+    apars.add_argument(
+        "--suppress_missing_peptide_warning",
+        help="Suppress missing peptide warning when mapping peptides to proteins.",
+        action="store_true",
+    )
+
     add_quant_arguments(apars)
     digest.add_digestion_arguments(apars)
 
     # ------------------------------------------------
     args = apars.parse_args(argv)
 
     return args
@@ -107,54 +121,61 @@
     )
     protein_sequences = digest.get_protein_sequences(
         args.fasta, db=db, parse_id=digest.parse_until_first_space
     )
 
     for fragpipe_psm_file in args.fragpipe_psm:
         fragpipe_psm_file_out = update_fragpipe_psm_file(
-            fragpipe_psm_file, protein_groups, protein_annotations, args.output_folder
+            fragpipe_psm_file,
+            protein_groups,
+            protein_annotations,
+            args.output_folder,
+            args.suppress_missing_peptide_warning,
         )
 
         # create a fresh ProteinGroupResults object for each psm.tsv
         protein_group_results = maxquant.parse_mq_protein_groups_file(
             args.protein_groups
         )
         generate_fragpipe_protein_file(
             fragpipe_psm_file_out,
             protein_groups,
             protein_group_results,
             protein_annotations,
             protein_sequences,
             experimental_design,
             args.output_folder,
+            suppress_missing_peptide_warning=args.suppress_missing_peptide_warning,
         )
 
     if args.combined_ion is not None:
         # create a fresh ProteinGroupResults object for combined_protein.tsv
         protein_group_results = maxquant.parse_mq_protein_groups_file(
             args.protein_groups
         )
         generate_fragpipe_combined_protein_file(
             args.fragpipe_psm,
             args.combined_ion,
             protein_groups,
             protein_group_results,
             protein_annotations,
             args.output_folder,
+            suppress_missing_peptide_warning=args.suppress_missing_peptide_warning,
         )
-    
+
     logger.info(f"Protein group results have been written to: {args.output_folder}")
 
 
 def update_fragpipe_psm_file(
     fragpipe_psm_file: str,
     protein_groups: ProteinGroups,
     protein_annotations: Dict[str, ProteinAnnotation],
     output_folder: Optional[str] = None,
     discard_shared_peptides: bool = True,
+    suppress_missing_peptide_warning: bool = False,
 ) -> str:
     """Update protein mappings for each peptide using the PickedGroupFDR protein groups.
 
     These columns are updated:
     - Protein
     - Protein ID (P00167) - from fasta
     - Entry Name (CYB5_HUMAN) - from fasta
@@ -199,17 +220,18 @@
     writer.writerow(headers)
     for row, proteins in fragpipe.parse_fragpipe_psm_file_for_peptide_remapping(
         reader, headers
     ):
         row_protein_groups = protein_groups.get_protein_groups(proteins)
 
         if helpers.is_missing_in_protein_groups(row_protein_groups):
-            logger.debug(
-                f"Could not find any of the proteins {proteins} in proteinGroups.txt"
-            )
+            if not suppress_missing_peptide_warning:
+                logger.debug(
+                    f"Could not find any of the proteins {proteins} in proteinGroups.txt"
+                )
             missing_peptides_in_protein_groups += 1
             continue
 
         if discard_shared_peptides and helpers.is_shared_peptide(row_protein_groups):
             shared_peptide_precursors += 1
             continue
 
@@ -279,14 +301,15 @@
     protein_group_results: ProteinGroupResults,
     protein_annotations: Dict[str, ProteinAnnotation],
     protein_sequences: Dict[str, str],
     experimental_design: Optional[pd.DataFrame],
     output_folder: Optional[str] = None,
     psm_fdr_cutoff: float = 0.01,
     discard_shared_peptides: bool = True,
+    suppress_missing_peptide_warning: bool = False,
 ):
     """Generate experiment specific protein.tsv file from psm.tsv and fasta file.
 
     https://fragpipe.nesvilab.org/docs/tutorial_fragpipe_outputs.html
 
     Output columns (LFQ):
     - Protein (sp|P00167|CYB5_HUMAN) - from fasta
@@ -320,14 +343,15 @@
     experiment = "1"
     protein_group_results, post_err_probs = add_precursor_quants(
         fragpipe_psm_file,
         protein_group_results,
         protein_groups,
         experiment,
         discard_shared_peptides,
+        suppress_missing_peptide_warning,
     )
 
     fragpipe_protein_file_out = get_fragpipe_protein_out_path(
         output_folder, fragpipe_psm_file
     )
 
     fragpipe_writer = writers.FragPipeSingleProteinWriter(
@@ -362,37 +386,42 @@
                 fragpipe_protein_file_backup,
             )
     return fragpipe_protein_file_out
 
 
 def generate_fragpipe_combined_protein_file(
     fragpipe_psm_files: List[str],
-    combined_ion_file: str,
+    combined_ion_files: List[str],
     protein_groups: ProteinGroups,
     protein_group_results: ProteinGroupResults,
     protein_annotations: Dict[str, ProteinAnnotation],
     output_folder: Optional[str] = None,
     psm_fdr_cutoff: float = 0.01,
     discard_shared_peptides: bool = True,
+    suppress_missing_peptide_warning: bool = False,
 ):
     """Generate combined_protein.tsv file from psm.tsv and protein annotations.
 
     Args:
         fragpipe_psm_file (str): file in Fragpipe's psm.tsv format
         fasta_file (str): fasta file with all protein sequences
     """
 
+    score_type = ProteinScoringStrategy("no_remap bestPEP")
+
     protein_group_results, post_err_probs = add_precursor_quants_multiple(
         fragpipe_psm_files,
-        combined_ion_file,
+        combined_ion_files,
         protein_groups,
         protein_group_results,
         peptide_to_protein_maps=None,
         experimental_design=None,
         discard_shared_peptides=discard_shared_peptides,
+        score_type=score_type,
+        suppress_missing_peptide_warning=suppress_missing_peptide_warning,
     )
 
     if output_folder is None:
         output_folder = Path(fragpipe_psm_files[0]).parents[1]
     fragpipe_combined_protein_file_out = f"{output_folder}/combined_protein.tsv"
 
     write_fragpipe_combined_protein_file(
@@ -460,12 +489,14 @@
         os.rename(
             protein_groups_out_file,
             protein_groups_out_file.replace(".tsv", ".original.tsv"),
         )
 
     fragpipe_writer.write(protein_group_results, protein_groups_out_file)
 
-    logger.info(f"Protein group results have been written to: {protein_groups_out_file}")
+    logger.info(
+        f"Protein group results have been written to: {protein_groups_out_file}"
+    )
 
 
 if __name__ == "__main__":
     main(sys.argv[1:])
```

## picked_group_fdr/plotter.py

```diff
@@ -24,15 +24,15 @@
     
     def show(self):
         pass
     
     def set_series_label_base(self, figure_label):
         pass
     
-    def set_series_label(self, score_type, grouping_strategy, picked_strategy, rescue_step):
+    def set_series_label(self, method_config: methods.MethodConfig, rescue_step: bool):
         pass
     
     def plot_qval_calibration_and_performance(self, reported_qvals, observed_qvals, absent_ratio = 1.0):
         pass
 
 
 class Plotter:
@@ -167,17 +167,17 @@
         for t in legend.get_texts():
                 t.set_ha('right') # ha is alias for horizontalalignment
                 t.set_position((shift,0))
     
     def set_series_label_base(self, figure_label):
         self.label_base = figure_label
     
-    def set_series_label(self, score_type, grouping_strategy, picked_strategy, rescue_step):
+    def set_series_label(self, method_config: methods.MethodConfig, rescue_step: bool):
         label = self.label_base + " " if self.label_base else ""
-        short_desc = methods.short_description(score_type, grouping_strategy, picked_strategy, rescue_step, sep=",")
+        short_desc = method_config.short_description(rescue_step, sep=",")
         label += f'({short_desc})'
         self.label = label
 
 
 class PlotterFactory:
     @staticmethod
     def get_plotter(figure_base_fn, plot_figures):
```

## picked_group_fdr/protein_annotation.py

```diff
@@ -155,27 +155,29 @@
 
 
 def get_protein_annotations(
     fasta: str, fasta_contains_decoys: bool, use_gene_level: bool
 ) -> Tuple[Dict[str, ProteinAnnotation], bool]:
     protein_annotations = dict()
     use_pseudo_genes = False
-    if fasta:
-        db = "target" if fasta_contains_decoys else "concat"
-        protein_annotations = get_protein_annotations_multiple(
-            fasta, db=db, parse_id=digest.parse_until_first_space
-        )
-        if use_gene_level:
-            if has_gene_names(protein_annotations, min_ratio_with_genes=0.5):
-                protein_annotations = get_protein_annotations_multiple(
-                    fasta, db=db, parse_id=parse_gene_name_func
+    if fasta is None:
+        return protein_annotations, use_pseudo_genes
+    
+    db = "target" if fasta_contains_decoys else "concat"
+    protein_annotations = get_protein_annotations_multiple(
+        fasta, db=db, parse_id=digest.parse_until_first_space
+    )
+    if use_gene_level:
+        if has_gene_names(protein_annotations, min_ratio_with_genes=0.5):
+            protein_annotations = get_protein_annotations_multiple(
+                fasta, db=db, parse_id=parse_gene_name_func
+            )
+        else:
+            logger.warning(
+                (
+                    "Found >50% of proteins without gene names in the "
+                    "fasta file, will infer pseudo-genes based on "
+                    "shared peptides instead."
                 )
-            else:
-                logger.warning(
-                    (
-                        "Found >50% of proteins without gene names in the "
-                        "fasta file, will infer pseudo-genes based on "
-                        "shared peptides instead."
-                    )
-                )
-                use_pseudo_genes = True
+            )
+            use_pseudo_genes = True
     return protein_annotations, use_pseudo_genes
```

## picked_group_fdr/protein_groups.py

```diff
@@ -1,14 +1,14 @@
 from __future__ import annotations
 from typing import List, Set, Dict
 import logging
 
-from .parsers import parsers
 from . import helpers
 from . import entrapment
+from .parsers import protein_groups as pgp
 
 # for type hints only
 from .peptide_info import ProteinGroupPeptideInfos
 
 
 logger = logging.getLogger(__name__)
 
@@ -26,15 +26,15 @@
         self.protein_to_group_idx_map = dict()
         self.valid_idx = False
 
     @staticmethod
     def from_mq_protein_groups_file(mq_protein_groups_file: str):
         protein_groups = [
             protein_group
-            for protein_group, _ in parsers.parse_protein_groups_file_single(
+            for protein_group, _ in pgp.parse_protein_groups_file_single(
                 mq_protein_groups_file
             )
         ]
         return ProteinGroups.init_from_list(protein_groups)
 
     @staticmethod
     def from_observed_peptide_map(protein_to_peptides_dict):
```

## picked_group_fdr/quant/fragpipe.py

```diff
@@ -1,32 +1,36 @@
+from __future__ import annotations
+
 import logging
 from pathlib import Path
 from typing import Dict, List, Tuple, Optional
 
 import numpy as np
 import pandas as pd
 
 from .. import helpers
 from ..parsers import fragpipe, tsv
 from ..precursor_quant import PrecursorQuant
-from ..protein_groups import ProteinGroups
-from ..results import ProteinGroupResults
 
 # for type hints only
 from .. import digest
+from .. import results
+from .. import protein_groups as pg
+from .. import scoring_strategy
 
 logger = logging.getLogger(__name__)
 
 
 def add_precursor_quants(
     fragpipe_psm_file: str,
-    protein_group_results: ProteinGroupResults,
-    protein_groups: ProteinGroups,
+    protein_group_results: results.ProteinGroupResults,
+    protein_groups: pg.ProteinGroups,
     experiment: str,
     discard_shared_peptides: bool,
+    suppress_missing_peptide_warning: bool,
 ):
     protein_group_results.experiments.append(experiment)
 
     delimiter = tsv.get_delimiter(fragpipe_psm_file)
     reader = tsv.get_tsv_reader(fragpipe_psm_file, delimiter)
     headers = next(reader)
 
@@ -38,17 +42,18 @@
         assigned_mods,
         observed_mods,
         proteins,
     ) in fragpipe.parse_fragpipe_psm_file_for_protein_tsv(reader, headers):
         protein_group_idxs = protein_groups.get_protein_group_idxs(proteins)
 
         if helpers.is_missing_in_protein_groups(protein_group_idxs):
-            logger.debug(
-                f"Could not find any of the proteins {proteins} in proteinGroups.txt"
-            )
+            if not suppress_missing_peptide_warning:
+                logger.debug(
+                    f"Could not find any of the proteins {proteins} in proteinGroups.txt"
+                )
             continue
 
         if discard_shared_peptides and helpers.is_shared_peptide(protein_group_idxs):
             continue
 
         if not helpers.is_decoy(proteins):
             post_err_probs.append((post_err_prob, experiment, experiment, peptide))
@@ -70,18 +75,37 @@
             protein_group_results[protein_group_idx].precursorQuants.append(
                 precursor_quant
             )
     return protein_group_results, post_err_probs
 
 
 def update_precursor_quants(
-    protein_group_results: ProteinGroupResults,
-    protein_groups: ProteinGroups,
+    protein_group_results: results.ProteinGroupResults,
+    protein_groups: pg.ProteinGroups,
+    combined_ion_files: List[str],
+    discard_shared_peptides: bool,
+    suppress_missing_peptide_warning: bool,
+):
+    for combined_ion_file in combined_ion_files:
+        protein_group_results = update_precursor_quants_single(
+            protein_group_results,
+            protein_groups,
+            combined_ion_file,
+            discard_shared_peptides,
+            suppress_missing_peptide_warning,
+        )
+    return protein_group_results
+
+
+def update_precursor_quants_single(
+    protein_group_results: results.ProteinGroupResults,
+    protein_groups: pg.ProteinGroups,
     combined_ion_file: str,
     discard_shared_peptides: bool,
+    suppress_missing_peptide_warning: bool,
 ):
     delimiter = tsv.get_delimiter(combined_ion_file)
     reader = tsv.get_tsv_reader(combined_ion_file, delimiter)
     headers = next(reader)
 
     for (
         peptide,
@@ -89,17 +113,18 @@
         assigned_mods,
         proteins,
         intensities,
     ) in fragpipe.parse_fragpipe_combined_ion_file(reader, headers):
         protein_group_idxs = protein_groups.get_protein_group_idxs(proteins)
 
         if helpers.is_missing_in_protein_groups(protein_group_idxs):
-            logger.debug(
-                f"Could not find any of the proteins {proteins} in proteinGroups.txt"
-            )
+            if not suppress_missing_peptide_warning:
+                logger.debug(
+                    f"Could not find any of the proteins {proteins} in proteinGroups.txt"
+                )
             continue
 
         if discard_shared_peptides and helpers.is_shared_peptide(protein_group_idxs):
             continue
 
         for protein_group_idx in protein_group_idxs:
             precursors_to_update: Dict[str, Tuple[float, int]] = {}
@@ -145,34 +170,38 @@
                         precursor_quant
                     )
     return protein_group_results
 
 
 def add_precursor_quants_multiple(
     fragpipe_psm_files: List[str],
-    combined_ion_file: List[str],
-    protein_groups: ProteinGroups,
-    protein_group_results: ProteinGroupResults,
+    combined_ion_files: List[str],
+    protein_groups: pg.ProteinGroups,
+    protein_group_results: results.ProteinGroupResults,
     peptide_to_protein_maps: List[digest.PeptideToProteinMap],
     experimental_design: Optional[pd.DataFrame],
     discard_shared_peptides: bool,
+    score_type: scoring_strategy.ProteinScoringStrategy,
+    suppress_missing_peptide_warning: bool,
 ):
     post_err_probs_combined = []
     for fragpipe_psm_file in fragpipe_psm_files:
         experiment = Path(fragpipe_psm_file).parent.name
         protein_group_results, post_err_probs = add_precursor_quants(
             fragpipe_psm_file,
             protein_group_results,
             protein_groups,
             experiment,
             discard_shared_peptides,
+            suppress_missing_peptide_warning,
         )
         post_err_probs_combined.extend(post_err_probs)
 
-    if combined_ion_file is not None:
+    if combined_ion_files is not None:
         protein_group_results = update_precursor_quants(
             protein_group_results,
             protein_groups,
-            combined_ion_file,
+            combined_ion_files,
             discard_shared_peptides,
+            suppress_missing_peptide_warning,
         )
     return protein_group_results, post_err_probs_combined
```

## picked_group_fdr/quant/maxquant.py

```diff
@@ -1,34 +1,39 @@
+from __future__ import annotations
+
 import logging
 from typing import List, Optional
 
 import numpy as np
 import pandas as pd
 
 from .. import helpers
 from ..parsers import psm
-from ..precursor_quant import PrecursorQuant
-from ..protein_groups import ProteinGroups
-from ..results import ProteinGroupResults
 from ..parsers import parsers
+from ..precursor_quant import PrecursorQuant
 
 # for type hints only
 from .. import digest
+from .. import results
+from .. import protein_groups as pg
+from .. import scoring_strategy
 
 logger = logging.getLogger(__name__)
 
 
 def add_precursor_quants(
     mq_evidence_files: List[str],
     mq_quantification_files: List[str],
-    protein_groups: ProteinGroups,
-    protein_group_results: ProteinGroupResults,
+    protein_groups: pg.ProteinGroups,
+    protein_group_results: results.ProteinGroupResults,
     peptide_to_protein_maps: List[digest.PeptideToProteinMap],
     experimental_design: Optional[pd.DataFrame],
     discard_shared_peptides: bool,
+    score_type: scoring_strategy.ProteinScoringStrategy,
+    suppress_missing_peptide_warning: bool,
 ):
     file_mapping = None
     if experimental_design is not None:
         protein_group_results.experiments = experimental_design["Experiment"].unique().tolist()
         file_mapping = parsers.get_file_mapping(experimental_design)
 
     post_err_probs = list()
@@ -47,15 +52,15 @@
         post_err_prob,
         tmt_cols,
         silac_cols,
         evidence_id,
     ) in psm.parse_evidence_file_multiple(
         mq_evidence_files,
         peptide_to_protein_maps=peptide_to_protein_maps,
-        score_type=None,
+        score_type=score_type,
         for_quantification=True,
     ):
         if protein_group_results.num_tmt_channels == -1:
             # There are 3 columns per TMT channel:
             #     Reporter intensity corrected,
             #     Reporter intensity
             #     Reporter intensity count
@@ -69,17 +74,18 @@
         elif experiment not in parsed_experiments:
             parsed_experiments.add(experiment)
 
         protein_group_idxs = protein_groups.get_protein_group_idxs(proteins)
 
         # removes peptides not present in the proteinGroups.txt file
         if helpers.is_missing_in_protein_groups(protein_group_idxs):
-            logger.debug(
-                f"Could not find any of the proteins {proteins} in proteinGroups.txt"
-            )
+            if not suppress_missing_peptide_warning:
+                logger.debug(
+                    f"Could not find any of the proteins {proteins} in proteinGroups.txt"
+                )
             missing_peptides_in_protein_groups += 1
             continue
 
         if discard_shared_peptides and helpers.is_shared_peptide(protein_group_idxs):
             shared_peptide_precursors += 1
             continue
```

## picked_group_fdr/quant/sage.py

```diff
@@ -1,31 +1,35 @@
+from __future__ import annotations
+
 import logging
 from typing import Dict, List, Optional, Tuple
 
 import numpy as np
 import pandas as pd
 
 from .. import helpers
 from ..parsers import sage, tsv, parsers
 from ..precursor_quant import PrecursorQuant
-from ..protein_groups import ProteinGroups
-from ..results import ProteinGroupResults
 
 # for type hints only
 from .. import digest
+from .. import results
+from .. import protein_groups as pg
+from .. import scoring_strategy
 
 logger = logging.getLogger(__name__)
 
 
 def add_precursor_quants(
     fragpipe_psm_file: str,
-    protein_group_results: ProteinGroupResults,
-    protein_groups: ProteinGroups,
+    protein_group_results: results.ProteinGroupResults,
+    protein_groups: pg.ProteinGroups,
     experimental_design: Optional[pd.DataFrame],
     discard_shared_peptides: bool,
+    suppress_missing_peptide_warning: bool,
 ):
     file_mapping = None
     if experimental_design is not None:
         protein_group_results.experiments = (
             experimental_design["Experiment"].unique().tolist()
         )
         file_mapping = parsers.get_file_mapping(experimental_design)
@@ -46,17 +50,18 @@
         charge,
     ) in sage.parse_sage_results_file(
         reader, headers, get_proteins, score_type=None, for_quantification=True
     ):
         protein_group_idxs = protein_groups.get_protein_group_idxs(proteins)
 
         if helpers.is_missing_in_protein_groups(protein_group_idxs):
-            logger.debug(
-                f"Could not find any of the proteins {proteins} in proteinGroups.txt"
-            )
+            if not suppress_missing_peptide_warning:
+                logger.debug(
+                    f"Could not find any of the proteins {proteins} in proteinGroups.txt"
+                )
             continue
 
         if discard_shared_peptides and helpers.is_shared_peptide(protein_group_idxs):
             continue
 
         experiment, fraction = filename, -1
         if file_mapping:
@@ -80,25 +85,46 @@
                 evidence_id=-1,
             )
             protein_group_results[protein_group_idx].precursorQuants.append(
                 precursorQuant
             )
 
     if len(parsed_experiments) > 0:
-        protein_group_results.experiments = sorted(list(parsed_experiments))
+        protein_group_results.experiments.extend(sorted(list(parsed_experiments)))
 
     return protein_group_results, post_err_probs
 
 
 def update_precursor_quants(
-    protein_group_results: ProteinGroupResults,
-    protein_groups: ProteinGroups,
+    protein_group_results: results.ProteinGroupResults,
+    protein_groups: pg.ProteinGroups,
+    sage_lfq_tsvs: List[str],
+    experimental_design: Optional[pd.DataFrame],
+    discard_shared_peptides: bool,
+    suppress_missing_peptide_warning: bool,
+):
+    for sage_lfq_tsv in sage_lfq_tsvs:
+        protein_group_results = update_precursor_quants_single(
+            protein_group_results,
+            protein_groups,
+            sage_lfq_tsv,
+            experimental_design,
+            discard_shared_peptides,
+            suppress_missing_peptide_warning,
+        )
+    return protein_group_results
+
+
+def update_precursor_quants_single(
+    protein_group_results: results.ProteinGroupResults,
+    protein_groups: pg.ProteinGroups,
     sage_lfq_tsv: str,
     experimental_design: Optional[pd.DataFrame],
     discard_shared_peptides: bool,
+    suppress_missing_peptide_warning: bool,
 ):
     file_mapping = None
     if experimental_design is not None:
         file_mapping = parsers.get_file_mapping(experimental_design)
 
     delimiter = tsv.get_delimiter(sage_lfq_tsv)
     reader = tsv.get_tsv_reader(sage_lfq_tsv, delimiter)
@@ -109,17 +135,18 @@
         charge,
         proteins,
         intensities,
     ) in sage.parse_sage_lfq_file(reader, headers):
         protein_group_idxs = protein_groups.get_protein_group_idxs(proteins)
 
         if helpers.is_missing_in_protein_groups(protein_group_idxs):
-            logger.debug(
-                f"Could not find any of the proteins {proteins} in proteinGroups.txt"
-            )
+            if not suppress_missing_peptide_warning:
+                logger.debug(
+                    f"Could not find any of the proteins {proteins} in proteinGroups.txt"
+                )
             continue
 
         if discard_shared_peptides and helpers.is_shared_peptide(protein_group_idxs):
             continue
 
         for protein_group_idx in protein_group_idxs:
             precursors_to_update: Dict[str, Tuple[float, int]] = {}
@@ -169,33 +196,37 @@
                         precursorQuant
                     )
     return protein_group_results
 
 
 def add_precursor_quants_multiple(
     sage_results_files: List[str],
-    sage_lfq_tsv: str,
-    protein_groups: ProteinGroups,
-    protein_group_results: ProteinGroupResults,
+    sage_lfq_tsv: List[str],
+    protein_groups: pg.ProteinGroups,
+    protein_group_results: results.ProteinGroupResults,
     peptide_to_protein_maps: List[digest.PeptideToProteinMap],
     experimental_design: Optional[pd.DataFrame],
     discard_shared_peptides: bool,
+    score_type: scoring_strategy.ProteinScoringStrategy,
+    suppress_missing_peptide_warning: bool,
 ):
     post_err_probs_combined = []
     for sage_results_file in sage_results_files:
         protein_group_results, post_err_probs = add_precursor_quants(
             sage_results_file,
             protein_group_results,
             protein_groups,
             experimental_design,
             discard_shared_peptides,
+            suppress_missing_peptide_warning,
         )
         post_err_probs_combined.extend(post_err_probs)
 
     protein_group_results = update_precursor_quants(
         protein_group_results,
         protein_groups,
         sage_lfq_tsv,
         experimental_design,
         discard_shared_peptides,
+        suppress_missing_peptide_warning,
     )
     return protein_group_results, post_err_probs_combined
```

## picked_group_fdr/quantification.py

```diff
@@ -1,64 +1,112 @@
+"""Performs quantification of previously generated protein groups and adds columns to a new output file.
+
+Currently only works with MaxQuant proteinGroups.txt.
+
+Usage:
+
+    python -m picked_group_fdr.quantification \
+        --mq_evidence evidence.txt \
+        --mq_protein_groups proteinGroups.txt \
+        --protein_groups_out proteinGroups_with_quant.txt \
+        --fasta db.fasta
+"""
+
 import sys
 import os
+import argparse
 import logging
 from typing import Dict, List, Tuple
 
 from . import writers
 from . import digest
 from . import digestion_params
 from . import protein_annotation
-from . import picked_group_fdr
+from . import peptide_protein_map
 from .parsers import maxquant
+from .parsers import fragpipe
 from .parsers import parsers
-from .quant import maxquant as mq_quant
-from .columns import protein_annotations as pa
-from .columns.triqler import init_triqler_params
+from .protein_groups import ProteinGroups
+from .scoring_strategy import ProteinScoringStrategy
+from .results import ProteinGroupResults
 
-logger = logging.getLogger(__name__)
+# hacky way to get package logger when running as module
+logger = logging.getLogger(__package__ + "." + __file__)
 
 
 def parse_args(argv):
-    import argparse
-
     apars = argparse.ArgumentParser(
         formatter_class=argparse.ArgumentDefaultsHelpFormatter
     )
 
     apars.add_argument(
         "--mq_evidence",
         default=None,
         metavar="EV",
-        required=True,
         nargs="+",
         help="""MaxQuant evidence file.""",
     )
 
     apars.add_argument(
+        "--fragpipe_psm",
+        default=None,
+        metavar="PSM",
+        nargs="+",
+        help="""Fragpipe psm.tsv output file(s); alternative for 
+                --mq_evidence.""",
+    )
+
+    apars.add_argument(
+        "--combined_ion",
+        default=None,
+        metavar="I",
+        nargs="+",
+        help="""Path to combined_ion.tsv produced by IonQuant/FragPipe. This enables
+                quantification of protein groups by PickedGroupFDR.""",
+    )
+
+    apars.add_argument(
         "--mq_protein_groups",
         default=None,
         metavar="PG",
-        required=True,
         help="""MaxQuant protein groups file.""",
     )
 
     apars.add_argument(
+        "--combined_protein",
+        default=None,
+        metavar="PG",
+        help="""Protein groups file in combined_protein.tsv MSFragger format.""",
+    )
+
+    apars.add_argument(
         "--protein_groups_out",
         default=None,
         metavar="PG",
         required=True,
-        help="""Protein groups output file, mimicks a subset of the MQ protein groups columns.
-                                """,
+        help="""Protein groups output file, mimicks a subset of the MQ protein groups columns.""",
+    )
+
+    apars.add_argument(
+        "--output_format",
+        default="auto",
+        metavar="PG",
+        help="""Protein groups output format. Options are "auto", "maxquant" and 
+                "fragpipe". "auto": decide based on input file format, uses
+                "maxquant" if no suitable format is known; "maxquant": proteinGroups.txt
+                format; "fragpipe": combined_protein.tsv format.""",
     )
 
     apars.add_argument(
         "--peptide_protein_map",
         default=None,
         metavar="M",
-        help="""TSV file with mapping from peptides to proteins.""",
+        nargs="+",
+        help="""Tab-separated file with mapping from peptides to proteins; alternative for 
+                --fasta flag if digestion is time consuming.""",
     )
 
     apars.add_argument(
         "--fasta",
         default=None,
         metavar="F",
         nargs="+",
@@ -76,14 +124,20 @@
 
     apars.add_argument(
         "--gene_level",
         help="""Do quantification on gene-level instead of on protein group level""",
         action="store_true",
     )
 
+    apars.add_argument(
+        "--suppress_missing_peptide_warning",
+        help="Suppress missing peptide warning when mapping peptides to proteins.",
+        action="store_true",
+    )
+
     digestion_params.add_digestion_arguments(apars)
 
     add_quant_arguments(apars)
 
     # ------------------------------------------------
     args = apars.parse_args(argv)
 
@@ -96,14 +150,20 @@
         default=0.01,
         metavar="C",
         type=float,
         help="PSM-level FDR threshold used for filtering PSMs for quantification.",
     )
 
     apars.add_argument(
+        "--skip_lfq",
+        help="Skip LFQ quantification, this significantly speeds up quantification.",
+        action="store_true",
+    )
+
+    apars.add_argument(
         "--lfq_min_peptide_ratios",
         default=2,
         type=int,
         metavar="M",
         help="""Minimum number of common peptides between two samples
                 to qualify for calculating a peptide ratio in LFQ.""",
     )
@@ -137,104 +197,142 @@
         metavar="L",
         help="""[deprecated in favor of --experimental_design_file] Tab separated file 
                 with lines of the format (third and fourth columns are optional): 
                 raw_file <tab> condition <tab> experiment <tab> fraction.""",
     )
 
 
+def do_quantification(
+    score_type: ProteinScoringStrategy,
+    args: argparse.Namespace,
+    protein_group_results: ProteinGroupResults,
+    protein_annotations: Dict[str, protein_annotation.ProteinAnnotation],
+    use_pseudo_genes: bool,
+    peptide_to_protein_maps: List[digest.PeptideToProteinMap],
+    suppress_missing_peptide_warning: bool,
+) -> Tuple[ProteinGroupResults, writers.ProteinGroupsWriter, List]:
+    if not score_type.can_do_quantification():
+        logger.warning(
+            "Skipping quantification: need input file with precursor quantifications."
+        )
+        return protein_group_results
+
+    logger.info("Preparing for quantification")
+
+    score_origin = score_type.score_origin.long_description().lower()
+    if args.output_format == "auto" and score_origin in ["maxquant", "fragpipe"]:
+        args.output_format = score_origin
+
+    parse_id = digest.parse_until_first_space
+    if args.gene_level and not use_pseudo_genes:
+        parse_id = protein_annotation.parse_gene_name_func
+
+    protein_groups_writer = writers.get_protein_groups_output_writer(
+        protein_group_results,
+        args.output_format,
+        args,
+        protein_annotations,
+        parse_id,
+        peptide_to_protein_maps,
+    )
+
+    protein_groups = ProteinGroups.from_protein_group_results(protein_group_results)
+    experimental_design = get_experimental_design(args)
+    discard_shared_peptides = True
+    protein_group_results, post_err_probs = score_type.get_quantification_parser()(
+        score_type.get_evidence_file(args),
+        score_type.get_quantification_file(args),
+        protein_groups,
+        protein_group_results,
+        peptide_to_protein_maps,
+        experimental_design,
+        discard_shared_peptides,
+        score_type=score_type,
+        suppress_missing_peptide_warning=suppress_missing_peptide_warning,
+    )
+
+    return protein_group_results, protein_groups_writer, post_err_probs
+
+
 def main(argv) -> None:
     logger.info(
         f'Issued command: {os.path.basename(__file__)} {" ".join(map(str, argv))}'
     )
 
     args = parse_args(argv)
 
     parse_id = digest.parse_until_first_space
     if args.gene_level:
         parse_id = protein_annotation.parse_gene_name_func
     elif args.fasta_use_uniprot_id:
         parse_id = protein_annotation.parse_uniprot_id
     db = "target" if args.fasta_contains_decoys else "concat"
 
-    (
-        peptide_to_protein_maps,
-        num_ibaq_peptides_per_protein,
-    ) = get_peptide_to_protein_maps(args, parse_id=parse_id)
-
-    protein_annotations = protein_annotation.get_protein_annotations_multiple(
-        args.fasta, db=db, parse_id=parse_id
-    )
-    protein_sequences = digest.get_protein_sequences(
-        args.fasta, db=db, parse_id=parse_id
+    peptide_to_protein_maps = peptide_protein_map.get_peptide_to_protein_maps_from_args(
+        args, use_pseudo_genes=False
     )
 
-    protein_group_results = maxquant.parse_mq_protein_groups_file(
-        args.mq_protein_groups,
-        additional_headers=pa.MQ_PROTEIN_ANNOTATION_HEADERS,
-    )
+    protein_annotations = dict()
+    if args.fasta:
+        protein_annotations = protein_annotation.get_protein_annotations_multiple(
+            args.fasta, db=db, parse_id=parse_id
+        )
 
-    experimental_design = get_experimental_design(args)
+    score_type_string = "bestPEP"
+    if peptide_to_protein_maps == [None]:
+        score_type_string = "no_remap bestPEP"
+    
+    if args.mq_protein_groups:
+        protein_group_results = maxquant.parse_mq_protein_groups_file(
+            args.mq_protein_groups
+        )
+    elif args.combined_protein:
+        protein_group_results = fragpipe.parse_fragpipe_combined_protein_file(
+            args.combined_protein
+        )
+        score_type_string = "FragPipe " + score_type_string
+    else:
+        raise ValueError("Need either --mq_protein_groups or --combined_protein as input to read protein groups from.")
 
-    params = init_triqler_params(experimental_design)
-    protein_groups_writer = writers.MaxQuantProteinGroupsWriter(
-        num_ibaq_peptides_per_protein,
-        protein_annotations,
-        protein_sequences,
-        args.lfq_min_peptide_ratios,
-        args.lfq_stabilize_large_ratios,
-        args.num_threads,
-        params,
-    )
+    score_type = ProteinScoringStrategy(score_type_string)
 
-    protein_group_results, post_err_probs = mq_quant.add_precursor_quants(
+    use_pseudo_genes = False
+    (
         protein_group_results,
-        args.mq_evidence,
+        protein_groups_writer,
+        post_err_probs,
+    ) = do_quantification(
+        score_type,
+        args,
+        protein_group_results,
+        protein_annotations,
+        use_pseudo_genes,
         peptide_to_protein_maps,
-        experimental_design,
-        discard_shared_peptides=True,
-    )
-
-    protein_group_results = protein_groups_writer.append_quant_columns(
-        protein_group_results, post_err_probs, args.psm_fdr_cutoff
+        args.suppress_missing_peptide_warning,
     )
 
-    protein_group_results.write(args.protein_groups_out)
-
-    logger.info(
-        f"Protein group results have been written to: {args.protein_groups_out}"
+    apply_filename_suffix = False
+    method_config = None
+    writers.finalize_output(
+        protein_group_results,
+        protein_groups_writer,
+        post_err_probs,
+        args.protein_groups_out,
+        args.psm_fdr_cutoff,
+        apply_filename_suffix,
+        method_config,
     )
 
 
 def get_experimental_design(args):
     experimental_design = None
     if args.experimental_design_file:
         experimental_design = parsers.parse_mq_experimental_design(
             args.experimental_design_file
         )
     elif args.file_list_file:
         experimental_design = parsers.parse_triqler_file_list(args.file_list_file)
     return experimental_design
 
 
-def get_peptide_to_protein_maps(
-    args, **kwargs
-) -> Tuple[List[digest.PeptideToProteinMap], Dict[str, int]]:
-    logger.info("Loading peptide to protein map...")
-
-    digestion_params_list = digestion_params.get_digestion_params_list(args)
-    peptide_to_protein_maps = picked_group_fdr.get_peptide_to_protein_maps(
-        args.fasta,
-        args.peptide_protein_map,
-        digestion_params_list,
-        args.mq_protein_groups,
-        **kwargs,
-    )
-
-    num_ibaq_peptides_per_protein = digest.get_num_ibaq_peptides_per_protein_from_args(
-        args, peptide_to_protein_maps
-    )
-
-    return peptide_to_protein_maps, num_ibaq_peptides_per_protein
-
-
 if __name__ == "__main__":
     main(sys.argv[1:])
```

## picked_group_fdr/score_origin.py

```diff
@@ -96,14 +96,19 @@
     def short_description(self):
         return 'm'
 
     def long_description(self):
         return 'MaxQuant'
 
 
+class MaxQuantInputNoRemap(MaxQuantInput):
+    def remaps_peptides_to_proteins(self):
+        return False
+
+
 class FragPipeInput(ScoreOrigin):
     def get_evidence_file(self, args):
         return args.fragpipe_psm
 
     def get_evidence_parser(self):
         return fragpipe.parse_fragpipe_psm_file
```

## picked_group_fdr/scoring.py

```diff
@@ -2,16 +2,15 @@
 import logging
 
 import numpy as np
 
 
 from . import helpers
 from . import fdr
-from .parsers import parsers
-
+from .parsers import protein_groups as pgp
 
 logger = logging.getLogger(__name__)
 
 
 """
 N.B.: Higher protein score indicates more confident identification
 
@@ -67,15 +66,15 @@
         return 'm'
     
     def long_description(self):
         return 'multiplication of'
         
     def get_protein_scores_from_file(self):
         protein_group_peptide_infos = list()
-        for protein_group, protein_score in parsers.parse_protein_groups_file_single(self.mq_protein_groups_file):
+        for protein_group, protein_score in pgp.parse_protein_groups_file_single(self.mq_protein_groups_file):
             protein_group_peptide_infos.append([(protein_score, "NA", protein_group)])
         return protein_group_peptide_infos
 
 
 class BestAndromedaScore(ProteinScore):
     def calculate_score(self, score_peptide_pairs):
         return max([y[0] for y in score_peptide_pairs]) if len(score_peptide_pairs) > 0 else -100.0
```

## picked_group_fdr/scoring_strategy.py

```diff
@@ -1,31 +1,36 @@
+from __future__ import annotations
+
 import hashlib
 import logging
 from typing import Callable, Dict, List
 
 from . import fdr, helpers
 from .observed_peptides import ObservedPeptides
-from .peptide_info import PeptideInfoList, ProteinGroupPeptideInfos
-from .protein_groups import ProteinGroups
 from .scoring import (
     BestAndromedaScore,
     BestPEPScore,
     MQProteinScore,
     MultPEPScore,
     ProteinScore,
 )
 from .score_origin import (
     FragPipeInput,
     MaxQuantInput,
+    MaxQuantInputNoRemap,
     PercolatorInput,
     PercolatorInputRemapped,
     SageInput,
     ScoreOrigin,
 )
 
+# for type hints only
+from .protein_groups import ProteinGroups
+from .peptide_info import PeptideInfoList, ProteinGroupPeptideInfos
+
 logger = logging.getLogger(__name__)
 
 
 class ProteinScoringStrategy:
     use_razor: bool
     use_shared_peptides: bool
     protein_score: ProteinScore
@@ -59,15 +64,18 @@
             else:
                 self.score_origin = PercolatorInput()
         elif "FragPipe" in score_description:
             self.score_origin = FragPipeInput()
         elif "Sage" in score_description:
             self.score_origin = SageInput()
         else:
-            self.score_origin = MaxQuantInput()
+            if "no_remap" in score_description:
+                self.score_origin = MaxQuantInputNoRemap()
+            else:
+                self.score_origin = MaxQuantInput()
 
     def get_evidence_file(self, args) -> str:
         return self.score_origin.get_evidence_file(args)
 
     def get_evidence_parser(self) -> Callable:
         return self.score_origin.get_evidence_parser()
 
@@ -166,15 +174,15 @@
         suppress_missing_protein_warning: bool = False,
     ) -> ProteinGroupPeptideInfos:
         """Groups peptides with associated scores by protein
 
         :param protein_groups: ProteinGroups object
         :param peptide_info_list: Dict of peptide -> (score, proteins)
         :param suppress_missing_protein_warning: suppresses the warning for missing proteins
-            in the proteiprotein_groupsnGroups object. This is set during the rescuing grouping procedure
+            in the proteinGroups object. This is set during the rescuing grouping procedure
             since some protein groups will have been filtered out in the rescuing step.
         :returns: lists of (score, peptide, proteins) tuples per protein group
         """
         if not self.get_score_column():
             return self.protein_score.get_protein_scores_from_file()
 
         logger.info("Assigning peptides to protein groups")
```

## picked_group_fdr/writers/__init__.py

```diff
@@ -1,9 +1,10 @@
 from .base import (
-    format_extra_columns,
+    finalize_output,
+    write_protein_groups,
     PROTEIN_GROUP_HEADERS,
     ProteinGroupsWriter,
 )
 
 from .factory import get_protein_groups_output_writer
 
 from .minimal import MinimalProteinGroupsWriter
```

## picked_group_fdr/writers/base.py

```diff
@@ -1,22 +1,25 @@
 from __future__ import annotations
 
 import collections
 import logging
-from typing import Dict, List, Union
+from pathlib import Path
+from typing import Dict, List, Union, TYPE_CHECKING
 
 import numpy as np
 
 from .. import fdr
 from .. import helpers
 
 # for type hints only
-from .. import results
-from .. import columns
-from ..precursor_quant import PrecursorQuant
+if TYPE_CHECKING:
+    from .. import results
+    from .. import columns
+    from .. import methods
+    from .. import precursor_quant
 
 logger = logging.getLogger(__name__)
 
 PROTEIN_GROUP_HEADERS = [
     "Protein IDs",
     "Majority protein IDs",
     "Peptide counts (unique)",
@@ -35,15 +38,15 @@
     ) -> Dict[str, str]:
         return {x: x for x in protein_group_results.headers}
 
     def get_columns(self) -> List[columns.ProteinGroupColumns]:
         pass
 
     def get_extra_columns_formatter(self):
-        return format_extra_columns
+        return _format_extra_columns
 
     def append_quant_columns(
         self,
         protein_group_results: results.ProteinGroupResults,
         post_err_probs: List,
         psm_fdr_cutoff: float,
     ):
@@ -83,16 +86,27 @@
         protein_group_results.write(
             protein_groups_out_file,
             header_dict=self.get_header_dict(protein_group_results),
             format_extra_columns=self.get_extra_columns_formatter(),
         )
 
 
+def write_protein_groups(
+    protein_groups_writer: ProteinGroupsWriter,
+    protein_group_results: results.ProteinGroupResults,
+    protein_groups_out: str,
+) -> None:
+    Path(protein_groups_out).parent.mkdir(parents=True, exist_ok=True)
+
+    protein_groups_writer.write(protein_group_results, protein_groups_out)
+    logger.info(f"Protein group results have been written to: {protein_groups_out}")
+
+
 def _retain_only_identified_precursors(
-    precursor_list: List[PrecursorQuant], post_err_prob_cutoff
+    precursor_list: List[precursor_quant.PrecursorQuant], post_err_prob_cutoff
 ):
     identified_precursors = set()
     for precursor in precursor_list:
         if precursor.post_err_prob <= post_err_prob_cutoff:
             identified_precursors.add((precursor.peptide, precursor.charge))
     return [
         precursor_row
@@ -133,15 +147,56 @@
             set(peptides + peptides_per_experiment_mbr[experiment])
         )
         logger.info(
             f"    {experiment}: {num_peptides} {'(' + str(num_peptides_with_mbr) + ' with MBR)' if num_peptides_with_mbr > num_peptides else ''}"
         )
 
 
-def format_extra_columns(x: Union[str, float]) -> str:
+def _format_extra_columns(x: Union[str, float]) -> str:
     if type(x) == str:
         return x
     if np.isnan(x):
         return ""
     return "%.0f" % (x)
 
 
+def _get_output_filename(
+    protein_groups_out: Path,
+    apply_filename_suffix: bool,
+    method_config: methods.MethodConfig,
+):
+    if not apply_filename_suffix:
+        return protein_groups_out
+
+    protein_groups_out = Path(protein_groups_out)
+    label = method_config.label
+    if label is None:
+        label = method_config.short_description(rescue_step=True)
+    else:
+        label = label.lower().replace(" ", "_")
+    return f"{protein_groups_out.stem}_{label}{protein_groups_out.suffix}"
+
+
+def finalize_output(
+    protein_group_results: results.ProteinGroupResults,
+    protein_groups_writer: ProteinGroupsWriter,
+    post_err_probs: List,
+    protein_groups_out: str,
+    psm_fdr_cutoff: float,
+    apply_filename_suffix: bool,
+    method_config: methods.MethodConfig,
+):
+    protein_groups_writer.append_quant_columns(
+        protein_group_results, post_err_probs, psm_fdr_cutoff
+    )
+
+    if not protein_groups_out:
+        return
+
+    protein_groups_out = _get_output_filename(
+        protein_groups_out, apply_filename_suffix, method_config
+    )
+    write_protein_groups(
+        protein_groups_writer,
+        protein_group_results,
+        protein_groups_out,
+    )
```

## picked_group_fdr/writers/factory.py

```diff
@@ -17,39 +17,41 @@
     protein_group_results: results.ProteinGroupResults,
     output_format: str,
     args: argparse.Namespace,
     protein_annotations: Dict[str, protein_annotation.ProteinAnnotation],
     parse_id: Callable,
     peptide_to_protein_maps: List[digest.PeptideToProteinMap],
 ):
-    if args.output_format == "fragpipe":
+    if output_format == "fragpipe":
         protein_groups = ProteinGroups.from_protein_group_results(protein_group_results)
         protein_groups.create_index()
         return writers.FragPipeCombinedProteinWriter(
             protein_groups,
             protein_annotations,
+            args.skip_lfq,
             args.lfq_min_peptide_ratios,
             args.lfq_stabilize_large_ratios,
             args.num_threads,
         )
-    elif args.output_format == "maxquant":
+    elif output_format == "maxquant":
         db = "target" if args.fasta_contains_decoys else "concat"
         protein_sequences = digest.get_protein_sequences(
             args.fasta, db=db, parse_id=parse_id
         )
         num_ibaq_peptides_per_protein = (
             digest.get_num_ibaq_peptides_per_protein_from_args(
                 args, peptide_to_protein_maps
             )
         )
         triqler_params = init_triqler_params(args.file_list_file)
         return writers.MaxQuantProteinGroupsWriter(
             num_ibaq_peptides_per_protein,
             protein_annotations,
             protein_sequences,
+            args.skip_lfq,
             args.lfq_min_peptide_ratios,
             args.lfq_stabilize_large_ratios,
             args.num_threads,
             triqler_params,
         )
     
-    raise ValueError(f"Unknown output format: {args.output_format}.")
+    raise ValueError(f"Unknown output format: {output_format}.")
```

## picked_group_fdr/writers/fragpipe_combined.py

```diff
@@ -26,82 +26,110 @@
     "Description": "Protein Description",
     "Protein Probability": "Protein Probability",
     "Top Peptide Probability": "Top Peptide Probability",
     "Combined Total Peptides": "Combined Total Peptides",
     "Combined Spectral Count": "Combined Spectral Count",
     "Combined Unique Spectral Count": "Combined Spectral Count",
     "Combined Total Spectral Count": "Combined Spectral Count",
+    # the following columns are not part of Fragpipe's format but were added upon popular demand
+    "Majority protein IDs": "Majority protein IDs",
+    "Q-value": "Q-value",
+    "Score": "Score",
+    "Reverse": "Reverse",
+    "Potential contaminant": "Potential contaminant",
 }
 
 
 class FragPipeCombinedProteinWriter(ProteinGroupsWriter):
     def __init__(
         self,
         protein_groups: ProteinGroups,
         protein_annotations: Dict[str, pa.ProteinAnnotation],
+        skip_lfq: bool = False,
         min_peptide_ratios_lfq: int = 1,
         stabilize_large_ratios_lfq: bool = True,
         num_threads: int = 1,
     ) -> None:
         self.protein_groups = protein_groups
         self.protein_annotations = protein_annotations
+        self.skip_lfq = skip_lfq
         self.min_peptide_ratios_lfq = min_peptide_ratios_lfq
         self.stabilize_large_ratios_lfq = stabilize_large_ratios_lfq
         self.num_threads = num_threads
 
-    def get_header_dict(self, protein_group_results: results.ProteinGroupResults) -> Dict[str, str]:
+    def get_header_dict(
+        self, protein_group_results: results.ProteinGroupResults
+    ) -> Dict[str, str]:
         """Adds experiment specific headers.
 
         - <Experiment> Spectral Count
         - <Experiment> Unique Spectral Count
         - <Experiment> Total Spectral Count
         - <Experiment> Intensity
         - <Experiment> MaxLFQ Intensity
+
+        - <Experiment> iBAQ Intensity
+        - <Experiment> Unique Peptide Count
         """
         experiments = protein_group_results.experiments
         header_dict = FRAGPIPE_COMBINED_PROTEIN_OUTPUT_DICT.copy()
         for experiment in experiments:
             header_dict[f"{experiment} Spectra Count"] = f"Spectral count {experiment}"
 
         for experiment in experiments:
-            header_dict[
-                f"{experiment} Unique Spectra Count"
-            ] = f"Spectral count {experiment}"
+            header_dict[f"{experiment} Unique Spectra Count"] = (
+                f"Spectral count {experiment}"
+            )
 
         for experiment in experiments:
-            header_dict[
-                f"{experiment} Total Spectra Count"
-            ] = f"Spectral count {experiment}"
+            header_dict[f"{experiment} Total Spectra Count"] = (
+                f"Spectral count {experiment}"
+            )
 
         for experiment in experiments:
             header_dict[f"{experiment} Intensity"] = f"Intensity {experiment}"
 
-        if len(experiments) > 1:
+        if len(experiments) > 1 and not self.skip_lfq:
             for experiment in experiments:
-                header_dict[f"{experiment} MaxLFQ Intensity"] = f"LFQ Intensity {experiment}"
+                header_dict[f"{experiment} MaxLFQ Intensity"] = (
+                    f"LFQ Intensity {experiment}"
+                )
+
+        # the iBAQ and peptide counts columns are not part of Fragpipe's format but were added upon popular demand
+        for experiment in experiments:
+            header_dict[f"{experiment} iBAQ Intensity"] = f"iBAQ {experiment}"
+
+        for experiment in experiments:
+            header_dict[f"{experiment} Unique Peptide Count"] = (
+                f"Unique peptides {experiment}"
+            )
 
         header_dict["Indistinguishable Proteins"] = "Indistinguishable Proteins"
 
         return header_dict
-        
+
     def get_columns(self) -> List[columns.ProteinGroupColumns]:
         num_ibaq_peptides_per_protein = collections.defaultdict(lambda: 1)
 
-        return [
+        output_columns = [
             columns.FragpipeProteinAnnotationsColumns(
                 self.protein_groups, self.protein_annotations
             ),
             columns.ProteinProbabilityColumns(),
             columns.TopPeptideProbabilityColumns(),
             columns.UniquePeptideCountColumns(),
             columns.SpectralCountColumns(),
             columns.SummedIntensityAndIbaqColumns(num_ibaq_peptides_per_protein),
-            columns.LFQIntensityColumns(
-                self.min_peptide_ratios_lfq,
-                self.stabilize_large_ratios_lfq,
-                self.num_threads,
-            ),
             columns.IndistinguishableProteinsColumns(),
         ]
-    
+        if not self.skip_lfq:
+            output_columns += [
+                columns.LFQIntensityColumns(
+                    self.min_peptide_ratios_lfq,
+                    self.stabilize_large_ratios_lfq,
+                    self.num_threads,
+                )
+            ]
+        return output_columns
+
     def get_extra_columns_formatter(self):
-        return fragpipe_format_extra_columns
+        return fragpipe_format_extra_columns
```

## picked_group_fdr/writers/maxquant.py

```diff
@@ -11,36 +11,42 @@
 
 class MaxQuantProteinGroupsWriter(ProteinGroupsWriter):
     def __init__(
         self,
         num_ibaq_peptides_per_protein: Dict[str, int],
         protein_annotations: Dict[str, pa.ProteinAnnotation],
         protein_sequences: Dict[str, str],
+        skip_lfq: bool,
         min_peptide_ratios_lfq: int,
         stabilize_large_ratios_lfq: bool,
         num_threads: int,
         params: Dict[str, Any],
     ) -> None:
         self.num_ibaq_peptides_per_protein = num_ibaq_peptides_per_protein
         self.protein_annotations = protein_annotations
         self.protein_sequences = protein_sequences
+        self.skip_lfq = skip_lfq
         self.min_peptide_ratios_lfq = min_peptide_ratios_lfq
         self.stabilize_large_ratios_lfq = stabilize_large_ratios_lfq
         self.num_threads = num_threads
-        self.params = params    
-        
+        self.params = params
+
     def get_columns(self) -> List[columns.ProteinGroupColumns]:
-        return [
+        output_columns = [
             columns.ProteinAnnotationsColumns(self.protein_annotations),
             columns.UniquePeptideCountColumns(),
             columns.IdentificationTypeColumns(),
             columns.SummedIntensityAndIbaqColumns(self.num_ibaq_peptides_per_protein),
             columns.SequenceCoverageColumns(self.protein_sequences),
             columns.EvidenceIdsColumns(),
-            columns.LFQIntensityColumns(
-                self.min_peptide_ratios_lfq,
-                self.stabilize_large_ratios_lfq,
-                self.num_threads,
-            ),
             columns.TMTIntensityColumns(),
             columns.TriqlerIntensityColumns(self.params),
         ]
+        if not self.skip_lfq:
+            output_columns += [
+                columns.LFQIntensityColumns(
+                    self.min_peptide_ratios_lfq,
+                    self.stabilize_large_ratios_lfq,
+                    self.num_threads,
+                )
+            ]
+        return output_columns
```

## Comparing `picked_group_fdr-0.6.6.dist-info/LICENSE` & `picked_group_fdr-0.7.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `picked_group_fdr-0.6.6.dist-info/RECORD` & `picked_group_fdr-0.7.0.dist-info/RECORD`

 * *Files 5% similar despite different names*

```diff
@@ -1,37 +1,37 @@
 LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
 picked_group_fdr/__init__.py,sha256=WzNppaILncZEOeed0aEurAljPYZ9mNTgxKVrOfofK_Q,1528
 picked_group_fdr/__main__.py,sha256=QNyYCG7bIs9oec0-jwSyT7ztKA4CBC0A9dISNAzrTXo,180
 picked_group_fdr/columns/__init__.py,sha256=dHIBeZpr--BB3w0Tixi1bc3WP7NyVuQjz9orhcsMHgM,831
 picked_group_fdr/columns/base.py,sha256=xOtMzlWyTeopB1ynLUEz6Fyb4AieAgX38AS8lxy90D0,911
-picked_group_fdr/columns/evidence_ids.py,sha256=g4CNRyDoAG6ojJqTY8dAM2fyR4nb-dJ0zZm3EWA9Xs0,1307
-picked_group_fdr/columns/fragpipe_protein_annotations.py,sha256=VoOWZyLj5_10XQR_y_kYf894uTnMEAuTF_-m2p487Ok,2281
-picked_group_fdr/columns/id_type.py,sha256=t9thldvvBmppDe9rAdT-TyuldWH3t_rWP-XKJxAe1cg,1664
-picked_group_fdr/columns/indistinguishable_proteins.py,sha256=yyuU3fNFgLBy9PNGxfNb9ipx243wWRepH_c6YMMOWH0,1229
-picked_group_fdr/columns/lfq.py,sha256=G-27SA4cvMQwjuVkzL3kJmaPTsfxBDkPPQZGGjuNCbw,13549
-picked_group_fdr/columns/modifications.py,sha256=bg5UN9V-e45z-xv0D7wZIRZJc7wtbrUvy8I8QbAbx5U,1809
-picked_group_fdr/columns/peptide_count.py,sha256=Ij1fOL3is2Dz8h2B9wPfSCALw7zpckTEOlsICoX59rI,2341
+picked_group_fdr/columns/evidence_ids.py,sha256=k0Kd2HNq1u2Wi3gM4_vxzWxF8PC33qM_msjsHUrEgy4,1301
+picked_group_fdr/columns/fragpipe_protein_annotations.py,sha256=BXRkHll7kRw-NXjF3WA9MjPR2sDF5zn0MxfKknnRCck,2313
+picked_group_fdr/columns/id_type.py,sha256=g3h0VV_Kk1r7zgzb7yaY-HEOKg5dOoaM-LrQeXd-E_o,1666
+picked_group_fdr/columns/indistinguishable_proteins.py,sha256=PXwzKcbR4aq7PwsPB-gA0MQFvzaqLpp6YoNLSIYlSt0,1226
+picked_group_fdr/columns/lfq.py,sha256=Q5kzHq6FV65qYvVE_2-Lvx9ASsuNVCmPa2lF2eie4Rk,13615
+picked_group_fdr/columns/modifications.py,sha256=oRldgUEYtFwScuqg8CqqLVoKbnkAuv584A1Xe29KBPM,1805
+picked_group_fdr/columns/peptide_count.py,sha256=ryssPzjU3gYJeWtuCnIJNrLhkFdb6bb9M5FKt2dUos4,2359
 picked_group_fdr/columns/protein_annotations.py,sha256=R6xdPfoiT_H4_tzpjI-nGpV6wIu5fgJYD_hEs79Fi5Q,1932
 picked_group_fdr/columns/protein_probability.py,sha256=5IvKV14LRhOovMOzVxvgI-L_RcE9Zese4kdpxC5-Y1k,3225
-picked_group_fdr/columns/sequence_coverage.py,sha256=12J_X7T8JvrEDpFO6SPHpqHhORD96SekMBA6qbbkXBU,4645
-picked_group_fdr/columns/spectral_count.py,sha256=gxxTf-2ii_7Na03WFjioJvAcPCM_zpne2qkzRO3ECt4,1717
-picked_group_fdr/columns/sum_and_ibaq.py,sha256=kS8F20PR-5Wnnw1smg23iC8w-3rMqOd85k0LK2-A_E0,5231
-picked_group_fdr/columns/tmt.py,sha256=ovhRR8wknB3Bg_K26M9z6aGwhJf7cDS7oYqrWGYmL44,2505
-picked_group_fdr/columns/top_peptide.py,sha256=wqc61fjmVzeyn8IC8r7QgkjlQzFFCUKFQ7NhGIjgvqM,1368
-picked_group_fdr/columns/triqler.py,sha256=AseIuByR34iJ-2oZ9RqCmm77Io2u9i_hibRkK6H5T4A,9141
-picked_group_fdr/competition.py,sha256=TbsStZrjQnJlCZ7krX9KEq-ZQj1BabjCAcXZh5toiNg,6873
-picked_group_fdr/digest.py,sha256=EY3uwAWO369rJ7aO1lukdF8EYE7Z7L13pbtpgcfDBHg,21784
+picked_group_fdr/columns/sequence_coverage.py,sha256=iebKPbIj43aYlavIrZGzbIPwQVFAhjFbP4foH7oaIcs,4663
+picked_group_fdr/columns/spectral_count.py,sha256=g-Z0EJoQjb5zbDxF6G89Rwtl7mkqwC7sM3_de6XqfVg,1719
+picked_group_fdr/columns/sum_and_ibaq.py,sha256=UtEuK9lpo7LAMdQHTBXJenrpltMlVZ7okwjz7WsbOp8,5222
+picked_group_fdr/columns/tmt.py,sha256=AtWYvx9lAWPQmibjzFvG-L6lmtkRnC8PHAROL1XJ60g,2507
+picked_group_fdr/columns/top_peptide.py,sha256=2VngPT57HGEAHO_UbaWqOvBo-v1Db4A4FAkEWaoSLgg,1364
+picked_group_fdr/columns/triqler.py,sha256=eIoeZcAm6onLa7NGqx8EPPh4Dy4SyzTcDpAhNued5Ao,9173
+picked_group_fdr/competition.py,sha256=WUi4AIBpv2_6KPSqumMebJRAKD3SHS7QrcaB4Q5tU-s,6910
+picked_group_fdr/digest.py,sha256=IQ7PJpKbKEkXyw9W4ljfv9TK2zCXTp8g_1M83X_2eQ4,21844
 picked_group_fdr/digestfast.cpp,sha256=9v4bAVrBbUIC2Kxs6AuKhVm0inyUEtKyiZ4MgFDTasI,432703
 picked_group_fdr/digestfast.html,sha256=arq6PjwdayY1Znx8UfZHpqQpkQYGfR9Pf0CzEIw5DPQ,220141
 picked_group_fdr/digestfast.pyx,sha256=oyKJnFAHQdXB0pT2Z20FVMTwSEMKDlGCz3IvaJnBiuk,3923
 picked_group_fdr/digestion_params.py,sha256=BixwgihrTfg9vdHEbNzGVIPvI9Z48gmWYjtRr47E_Co,5058
-picked_group_fdr/entrapment.py,sha256=XL16p8aSeh4GiVaVh5pryRyjmTS_No1bZRJZxPJwvjA,1893
+picked_group_fdr/entrapment.py,sha256=hURBJ4rhUHq-ZbRn8pQqVLyYdSjbLDc1wLETuzwAbrM,1903
 picked_group_fdr/fdr.py,sha256=-PdN5oykSWvYgXzJpOw7dC2yy6PozlU9vWMIS1te9_w,7231
 picked_group_fdr/graphs.py,sha256=Tuzc72ZCjdXczR9QUw7zonk0UWyD6IbHio6ItxmZEOA,5843
-picked_group_fdr/grouping.py,sha256=NTVxAmiQRsVdmsudwz9hyi8wpv_6ajZNE5nu0EVM9zU,10867
+picked_group_fdr/grouping.py,sha256=mbZ4keuw3Ak-5kzfyteE-qUWkW8C3h0Dmy8g1exPtWI,10915
 picked_group_fdr/helpers.py,sha256=eLZ3I4OlBzPlt3kVcrX9WuS2R8jF2nF6vpg1W8gUkRY,3200
 picked_group_fdr/methods/classic_no_grouping.toml,sha256=ALOogabOiCT0rqTx3quf9m-LbT-Z1AYWkEWIpYUPUeY,134
 picked_group_fdr/methods/classic_no_grouping_no_remap.toml,sha256=YhIXLd9RdiqF5EiHhkNI4YF5KVyakyPzSsbNGIhK93c,128
 picked_group_fdr/methods/classic_protein_group.toml,sha256=LRsZDr7ARiHryHzPbYXpssW9y_y8L6Vm5S54UKYWBic,152
 picked_group_fdr/methods/classic_rescued_subset_grouping.toml,sha256=COrWDPdv_io2LQpCMSZ8I67yquEe9AWN9kgDyQkvvHE,158
 picked_group_fdr/methods/classic_subset_grouping.toml,sha256=DTGQN82ioaKAx4PZd8eO4njBbGhY6BBmvkarI4VcYvw,142
 picked_group_fdr/methods/discard_picked.toml,sha256=5BKD6xZHc-_mehX2FMP-c2djsNMFAEyQuxwMBkRaOf8,142
@@ -41,70 +41,75 @@
 picked_group_fdr/methods/maxquant_mq_best.toml,sha256=gbnQPr5fBq-7IkVRkeHxgpowsgUDzoJmM2JAh0tBziY,128
 picked_group_fdr/methods/maxquant_mq_best_picked.toml,sha256=-PJ0eoyyWbnlcw51aHK7yoiDl9O8ORTeTTxwD71IIiI,148
 picked_group_fdr/methods/maxquant_perc_best.toml,sha256=lH2RbRudSq1ILOxd4vZk_kogmlzOmQ4emHomDMkPJQA,133
 picked_group_fdr/methods/maxquant_perc_best_picked.toml,sha256=kkUa3FF9mSMj7Pon75-U4UBsGw0q5L-UIkJcE9amKAU,155
 picked_group_fdr/methods/maxquant_picked.toml,sha256=vtHS4gfySu16rc-AE0nWg42LklDHZbyROjzCTn8JPK8,134
 picked_group_fdr/methods/picked_protein_group.toml,sha256=zCxhbLrKqyUbvkv6aa8YV_HR6fGKSZ-aDHAySUSqxWc,156
 picked_group_fdr/methods/picked_protein_group_mq_input.toml,sha256=avH06-gtSB9GF1nK2YJTOxDgPhVWxLw5QgYrYd4vb0w,145
+picked_group_fdr/methods/picked_protein_group_mq_input_no_remap.toml,sha256=sh54qGl457Y6ZIcwxJI7EdSZR8WPHsokHlAAGxQYL2s,154
 picked_group_fdr/methods/picked_protein_group_no_remap.toml,sha256=yYhloDaSt1nE6rjutKyYHSSSYfwp2oVzIvEh81u6VoU,150
 picked_group_fdr/methods/razor_picked.toml,sha256=CLGk34tf-nCAfwWayDzYLB04fOP3N8vflWDvlPci-48,138
 picked_group_fdr/methods/razor_picked_mq_input.toml,sha256=aa3UugGRRtDr5mk7Wcc9ewoVQcb8g9Q6ArnwWrrlP-k,127
 picked_group_fdr/methods/sage.toml,sha256=2oTwJkkqn7iTs6yg3sipmj74wy2br5yKteIDDSGIkBA,150
 picked_group_fdr/methods/savitski.toml,sha256=yAxpgHVLMMH1O6595tPAfha1_KfX-SydNKZRWsE_8K4,122
 picked_group_fdr/methods/savitski_classic.toml,sha256=sJytbWRGCnOBMrOQxaHOnrHOxAlk-BkZRcvbnaHO4dI,123
 picked_group_fdr/methods/savitski_mq_best.toml,sha256=07qBvp7ym3h_prrXz6bSOM0adeH4n5_COioTLgGs_KE,125
 picked_group_fdr/methods/savitski_mq_mult.toml,sha256=I_MfeYMMfAO0CwjXt8ksx7--pP4ZCy5f-Cs0THhtRPk,125
 picked_group_fdr/methods/savitski_no_remap.toml,sha256=xIfM2ap2M24bcOy-3-_8phe0Ub2KbJI-4HTiycmO_FI,116
-picked_group_fdr/methods.py,sha256=5isCZaI73gmsziUB08ij81Mn088RxxT1-5jPDwmtQlE,3514
+picked_group_fdr/methods.py,sha256=7px4b83Tc2kP1hFVa2sSKg2H3rKvVLnYfjmZD1sK2dw,5157
 picked_group_fdr/observed_peptides.py,sha256=2keendCWMBvYfFK_rj_ba-z8s54GAIaQEjVM4Af1wY8,7790
 picked_group_fdr/parsers/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-picked_group_fdr/parsers/fragpipe.py,sha256=MK07S7PiW1OwOkgohMOq3wE3lRAfiN0hJJpFWBJELl0,5007
-picked_group_fdr/parsers/maxquant.py,sha256=UwQ6tsp4vPyiorglkDO4BXXMcman8GZ8sG0mlPOVGBY,8752
+picked_group_fdr/parsers/evidence.py,sha256=DRY09AxPHXcT5uz8LtB7uZzLfY_nEs9fWJSoRPvOMCg,1062
+picked_group_fdr/parsers/fragpipe.py,sha256=1zpOdDpH2IuhB7eTjvAzY_BUILznQeMzQReu6tfNi3s,7169
+picked_group_fdr/parsers/maxquant.py,sha256=jbB7cv4rUWl9EVUnxBnFyIqdnrrIK2SAaVlCAjIEYBk,8800
 picked_group_fdr/parsers/modifications.py,sha256=A49Eszlwq41lOuFW-b0GpvJBQa_Jy9aum42SzMsDO2k,3597
-picked_group_fdr/parsers/parsers.py,sha256=s5DKKUYObblYcI8GweDjbOBaP7j0eX64hMyH1nPqI5w,6129
+picked_group_fdr/parsers/parsers.py,sha256=6830f9LLp-8M4KkQegUiIt0BXFDTOfjJpXnnhqH2p8I,4402
 picked_group_fdr/parsers/percolator.py,sha256=TQzAJ1zUrNXz_gDFPvISsAsNmD1GhJ7nqEOBMnVt06I,4684
-picked_group_fdr/parsers/psm.py,sha256=2S5KtP6ymRFrB7k9ojFJQn9BRq6m8td9YRb3C4ybMRA,3309
-picked_group_fdr/parsers/sage.py,sha256=VzntGJQ434_sCTGET1MOpx4LR2My0IuEawT-rrHCr8g,3510
+picked_group_fdr/parsers/protein_groups.py,sha256=A0seKwKOAgLTAyJygpj20oQz4SVw-chj4y_rkHYUtoQ,1823
+picked_group_fdr/parsers/psm.py,sha256=BhvSH1TwmBkOesFysqgmW-78PgHlq38OdZETmBPUElM,3480
+picked_group_fdr/parsers/sage.py,sha256=aUF6dJP5Rv1HbQjLct1lfgBVV4nYEe9q5Lg74us2Sq0,3533
 picked_group_fdr/parsers/tsv.py,sha256=d_9d6RVoT7nP_8cMN-e2LHaftkSqI36x-P6C3HUk4TA,1340
 picked_group_fdr/peptide_info.py,sha256=6uv6fbBAuiWWDfIpNMWrluLzxoe1jibiTiWqa_JpG7I,331
-picked_group_fdr/picked_group_fdr.py,sha256=0J7qp-m-gkWDa4olg2nEhz0TKH7fIedvx_nzAEdAn2c,17891
+picked_group_fdr/peptide_protein_map.py,sha256=mLUISXp63Ucg59hA7M_DWwOVQ8uukZvbpTI-yfVfvKY,2057
+picked_group_fdr/picked_group_fdr.py,sha256=yz30xuAzbPJiHKF2p3h_qvmtMO6UPtwn_DTJLpzzvcU,12242
 picked_group_fdr/pipeline/__init__.py,sha256=OqG91TEinJGsHvCLWgc2JMrmZtChZMtWgKclc21g_BA,317
+picked_group_fdr/pipeline/add_ibaq_columns.py,sha256=MDeA3fvAH4BNQ6sFiWnLg6VJ9eDFHV9oY7w-PvMWKq8,4147
 picked_group_fdr/pipeline/analyze_missing_peptides.py,sha256=PYlw975wR9XFccMSL_kk3d7i7j_jm-1GbpFqLYQHTJU,3516
-picked_group_fdr/pipeline/andromeda2pin.py,sha256=9FRjXmjvV8VM9fpEQUsD1OOzNdez9jZLguZlCLeHtVw,11365
-picked_group_fdr/pipeline/entrapment_fdr.py,sha256=YD-R1Ff3ObQpUCzFhlG2elZXzvXP4XLOUD9IobQAPpU,7355
+picked_group_fdr/pipeline/andromeda2pin.py,sha256=mzFAKTWKeow4TvIGiT3Vlp-2iibHNg3RaT9Za5Lac4E,12479
+picked_group_fdr/pipeline/entrapment_fdr.py,sha256=9GDTO5Pa_K934sNiaaGLhE-iw_8GAA7wJugLZQ9W8YI,7395
 picked_group_fdr/pipeline/filter_fdr_maxquant.py,sha256=nvgC6klorgano8TbR0l8s-uZ9r-0eUDopLZRACSwYDQ,14045
-picked_group_fdr/pipeline/merge_pout.py,sha256=t6OTGd_q2sDogZLbZ9v7hdLFNcvGazaJbgREF-H9SrM,6927
-picked_group_fdr/pipeline/pipeline.py,sha256=tr3E5NVDlxBdnbS3ZGlAuBHyJ06sqp1W0h8dQWUJLo0,7510
-picked_group_fdr/pipeline/run_mokapot.py,sha256=V4UgYcd2Zc6X2onbbodnrqdmiFzt17lAAOPt6eM-TJ8,2013
-picked_group_fdr/pipeline/sage_quantification.py,sha256=janbK8-98hSYxH-ZLp6Xtm-8be40eEYAnGPrKx69r94,4050
-picked_group_fdr/pipeline/update_evidence_from_pout.py,sha256=00-R5vkf40FuXM23-oXLHd5hH-7Kyop7cgfqsH1U0No,14856
-picked_group_fdr/pipeline/update_fragpipe_results.py,sha256=rkn3nzppqX9XcmpvJabZoiuWbfXIIftkimKKIyRwYo8,16452
-picked_group_fdr/plotter.py,sha256=5UZlbHXC6OVb1OV4PCFgT1JJ0laRlvxWNVUqvg5eIac,6975
+picked_group_fdr/pipeline/merge_pout.py,sha256=2BORjrzpUtJ5KQzTQOsAq7kV9KugfrKG8-bJ7h0A0fw,7158
+picked_group_fdr/pipeline/pipeline.py,sha256=O6NxCMgcivjKZUwJXnP7dHayg0029N52xmA4KEA9ezI,9362
+picked_group_fdr/pipeline/run_mokapot.py,sha256=SaeXN-jyIdZEGKDH1X2FT84F0Ydvc_Stq1gr7eO6Z20,2036
+picked_group_fdr/pipeline/sage_quantification.py,sha256=NkxKs1nMMXmhrMFvmNHLPG7XgyA45JcDzs_RNwt7b_s,4077
+picked_group_fdr/pipeline/update_evidence_from_pout.py,sha256=K7NIhMxm2M9jXNvyBQSWxkHWVNlQ9IyE8D9R2nfnwGo,15397
+picked_group_fdr/pipeline/update_fragpipe_results.py,sha256=NwpxwYkWHE767D2biGrR_wefrXVeekzIm6DmOZTmJTg,17651
+picked_group_fdr/plotter.py,sha256=0paSFNxX3cPWnH4AMt6D9AqAKYC78tpZx29MfAwRziM,6923
 picked_group_fdr/precursor_quant.py,sha256=0b8NdyGFz534zwC1ngBHVd9MCXpPTxSkXV4ZXiHEJYs,417
-picked_group_fdr/protein_annotation.py,sha256=k2wZasEgnn44dIWmOCEvSnWLH4G-rRnz1N5omCPHRvg,5600
-picked_group_fdr/protein_groups.py,sha256=B6QJ0NuIT5xd4M7KV05LUttbwzALW8vtdoofOhoS7VM,6861
+picked_group_fdr/protein_annotation.py,sha256=uahQvN188b3asgoZVAsfo0QODMqYt-pXJjBaPUGgCDQ,5594
+picked_group_fdr/protein_groups.py,sha256=mlV2RRRRIWCEcJoUwK2hkeDdFTeZe84Psz31EvoJyUo,6871
 picked_group_fdr/quant/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-picked_group_fdr/quant/fragpipe.py,sha256=W3l6aGj5OC5gKLB48BZrLtKcSww2bUtfBSyuruYAGY4,6222
-picked_group_fdr/quant/maxquant.py,sha256=gzFvs6jwJ22ZIEHU-w30-npAIvb7e9ZIJQWHdOtPVEw,4246
-picked_group_fdr/quant/sage.py,sha256=mB8QgJg6ghV6SQkzQioVw9tI1DhH5AKMbUtVt-CoJ-s,7088
-picked_group_fdr/quantification.py,sha256=ZFxl6PkYMjdL5Ij0_8CgToQ0OZRbcNRYltCqHhJQ81k,7017
+picked_group_fdr/quant/fragpipe.py,sha256=dCSnxwE8PDkn_tuJB_IQIc6QqVkiCZm2-KE61mBS1gg,7293
+picked_group_fdr/quant/maxquant.py,sha256=NLOQYlw7_GAC5i8ePel44wHRiLyUjRuZn5BSPez18Tw,4471
+picked_group_fdr/quant/sage.py,sha256=soZUBxaWWlG6Hz4PLRJFaIN45YrVBYll7nObRCRFEFk,8226
+picked_group_fdr/quantification.py,sha256=qHBW3dHIbq1dLtU7ZV-jc-G2aZv-FO5vRf3tXl4tz_0,10457
 picked_group_fdr/results.py,sha256=wFe30weiIc7TAy7rpggpPjD4RCJMgBCNKIE8Wm2PAFI,7899
-picked_group_fdr/score_origin.py,sha256=IE0gVT6zG4cW58VEaUs9e42Lh8LG05d95DIg1WFlxAM,3489
-picked_group_fdr/scoring.py,sha256=kWgaVQVIF_FQ6PmjDt_A62hck0R4ebhrjHsIG8pHWj8,6348
-picked_group_fdr/scoring_strategy.py,sha256=fcR40UXqQNf-64T-9efmw1iCXF148yyRMN2eaMmwjzs,8549
+picked_group_fdr/score_origin.py,sha256=XQH0QnL2-2Lc_Y14SHNJVvcII44Zv85rwaAfy91ajk8,3598
+picked_group_fdr/scoring.py,sha256=8yLNwil6OiiApRs51ErZMS7om9P8T6Jkm94t6izT8kc,6357
+picked_group_fdr/scoring_strategy.py,sha256=h8PzVgHNwkr_pbXO4ij3AxSF08XtwmmC6n-CiKDE_cQ,8749
 picked_group_fdr/setup.py,sha256=1RjiJ6Kqsf9WY-k7wq9QlHwp7neDGHI99O_oQI11eOw,154
 picked_group_fdr/simulation/simulate.py,sha256=Iqoxgbc77qqdb-NHgBpuk35Fjk_PuZjSgIA-dGw7DkA,17000
 picked_group_fdr/utils/compare_razor_peptides.py,sha256=XTxxWcrxvc8uWb-i3f134QN_3h4YqkNPP96EptgTarE,1061
 picked_group_fdr/utils/compare_results.py,sha256=mpuwvdtFZa6t_1rXGGDKdgOs5xXzNtJz683vSJPTEGw,1511
 picked_group_fdr/utils/get_genes_with_multiple_isoforms.py,sha256=i1G8AMQdjHT8w-t7zrv8SWw_fEfIHORBkQrOrXpXjVc,3412
-picked_group_fdr/writers/__init__.py,sha256=eXYvJD_trbPtLR3RPid2q2FlISgfVU9dThqtFFjWThE,372
-picked_group_fdr/writers/base.py,sha256=uAWhjyllSoLqDArYFtsZM1Fzv6lDTnMsmOIMibTIGH0,5107
-picked_group_fdr/writers/factory.py,sha256=TdMIKP3YT9Lu9tZqUwpQO_LBuNQRgK6oI6_qYpaiAk8,1889
+picked_group_fdr/writers/__init__.py,sha256=C70kyQcwtGPryYDo4fnG-OJHU6kHK4aBPTrO718f7QI,393
+picked_group_fdr/writers/base.py,sha256=WOkjPLvYUknlx4GAkbH_pqoBDGvVSlrNtVMphoCQZr8,6807
+picked_group_fdr/writers/factory.py,sha256=C3d0KWT9uDYkLVjwS5dIQcuzamqhmWCm4-vxZyNpBjg,1928
 picked_group_fdr/writers/fragpipe.py,sha256=ZyHqAkhlxAvQF_44D6_RqWezwaNsDztYdb76pqJZuf4,271
-picked_group_fdr/writers/fragpipe_combined.py,sha256=9ryohtdprDiEyfIivEPF_Org5RX33NCl3LL1q3P467E,3874
+picked_group_fdr/writers/fragpipe_combined.py,sha256=DfZ9GyZNhYt9zQ86ctDtunyiA-Bw2MMTsj-xkvptLNs,4905
 picked_group_fdr/writers/fragpipe_single.py,sha256=aq5DGsDpAsSOlITlbtVQDRWUpYhgwVebZg14XJhC89s,2747
-picked_group_fdr/writers/maxquant.py,sha256=DdEJejb0Ysvql-PEBUdVdtoAAVKhuv36CYmFLjyHgS0,1735
+picked_group_fdr/writers/maxquant.py,sha256=0Ec4MqTqyRyACnksNgLesAK8WWdERSVc0lDqk1Wrh5s,1915
 picked_group_fdr/writers/minimal.py,sha256=7oWhV3iZ33m3hYb6g3obdFdu5AP3R1pzp3SSN-HmmTE,851
-picked_group_fdr-0.6.6.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-picked_group_fdr-0.6.6.dist-info/METADATA,sha256=TFOPwF0ToOmpDl59g2piSU0N-Wi1KYjZLJjPC9yCcbk,5015
-picked_group_fdr-0.6.6.dist-info/WHEEL,sha256=7Z8_27uaHI_UZAc4Uox4PpBhQ9Y5_modZXWMxtUi4NU,88
-picked_group_fdr-0.6.6.dist-info/RECORD,,
+picked_group_fdr-0.7.0.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
+picked_group_fdr-0.7.0.dist-info/METADATA,sha256=QG_KESTc9AttFTAMNg6hIKI8YwHswA5Fp6t1CJqd0Ow,2792
+picked_group_fdr-0.7.0.dist-info/WHEEL,sha256=7Z8_27uaHI_UZAc4Uox4PpBhQ9Y5_modZXWMxtUi4NU,88
+picked_group_fdr-0.7.0.dist-info/RECORD,,
```

